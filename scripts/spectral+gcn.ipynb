{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TFFyUPsaSo1_",
        "outputId": "432f0956-4206-44b5-8b0c-c1c133a2f42f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/tkipf/pygcn.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O2XGiE85TkmK",
        "outputId": "770aa055-04b4-45d6-f829-d394a35b34a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'pygcn'...\n",
            "remote: Enumerating objects: 78, done.\u001b[K\n",
            "remote: Total 78 (delta 0), reused 0 (delta 0), pack-reused 78\u001b[K\n",
            "Receiving objects: 100% (78/78), 226.61 KiB | 1.33 MiB/s, done.\n",
            "Resolving deltas: 100% (35/35), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd pygcn/pygcn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pwoME7n2UAtU",
        "outputId": "6b678f43-1fa7-48df-80d6-550995b48211"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/pygcn/pygcn\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "with zipfile.ZipFile('/content/drive/MyDrive/da324dataminingproject2.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('/content/pygcn/pygcn')"
      ],
      "metadata": {
        "id": "uj7JrwqmTkSN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python train.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qoyVtmbaZMuu",
        "outputId": "71ed8acd-e865-41da-f693-6b3a1939105f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data Loaded\n",
            "Epoch: 0001 loss_train: 161729392.0000 acc_train: 0.1011 time: 1.1290s\n",
            "Epoch: 0002 loss_train: 112011696.0000 acc_train: 0.1013 time: 0.0254s\n",
            "Epoch: 0003 loss_train: 103070152.0000 acc_train: 0.1878 time: 0.0252s\n",
            "Epoch: 0004 loss_train: 94600680.0000 acc_train: 0.1878 time: 0.0252s\n",
            "Epoch: 0005 loss_train: 86785360.0000 acc_train: 0.0962 time: 0.0252s\n",
            "Epoch: 0006 loss_train: 86306672.0000 acc_train: 0.0878 time: 0.0246s\n",
            "Epoch: 0007 loss_train: 75623744.0000 acc_train: 0.0951 time: 0.0188s\n",
            "Epoch: 0008 loss_train: 65385756.0000 acc_train: 0.0919 time: 0.0187s\n",
            "Epoch: 0009 loss_train: 66157516.0000 acc_train: 0.0987 time: 0.0187s\n",
            "Epoch: 0010 loss_train: 60455344.0000 acc_train: 0.0991 time: 0.0187s\n",
            "Epoch: 0011 loss_train: 50941644.0000 acc_train: 0.1292 time: 0.0187s\n",
            "Epoch: 0012 loss_train: 49830388.0000 acc_train: 0.1872 time: 0.0188s\n",
            "Epoch: 0013 loss_train: 48188404.0000 acc_train: 0.0871 time: 0.0187s\n",
            "Epoch: 0014 loss_train: 40668288.0000 acc_train: 0.1859 time: 0.0187s\n",
            "Epoch: 0015 loss_train: 33394290.0000 acc_train: 0.1811 time: 0.0187s\n",
            "Epoch: 0016 loss_train: 26659850.0000 acc_train: 0.0900 time: 0.0188s\n",
            "Epoch: 0017 loss_train: 22425428.0000 acc_train: 0.0990 time: 0.0186s\n",
            "Epoch: 0018 loss_train: 25970902.0000 acc_train: 0.0862 time: 0.0177s\n",
            "Epoch: 0019 loss_train: 25087390.0000 acc_train: 0.0982 time: 0.0178s\n",
            "Epoch: 0020 loss_train: 23626564.0000 acc_train: 0.0972 time: 0.0179s\n",
            "Epoch: 0021 loss_train: 27621234.0000 acc_train: 0.1006 time: 0.0177s\n",
            "Epoch: 0022 loss_train: 27732316.0000 acc_train: 0.1004 time: 0.0178s\n",
            "Epoch: 0023 loss_train: 23467262.0000 acc_train: 0.1050 time: 0.0177s\n",
            "Epoch: 0024 loss_train: 23177462.0000 acc_train: 0.1104 time: 0.0178s\n",
            "Epoch: 0025 loss_train: 19176946.0000 acc_train: 0.1056 time: 0.0178s\n",
            "Epoch: 0026 loss_train: 16469675.0000 acc_train: 0.0959 time: 0.0177s\n",
            "Epoch: 0027 loss_train: 14261551.0000 acc_train: 0.1136 time: 0.0179s\n",
            "Epoch: 0028 loss_train: 13424220.0000 acc_train: 0.1672 time: 0.0178s\n",
            "Epoch: 0029 loss_train: 13464155.0000 acc_train: 0.1699 time: 0.0177s\n",
            "Epoch: 0030 loss_train: 11979568.0000 acc_train: 0.1649 time: 0.0178s\n",
            "Epoch: 0031 loss_train: 11120465.0000 acc_train: 0.0795 time: 0.0177s\n",
            "Epoch: 0032 loss_train: 11673428.0000 acc_train: 0.0846 time: 0.0176s\n",
            "Epoch: 0033 loss_train: 11642608.0000 acc_train: 0.0942 time: 0.0176s\n",
            "Epoch: 0034 loss_train: 13714965.0000 acc_train: 0.0826 time: 0.0175s\n",
            "Epoch: 0035 loss_train: 9930517.0000 acc_train: 0.0846 time: 0.0178s\n",
            "Epoch: 0036 loss_train: 8957057.0000 acc_train: 0.0985 time: 0.0179s\n",
            "Epoch: 0037 loss_train: 9047389.0000 acc_train: 0.0779 time: 0.0177s\n",
            "Epoch: 0038 loss_train: 8185611.5000 acc_train: 0.0995 time: 0.0177s\n",
            "Epoch: 0039 loss_train: 9716779.0000 acc_train: 0.1074 time: 0.0177s\n",
            "Epoch: 0040 loss_train: 10536121.0000 acc_train: 0.1692 time: 0.0177s\n",
            "Epoch: 0041 loss_train: 10750516.0000 acc_train: 0.1754 time: 0.0178s\n",
            "Epoch: 0042 loss_train: 9279234.0000 acc_train: 0.1091 time: 0.0177s\n",
            "Epoch: 0043 loss_train: 7061069.5000 acc_train: 0.0991 time: 0.0177s\n",
            "Epoch: 0044 loss_train: 5193221.5000 acc_train: 0.1009 time: 0.0178s\n",
            "Epoch: 0045 loss_train: 5050649.0000 acc_train: 0.1118 time: 0.0178s\n",
            "Epoch: 0046 loss_train: 5053331.0000 acc_train: 0.1045 time: 0.0179s\n",
            "Epoch: 0047 loss_train: 5918410.5000 acc_train: 0.0792 time: 0.0178s\n",
            "Epoch: 0048 loss_train: 6871759.0000 acc_train: 0.0962 time: 0.0218s\n",
            "Epoch: 0049 loss_train: 7264791.0000 acc_train: 0.1555 time: 0.0173s\n",
            "Epoch: 0050 loss_train: 6818422.5000 acc_train: 0.1623 time: 0.0173s\n",
            "Epoch: 0051 loss_train: 6184854.0000 acc_train: 0.0864 time: 0.0174s\n",
            "Epoch: 0052 loss_train: 3944958.5000 acc_train: 0.0845 time: 0.0176s\n",
            "Epoch: 0053 loss_train: 4449171.0000 acc_train: 0.1030 time: 0.0177s\n",
            "Epoch: 0054 loss_train: 4265188.5000 acc_train: 0.0981 time: 0.0177s\n",
            "Epoch: 0055 loss_train: 5937874.5000 acc_train: 0.0869 time: 0.0178s\n",
            "Epoch: 0056 loss_train: 5580187.0000 acc_train: 0.0989 time: 0.0179s\n",
            "Epoch: 0057 loss_train: 6698233.0000 acc_train: 0.1608 time: 0.0182s\n",
            "Epoch: 0058 loss_train: 6788679.5000 acc_train: 0.1402 time: 0.0183s\n",
            "Epoch: 0059 loss_train: 6358626.5000 acc_train: 0.0911 time: 0.0186s\n",
            "Epoch: 0060 loss_train: 7114710.0000 acc_train: 0.0919 time: 0.0187s\n",
            "Epoch: 0061 loss_train: 6905916.5000 acc_train: 0.0793 time: 0.0188s\n",
            "Epoch: 0062 loss_train: 6017959.0000 acc_train: 0.0816 time: 0.0189s\n",
            "Epoch: 0063 loss_train: 5487169.0000 acc_train: 0.1351 time: 0.0190s\n",
            "Epoch: 0064 loss_train: 5830664.0000 acc_train: 0.1200 time: 0.0190s\n",
            "Epoch: 0065 loss_train: 5089749.0000 acc_train: 0.1186 time: 0.0190s\n",
            "Epoch: 0066 loss_train: 3945645.2500 acc_train: 0.1228 time: 0.0193s\n",
            "Epoch: 0067 loss_train: 5611352.5000 acc_train: 0.0825 time: 0.0194s\n",
            "Epoch: 0068 loss_train: 5315932.0000 acc_train: 0.0885 time: 0.0192s\n",
            "Epoch: 0069 loss_train: 5649525.5000 acc_train: 0.1244 time: 0.0188s\n",
            "Epoch: 0070 loss_train: 5525052.0000 acc_train: 0.1234 time: 0.0182s\n",
            "Epoch: 0071 loss_train: 5387691.0000 acc_train: 0.1696 time: 0.0180s\n",
            "Epoch: 0072 loss_train: 5906294.5000 acc_train: 0.1013 time: 0.0178s\n",
            "Epoch: 0073 loss_train: 5866012.5000 acc_train: 0.0972 time: 0.0179s\n",
            "Epoch: 0074 loss_train: 5296439.0000 acc_train: 0.0894 time: 0.0179s\n",
            "Epoch: 0075 loss_train: 4594047.5000 acc_train: 0.0930 time: 0.0177s\n",
            "Epoch: 0076 loss_train: 6723464.5000 acc_train: 0.0828 time: 0.0178s\n",
            "Epoch: 0077 loss_train: 6072863.0000 acc_train: 0.0868 time: 0.0178s\n",
            "Epoch: 0078 loss_train: 5763785.0000 acc_train: 0.1519 time: 0.0183s\n",
            "Epoch: 0079 loss_train: 4959522.0000 acc_train: 0.1378 time: 0.0183s\n",
            "Epoch: 0080 loss_train: 5095742.5000 acc_train: 0.0768 time: 0.0183s\n",
            "Epoch: 0081 loss_train: 4529884.0000 acc_train: 0.1046 time: 0.0182s\n",
            "Epoch: 0082 loss_train: 4761045.0000 acc_train: 0.1017 time: 0.0180s\n",
            "Epoch: 0083 loss_train: 5696958.0000 acc_train: 0.0954 time: 0.0179s\n",
            "Epoch: 0084 loss_train: 4681109.5000 acc_train: 0.1076 time: 0.0179s\n",
            "Epoch: 0085 loss_train: 4399835.0000 acc_train: 0.1593 time: 0.0178s\n",
            "Epoch: 0086 loss_train: 4342495.5000 acc_train: 0.1339 time: 0.0180s\n",
            "Epoch: 0087 loss_train: 4265606.0000 acc_train: 0.1119 time: 0.0182s\n",
            "Epoch: 0088 loss_train: 5073167.5000 acc_train: 0.0820 time: 0.0182s\n",
            "Epoch: 0089 loss_train: 4678941.5000 acc_train: 0.1024 time: 0.0182s\n",
            "Epoch: 0090 loss_train: 5392368.0000 acc_train: 0.0987 time: 0.0182s\n",
            "Epoch: 0091 loss_train: 3812345.7500 acc_train: 0.1044 time: 0.0182s\n",
            "Epoch: 0092 loss_train: 5291052.0000 acc_train: 0.1413 time: 0.0181s\n",
            "Epoch: 0093 loss_train: 5821209.0000 acc_train: 0.1069 time: 0.0182s\n",
            "Epoch: 0094 loss_train: 5498233.0000 acc_train: 0.1693 time: 0.0181s\n",
            "Epoch: 0095 loss_train: 4485630.5000 acc_train: 0.1295 time: 0.0180s\n",
            "Epoch: 0096 loss_train: 6158898.5000 acc_train: 0.0794 time: 0.0183s\n",
            "Epoch: 0097 loss_train: 5564563.5000 acc_train: 0.1016 time: 0.0185s\n",
            "Epoch: 0098 loss_train: 5486020.0000 acc_train: 0.1026 time: 0.0188s\n",
            "Epoch: 0099 loss_train: 5529149.0000 acc_train: 0.0918 time: 0.0185s\n",
            "Epoch: 0100 loss_train: 4435385.0000 acc_train: 0.0977 time: 0.0182s\n",
            "Epoch: 0101 loss_train: 4913952.0000 acc_train: 0.0781 time: 0.0178s\n",
            "Epoch: 0102 loss_train: 5165592.5000 acc_train: 0.0947 time: 0.0177s\n",
            "Epoch: 0103 loss_train: 7166053.5000 acc_train: 0.1855 time: 0.0177s\n",
            "Epoch: 0104 loss_train: 5912415.0000 acc_train: 0.1096 time: 0.0177s\n",
            "Epoch: 0105 loss_train: 5869803.0000 acc_train: 0.1097 time: 0.0178s\n",
            "Epoch: 0106 loss_train: 5653466.0000 acc_train: 0.1468 time: 0.0178s\n",
            "Epoch: 0107 loss_train: 3969236.7500 acc_train: 0.0938 time: 0.0181s\n",
            "Epoch: 0108 loss_train: 2893232.7500 acc_train: 0.1235 time: 0.0179s\n",
            "Epoch: 0109 loss_train: 3831374.5000 acc_train: 0.1004 time: 0.0180s\n",
            "Epoch: 0110 loss_train: 4460634.0000 acc_train: 0.0996 time: 0.0180s\n",
            "Epoch: 0111 loss_train: 3969188.2500 acc_train: 0.0929 time: 0.0182s\n",
            "Epoch: 0112 loss_train: 6044015.5000 acc_train: 0.0966 time: 0.0183s\n",
            "Epoch: 0113 loss_train: 4822068.5000 acc_train: 0.1362 time: 0.0214s\n",
            "Epoch: 0114 loss_train: 4895618.5000 acc_train: 0.1224 time: 0.0180s\n",
            "Epoch: 0115 loss_train: 4300095.0000 acc_train: 0.1501 time: 0.0175s\n",
            "Epoch: 0116 loss_train: 5322836.0000 acc_train: 0.0984 time: 0.0175s\n",
            "Epoch: 0117 loss_train: 6953602.5000 acc_train: 0.0626 time: 0.0178s\n",
            "Epoch: 0118 loss_train: 4549637.0000 acc_train: 0.0974 time: 0.0181s\n",
            "Epoch: 0119 loss_train: 4517157.5000 acc_train: 0.1002 time: 0.0181s\n",
            "Epoch: 0120 loss_train: 4205584.0000 acc_train: 0.0862 time: 0.0182s\n",
            "Epoch: 0121 loss_train: 3589745.7500 acc_train: 0.0924 time: 0.0178s\n",
            "Epoch: 0122 loss_train: 4000070.5000 acc_train: 0.1327 time: 0.0179s\n",
            "Epoch: 0123 loss_train: 4349650.0000 acc_train: 0.1715 time: 0.0179s\n",
            "Epoch: 0124 loss_train: 4067452.2500 acc_train: 0.0984 time: 0.0179s\n",
            "Epoch: 0125 loss_train: 4045390.2500 acc_train: 0.0990 time: 0.0180s\n",
            "Epoch: 0126 loss_train: 3425430.0000 acc_train: 0.1208 time: 0.0196s\n",
            "Epoch: 0127 loss_train: 4083512.2500 acc_train: 0.1042 time: 0.0189s\n",
            "Epoch: 0128 loss_train: 3338925.5000 acc_train: 0.1367 time: 0.0185s\n",
            "Epoch: 0129 loss_train: 3052129.0000 acc_train: 0.0997 time: 0.0183s\n",
            "Epoch: 0130 loss_train: 3300276.7500 acc_train: 0.0828 time: 0.0180s\n",
            "Epoch: 0131 loss_train: 4036646.2500 acc_train: 0.1361 time: 0.0178s\n",
            "Epoch: 0132 loss_train: 5167603.0000 acc_train: 0.0899 time: 0.0177s\n",
            "Epoch: 0133 loss_train: 3654917.7500 acc_train: 0.1425 time: 0.0177s\n",
            "Epoch: 0134 loss_train: 4114304.0000 acc_train: 0.0606 time: 0.0178s\n",
            "Epoch: 0135 loss_train: 3187226.2500 acc_train: 0.0899 time: 0.0177s\n",
            "Epoch: 0136 loss_train: 3748572.7500 acc_train: 0.0889 time: 0.0176s\n",
            "Epoch: 0137 loss_train: 2692111.2500 acc_train: 0.0976 time: 0.0177s\n",
            "Epoch: 0138 loss_train: 4131138.7500 acc_train: 0.0981 time: 0.0180s\n",
            "Epoch: 0139 loss_train: 4429065.5000 acc_train: 0.1614 time: 0.0179s\n",
            "Epoch: 0140 loss_train: 4785354.5000 acc_train: 0.1415 time: 0.0179s\n",
            "Epoch: 0141 loss_train: 4895251.5000 acc_train: 0.1031 time: 0.0178s\n",
            "Epoch: 0142 loss_train: 4496713.5000 acc_train: 0.0885 time: 0.0197s\n",
            "Epoch: 0143 loss_train: 5013113.5000 acc_train: 0.1000 time: 0.0176s\n",
            "Epoch: 0144 loss_train: 4943934.5000 acc_train: 0.1040 time: 0.0175s\n",
            "Epoch: 0145 loss_train: 4915944.5000 acc_train: 0.1592 time: 0.0176s\n",
            "Epoch: 0146 loss_train: 4826168.0000 acc_train: 0.0830 time: 0.0205s\n",
            "Epoch: 0147 loss_train: 4081394.0000 acc_train: 0.1434 time: 0.0178s\n",
            "Epoch: 0148 loss_train: 5524291.5000 acc_train: 0.0936 time: 0.0175s\n",
            "Epoch: 0149 loss_train: 5110954.5000 acc_train: 0.0982 time: 0.0177s\n",
            "Epoch: 0150 loss_train: 4645017.5000 acc_train: 0.1012 time: 0.0180s\n",
            "Epoch: 0151 loss_train: 4177657.0000 acc_train: 0.0935 time: 0.0177s\n",
            "Epoch: 0152 loss_train: 3298630.5000 acc_train: 0.0753 time: 0.0176s\n",
            "Epoch: 0153 loss_train: 4085066.5000 acc_train: 0.1644 time: 0.0176s\n",
            "Epoch: 0154 loss_train: 3620128.7500 acc_train: 0.1501 time: 0.0176s\n",
            "Epoch: 0155 loss_train: 6096954.5000 acc_train: 0.0806 time: 0.0177s\n",
            "Epoch: 0156 loss_train: 6898662.5000 acc_train: 0.0800 time: 0.0180s\n",
            "Epoch: 0157 loss_train: 6771537.5000 acc_train: 0.0831 time: 0.0183s\n",
            "Epoch: 0158 loss_train: 5556861.0000 acc_train: 0.0932 time: 0.0181s\n",
            "Epoch: 0159 loss_train: 4588034.0000 acc_train: 0.1003 time: 0.0179s\n",
            "Epoch: 0160 loss_train: 4810496.5000 acc_train: 0.0933 time: 0.0179s\n",
            "Epoch: 0161 loss_train: 4134329.7500 acc_train: 0.0887 time: 0.0178s\n",
            "Epoch: 0162 loss_train: 6697272.0000 acc_train: 0.1738 time: 0.0180s\n",
            "Epoch: 0163 loss_train: 6124257.0000 acc_train: 0.1549 time: 0.0182s\n",
            "Epoch: 0164 loss_train: 6218186.0000 acc_train: 0.0814 time: 0.0182s\n",
            "Epoch: 0165 loss_train: 7356114.5000 acc_train: 0.0901 time: 0.0183s\n",
            "Epoch: 0166 loss_train: 7657362.0000 acc_train: 0.0984 time: 0.0184s\n",
            "Epoch: 0167 loss_train: 6562525.0000 acc_train: 0.1066 time: 0.0189s\n",
            "Epoch: 0168 loss_train: 4935737.0000 acc_train: 0.0935 time: 0.0187s\n",
            "Epoch: 0169 loss_train: 5387260.0000 acc_train: 0.0667 time: 0.0185s\n",
            "Epoch: 0170 loss_train: 5895265.5000 acc_train: 0.1839 time: 0.0183s\n",
            "Epoch: 0171 loss_train: 5838693.0000 acc_train: 0.0965 time: 0.0183s\n",
            "Epoch: 0172 loss_train: 5929772.0000 acc_train: 0.1105 time: 0.0183s\n",
            "Epoch: 0173 loss_train: 5023762.0000 acc_train: 0.1064 time: 0.0182s\n",
            "Epoch: 0174 loss_train: 5288103.0000 acc_train: 0.1636 time: 0.0180s\n",
            "Epoch: 0175 loss_train: 5782782.5000 acc_train: 0.0946 time: 0.0178s\n",
            "Epoch: 0176 loss_train: 5214115.0000 acc_train: 0.0869 time: 0.0181s\n",
            "Epoch: 0177 loss_train: 4391385.0000 acc_train: 0.0956 time: 0.0185s\n",
            "Epoch: 0178 loss_train: 4617405.5000 acc_train: 0.1003 time: 0.0189s\n",
            "Epoch: 0179 loss_train: 5336151.5000 acc_train: 0.1039 time: 0.0188s\n",
            "Epoch: 0180 loss_train: 5705900.5000 acc_train: 0.1518 time: 0.0187s\n",
            "Epoch: 0181 loss_train: 5457667.0000 acc_train: 0.0884 time: 0.0183s\n",
            "Epoch: 0182 loss_train: 4654830.0000 acc_train: 0.1456 time: 0.0181s\n",
            "Epoch: 0183 loss_train: 5098233.0000 acc_train: 0.0981 time: 0.0180s\n",
            "Epoch: 0184 loss_train: 4031151.5000 acc_train: 0.0927 time: 0.0181s\n",
            "Epoch: 0185 loss_train: 3774636.5000 acc_train: 0.0950 time: 0.0181s\n",
            "Epoch: 0186 loss_train: 2195249.7500 acc_train: 0.1291 time: 0.0181s\n",
            "Epoch: 0187 loss_train: 3353842.7500 acc_train: 0.1222 time: 0.0183s\n",
            "Epoch: 0188 loss_train: 3740930.7500 acc_train: 0.0911 time: 0.0187s\n",
            "Epoch: 0189 loss_train: 3829238.7500 acc_train: 0.1473 time: 0.0188s\n",
            "Epoch: 0190 loss_train: 5271246.5000 acc_train: 0.0635 time: 0.0183s\n",
            "Epoch: 0191 loss_train: 4188181.7500 acc_train: 0.0887 time: 0.0182s\n",
            "Epoch: 0192 loss_train: 4814675.0000 acc_train: 0.0844 time: 0.0179s\n",
            "Epoch: 0193 loss_train: 3723076.7500 acc_train: 0.0870 time: 0.0176s\n",
            "Epoch: 0194 loss_train: 4345341.5000 acc_train: 0.0867 time: 0.0177s\n",
            "Epoch: 0195 loss_train: 4171990.0000 acc_train: 0.1402 time: 0.0178s\n",
            "Epoch: 0196 loss_train: 4524552.0000 acc_train: 0.1438 time: 0.0178s\n",
            "Epoch: 0197 loss_train: 6338845.5000 acc_train: 0.0965 time: 0.0179s\n",
            "Epoch: 0198 loss_train: 6146969.0000 acc_train: 0.0824 time: 0.0183s\n",
            "Epoch: 0199 loss_train: 4279285.5000 acc_train: 0.0916 time: 0.0187s\n",
            "Epoch: 0200 loss_train: 4441915.5000 acc_train: 0.1422 time: 0.0184s\n",
            "Epoch: 0201 loss_train: 5016462.5000 acc_train: 0.1245 time: 0.0183s\n",
            "Epoch: 0202 loss_train: 5646392.5000 acc_train: 0.1224 time: 0.0180s\n",
            "Epoch: 0203 loss_train: 4977056.5000 acc_train: 0.1464 time: 0.0181s\n",
            "Epoch: 0204 loss_train: 4034039.0000 acc_train: 0.1149 time: 0.0181s\n",
            "Epoch: 0205 loss_train: 4139503.5000 acc_train: 0.0864 time: 0.0179s\n",
            "Epoch: 0206 loss_train: 5080501.0000 acc_train: 0.0970 time: 0.0178s\n",
            "Epoch: 0207 loss_train: 4253877.5000 acc_train: 0.0912 time: 0.0178s\n",
            "Epoch: 0208 loss_train: 4628299.5000 acc_train: 0.0947 time: 0.0181s\n",
            "Epoch: 0209 loss_train: 4905603.5000 acc_train: 0.0758 time: 0.0180s\n",
            "Epoch: 0210 loss_train: 4679685.5000 acc_train: 0.0982 time: 0.0178s\n",
            "Epoch: 0211 loss_train: 4687861.0000 acc_train: 0.1317 time: 0.0178s\n",
            "Epoch: 0212 loss_train: 5398779.0000 acc_train: 0.1277 time: 0.0177s\n",
            "Epoch: 0213 loss_train: 6047888.5000 acc_train: 0.1555 time: 0.0178s\n",
            "Epoch: 0214 loss_train: 5919121.5000 acc_train: 0.0920 time: 0.0178s\n",
            "Epoch: 0215 loss_train: 5412177.0000 acc_train: 0.1050 time: 0.0178s\n",
            "Epoch: 0216 loss_train: 3699516.0000 acc_train: 0.1222 time: 0.0179s\n",
            "Epoch: 0217 loss_train: 2758868.7500 acc_train: 0.1497 time: 0.0185s\n",
            "Epoch: 0218 loss_train: 4660654.0000 acc_train: 0.0856 time: 0.0189s\n",
            "Epoch: 0219 loss_train: 5103746.0000 acc_train: 0.0804 time: 0.0187s\n",
            "Epoch: 0220 loss_train: 5684932.5000 acc_train: 0.0827 time: 0.0184s\n",
            "Epoch: 0221 loss_train: 6475202.5000 acc_train: 0.0884 time: 0.0183s\n",
            "Epoch: 0222 loss_train: 5425393.5000 acc_train: 0.0923 time: 0.0183s\n",
            "Epoch: 0223 loss_train: 5359072.5000 acc_train: 0.0806 time: 0.0183s\n",
            "Epoch: 0224 loss_train: 7452883.0000 acc_train: 0.0868 time: 0.0182s\n",
            "Epoch: 0225 loss_train: 3888325.5000 acc_train: 0.1626 time: 0.0182s\n",
            "Epoch: 0226 loss_train: 4020069.2500 acc_train: 0.1737 time: 0.0180s\n",
            "Epoch: 0227 loss_train: 4663603.0000 acc_train: 0.0944 time: 0.0181s\n",
            "Epoch: 0228 loss_train: 3969049.5000 acc_train: 0.0946 time: 0.0186s\n",
            "Epoch: 0229 loss_train: 4642373.5000 acc_train: 0.1060 time: 0.0189s\n",
            "Epoch: 0230 loss_train: 3846271.2500 acc_train: 0.0993 time: 0.0186s\n",
            "Epoch: 0231 loss_train: 4316965.5000 acc_train: 0.0844 time: 0.0186s\n",
            "Epoch: 0232 loss_train: 3905146.7500 acc_train: 0.0763 time: 0.0184s\n",
            "Epoch: 0233 loss_train: 3938547.0000 acc_train: 0.1747 time: 0.0183s\n",
            "Epoch: 0234 loss_train: 3424848.7500 acc_train: 0.1612 time: 0.0183s\n",
            "Epoch: 0235 loss_train: 4115693.5000 acc_train: 0.0937 time: 0.0182s\n",
            "Epoch: 0236 loss_train: 5764012.0000 acc_train: 0.0819 time: 0.0182s\n",
            "Epoch: 0237 loss_train: 4448648.5000 acc_train: 0.0882 time: 0.0181s\n",
            "Epoch: 0238 loss_train: 5422683.5000 acc_train: 0.1064 time: 0.0182s\n",
            "Epoch: 0239 loss_train: 5324248.0000 acc_train: 0.0987 time: 0.0186s\n",
            "Epoch: 0240 loss_train: 4844675.5000 acc_train: 0.0919 time: 0.0190s\n",
            "Epoch: 0241 loss_train: 4315368.0000 acc_train: 0.0930 time: 0.0192s\n",
            "Epoch: 0242 loss_train: 4700675.5000 acc_train: 0.1696 time: 0.0186s\n",
            "Epoch: 0243 loss_train: 6402744.5000 acc_train: 0.0975 time: 0.0183s\n",
            "Epoch: 0244 loss_train: 6669353.0000 acc_train: 0.0922 time: 0.0179s\n",
            "Epoch: 0245 loss_train: 6697581.0000 acc_train: 0.1525 time: 0.0176s\n",
            "Epoch: 0246 loss_train: 6223599.5000 acc_train: 0.1759 time: 0.0178s\n",
            "Epoch: 0247 loss_train: 3913852.5000 acc_train: 0.0905 time: 0.0178s\n",
            "Epoch: 0248 loss_train: 4920982.5000 acc_train: 0.0804 time: 0.0177s\n",
            "Epoch: 0249 loss_train: 3732563.0000 acc_train: 0.1039 time: 0.0178s\n",
            "Epoch: 0250 loss_train: 3168426.2500 acc_train: 0.1032 time: 0.0181s\n",
            "Epoch: 0251 loss_train: 4468946.5000 acc_train: 0.0865 time: 0.0182s\n",
            "Epoch: 0252 loss_train: 4396413.5000 acc_train: 0.0917 time: 0.0183s\n",
            "Epoch: 0253 loss_train: 3664426.7500 acc_train: 0.0899 time: 0.0182s\n",
            "Epoch: 0254 loss_train: 4139369.2500 acc_train: 0.1690 time: 0.0183s\n",
            "Epoch: 0255 loss_train: 4390386.0000 acc_train: 0.0769 time: 0.0185s\n",
            "Epoch: 0256 loss_train: 3223437.5000 acc_train: 0.1022 time: 0.0182s\n",
            "Epoch: 0257 loss_train: 3158893.7500 acc_train: 0.1176 time: 0.0179s\n",
            "Epoch: 0258 loss_train: 3909987.0000 acc_train: 0.1150 time: 0.0178s\n",
            "Epoch: 0259 loss_train: 4293513.0000 acc_train: 0.1141 time: 0.0181s\n",
            "Epoch: 0260 loss_train: 4909788.0000 acc_train: 0.1438 time: 0.0184s\n",
            "Epoch: 0261 loss_train: 5643690.0000 acc_train: 0.0922 time: 0.0180s\n",
            "Epoch: 0262 loss_train: 5307168.0000 acc_train: 0.1032 time: 0.0178s\n",
            "Epoch: 0263 loss_train: 4546915.5000 acc_train: 0.0985 time: 0.0176s\n",
            "Epoch: 0264 loss_train: 5671347.5000 acc_train: 0.1123 time: 0.0178s\n",
            "Epoch: 0265 loss_train: 4825668.5000 acc_train: 0.1494 time: 0.0178s\n",
            "Epoch: 0266 loss_train: 3928275.2500 acc_train: 0.1185 time: 0.0177s\n",
            "Epoch: 0267 loss_train: 4291034.0000 acc_train: 0.0855 time: 0.0178s\n",
            "Epoch: 0268 loss_train: 5716833.0000 acc_train: 0.0916 time: 0.0181s\n",
            "Epoch: 0269 loss_train: 4913470.0000 acc_train: 0.0927 time: 0.0177s\n",
            "Epoch: 0270 loss_train: 5712581.5000 acc_train: 0.0882 time: 0.0177s\n",
            "Epoch: 0271 loss_train: 4592256.5000 acc_train: 0.1559 time: 0.0176s\n",
            "Epoch: 0272 loss_train: 4281086.5000 acc_train: 0.1248 time: 0.0180s\n",
            "Epoch: 0273 loss_train: 4159789.5000 acc_train: 0.0867 time: 0.0182s\n",
            "Epoch: 0274 loss_train: 4950627.5000 acc_train: 0.0723 time: 0.0181s\n",
            "Epoch: 0275 loss_train: 4913141.0000 acc_train: 0.0816 time: 0.0179s\n",
            "Epoch: 0276 loss_train: 3942751.2500 acc_train: 0.1555 time: 0.0179s\n",
            "Epoch: 0277 loss_train: 4483251.0000 acc_train: 0.1021 time: 0.0184s\n",
            "Epoch: 0278 loss_train: 5001815.5000 acc_train: 0.0980 time: 0.0186s\n",
            "Epoch: 0279 loss_train: 4502711.5000 acc_train: 0.1263 time: 0.0185s\n",
            "Epoch: 0280 loss_train: 5122826.5000 acc_train: 0.1208 time: 0.0183s\n",
            "Epoch: 0281 loss_train: 5481466.5000 acc_train: 0.0877 time: 0.0181s\n",
            "Epoch: 0282 loss_train: 4962737.5000 acc_train: 0.1111 time: 0.0184s\n",
            "Epoch: 0283 loss_train: 4306853.5000 acc_train: 0.1268 time: 0.0183s\n",
            "Epoch: 0284 loss_train: 3094071.2500 acc_train: 0.1241 time: 0.0184s\n",
            "Epoch: 0285 loss_train: 1939601.2500 acc_train: 0.1338 time: 0.0183s\n",
            "Epoch: 0286 loss_train: 2743295.0000 acc_train: 0.0854 time: 0.0183s\n",
            "Epoch: 0287 loss_train: 3074358.5000 acc_train: 0.0781 time: 0.0187s\n",
            "Epoch: 0288 loss_train: 3547996.5000 acc_train: 0.1003 time: 0.0187s\n",
            "Epoch: 0289 loss_train: 4338359.5000 acc_train: 0.0828 time: 0.0188s\n",
            "Epoch: 0290 loss_train: 3936030.0000 acc_train: 0.0871 time: 0.0185s\n",
            "Epoch: 0291 loss_train: 4230664.5000 acc_train: 0.1607 time: 0.0183s\n",
            "Epoch: 0292 loss_train: 3734432.2500 acc_train: 0.0799 time: 0.0183s\n",
            "Epoch: 0293 loss_train: 3198323.7500 acc_train: 0.1145 time: 0.0180s\n",
            "Epoch: 0294 loss_train: 3337662.5000 acc_train: 0.1023 time: 0.0181s\n",
            "Epoch: 0295 loss_train: 3259625.0000 acc_train: 0.1325 time: 0.0183s\n",
            "Epoch: 0296 loss_train: 3457530.0000 acc_train: 0.0976 time: 0.0184s\n",
            "Epoch: 0297 loss_train: 3544963.7500 acc_train: 0.0935 time: 0.0183s\n",
            "Epoch: 0298 loss_train: 4350896.5000 acc_train: 0.0930 time: 0.0182s\n",
            "Epoch: 0299 loss_train: 5071464.0000 acc_train: 0.1592 time: 0.0183s\n",
            "Epoch: 0300 loss_train: 5838635.5000 acc_train: 0.0815 time: 0.0185s\n",
            "Epoch: 0301 loss_train: 4280448.5000 acc_train: 0.1250 time: 0.0183s\n",
            "Epoch: 0302 loss_train: 3707537.0000 acc_train: 0.1567 time: 0.0182s\n",
            "Epoch: 0303 loss_train: 4655171.5000 acc_train: 0.1035 time: 0.0179s\n",
            "Epoch: 0304 loss_train: 4607454.5000 acc_train: 0.0924 time: 0.0176s\n",
            "Epoch: 0305 loss_train: 6072011.0000 acc_train: 0.0830 time: 0.0178s\n",
            "Epoch: 0306 loss_train: 5254029.5000 acc_train: 0.0934 time: 0.0180s\n",
            "Epoch: 0307 loss_train: 5475327.5000 acc_train: 0.0931 time: 0.0181s\n",
            "Epoch: 0308 loss_train: 3741105.7500 acc_train: 0.0958 time: 0.0183s\n",
            "Epoch: 0309 loss_train: 3874793.2500 acc_train: 0.1516 time: 0.0185s\n",
            "Epoch: 0310 loss_train: 4203262.5000 acc_train: 0.1179 time: 0.0212s\n",
            "Epoch: 0311 loss_train: 5739300.0000 acc_train: 0.0875 time: 0.0183s\n",
            "Epoch: 0312 loss_train: 4945089.5000 acc_train: 0.1113 time: 0.0181s\n",
            "Epoch: 0313 loss_train: 5149190.0000 acc_train: 0.1743 time: 0.0179s\n",
            "Epoch: 0314 loss_train: 6752051.0000 acc_train: 0.1001 time: 0.0181s\n",
            "Epoch: 0315 loss_train: 5554029.5000 acc_train: 0.0851 time: 0.0179s\n",
            "Epoch: 0316 loss_train: 6663469.5000 acc_train: 0.0633 time: 0.0178s\n",
            "Epoch: 0317 loss_train: 5421625.5000 acc_train: 0.0940 time: 0.0178s\n",
            "Epoch: 0318 loss_train: 6339371.5000 acc_train: 0.1254 time: 0.0177s\n",
            "Epoch: 0319 loss_train: 6149574.5000 acc_train: 0.1773 time: 0.0180s\n",
            "Epoch: 0320 loss_train: 5310030.0000 acc_train: 0.1024 time: 0.0184s\n",
            "Epoch: 0321 loss_train: 7666195.0000 acc_train: 0.0816 time: 0.0184s\n",
            "Epoch: 0322 loss_train: 6602687.0000 acc_train: 0.0939 time: 0.0183s\n",
            "Epoch: 0323 loss_train: 5076627.0000 acc_train: 0.0931 time: 0.0182s\n",
            "Epoch: 0324 loss_train: 5423158.5000 acc_train: 0.1753 time: 0.0178s\n",
            "Epoch: 0325 loss_train: 6082582.0000 acc_train: 0.1101 time: 0.0177s\n",
            "Epoch: 0326 loss_train: 4603417.5000 acc_train: 0.0962 time: 0.0177s\n",
            "Epoch: 0327 loss_train: 5094143.0000 acc_train: 0.0879 time: 0.0178s\n",
            "Epoch: 0328 loss_train: 6061693.0000 acc_train: 0.1057 time: 0.0180s\n",
            "Epoch: 0329 loss_train: 3930132.5000 acc_train: 0.1772 time: 0.0182s\n",
            "Epoch: 0330 loss_train: 4568849.5000 acc_train: 0.0892 time: 0.0187s\n",
            "Epoch: 0331 loss_train: 6599222.0000 acc_train: 0.0892 time: 0.0184s\n",
            "Epoch: 0332 loss_train: 3918903.2500 acc_train: 0.0974 time: 0.0183s\n",
            "Epoch: 0333 loss_train: 4733996.5000 acc_train: 0.0996 time: 0.0179s\n",
            "Epoch: 0334 loss_train: 4454507.5000 acc_train: 0.0741 time: 0.0179s\n",
            "Epoch: 0335 loss_train: 5377282.0000 acc_train: 0.1845 time: 0.0182s\n",
            "Epoch: 0336 loss_train: 5076020.5000 acc_train: 0.1266 time: 0.0181s\n",
            "Epoch: 0337 loss_train: 4255099.0000 acc_train: 0.0958 time: 0.0179s\n",
            "Epoch: 0338 loss_train: 3901669.0000 acc_train: 0.0993 time: 0.0180s\n",
            "Epoch: 0339 loss_train: 3850749.0000 acc_train: 0.0794 time: 0.0186s\n",
            "Epoch: 0340 loss_train: 4215294.0000 acc_train: 0.1266 time: 0.0189s\n",
            "Epoch: 0341 loss_train: 5572351.5000 acc_train: 0.0965 time: 0.0184s\n",
            "Epoch: 0342 loss_train: 5682547.0000 acc_train: 0.1857 time: 0.0184s\n",
            "Epoch: 0343 loss_train: 4435213.5000 acc_train: 0.1123 time: 0.0183s\n",
            "Epoch: 0344 loss_train: 4369609.5000 acc_train: 0.0865 time: 0.0182s\n",
            "Epoch: 0345 loss_train: 5318867.0000 acc_train: 0.0846 time: 0.0182s\n",
            "Epoch: 0346 loss_train: 5491829.0000 acc_train: 0.0762 time: 0.0182s\n",
            "Epoch: 0347 loss_train: 4229512.5000 acc_train: 0.0814 time: 0.0182s\n",
            "Epoch: 0348 loss_train: 2138345.0000 acc_train: 0.1475 time: 0.0182s\n",
            "Epoch: 0349 loss_train: 3226695.5000 acc_train: 0.0954 time: 0.0183s\n",
            "Epoch: 0350 loss_train: 4063959.5000 acc_train: 0.0962 time: 0.0185s\n",
            "Epoch: 0351 loss_train: 3715272.0000 acc_train: 0.1489 time: 0.0185s\n",
            "Epoch: 0352 loss_train: 4960492.0000 acc_train: 0.0968 time: 0.0193s\n",
            "Epoch: 0353 loss_train: 3580015.5000 acc_train: 0.1472 time: 0.0187s\n",
            "Epoch: 0354 loss_train: 3396864.2500 acc_train: 0.1028 time: 0.0184s\n",
            "Epoch: 0355 loss_train: 3851669.5000 acc_train: 0.0984 time: 0.0182s\n",
            "Epoch: 0356 loss_train: 5287818.0000 acc_train: 0.0932 time: 0.0181s\n",
            "Epoch: 0357 loss_train: 4010382.0000 acc_train: 0.0873 time: 0.0179s\n",
            "Epoch: 0358 loss_train: 4387922.0000 acc_train: 0.1777 time: 0.0178s\n",
            "Epoch: 0359 loss_train: 5665586.0000 acc_train: 0.1066 time: 0.0179s\n",
            "Epoch: 0360 loss_train: 5748469.5000 acc_train: 0.0770 time: 0.0181s\n",
            "Epoch: 0361 loss_train: 5302402.0000 acc_train: 0.0833 time: 0.0184s\n",
            "Epoch: 0362 loss_train: 3270798.7500 acc_train: 0.1003 time: 0.0185s\n",
            "Epoch: 0363 loss_train: 4447483.5000 acc_train: 0.1792 time: 0.0183s\n",
            "Epoch: 0364 loss_train: 3501332.0000 acc_train: 0.1171 time: 0.0183s\n",
            "Epoch: 0365 loss_train: 4793271.0000 acc_train: 0.0855 time: 0.0184s\n",
            "Epoch: 0366 loss_train: 4152320.0000 acc_train: 0.0844 time: 0.0180s\n",
            "Epoch: 0367 loss_train: 4442872.5000 acc_train: 0.0884 time: 0.0177s\n",
            "Epoch: 0368 loss_train: 5733250.5000 acc_train: 0.0908 time: 0.0178s\n",
            "Epoch: 0369 loss_train: 7881199.0000 acc_train: 0.1109 time: 0.0179s\n",
            "Epoch: 0370 loss_train: 7390899.0000 acc_train: 0.1833 time: 0.0180s\n",
            "Epoch: 0371 loss_train: 6590488.0000 acc_train: 0.0795 time: 0.0184s\n",
            "Epoch: 0372 loss_train: 7518689.5000 acc_train: 0.0957 time: 0.0186s\n",
            "Epoch: 0373 loss_train: 5154046.0000 acc_train: 0.0844 time: 0.0185s\n",
            "Epoch: 0374 loss_train: 4219012.0000 acc_train: 0.1612 time: 0.0183s\n",
            "Epoch: 0375 loss_train: 4002104.7500 acc_train: 0.1171 time: 0.0184s\n",
            "Epoch: 0376 loss_train: 5121349.0000 acc_train: 0.0957 time: 0.0179s\n",
            "Epoch: 0377 loss_train: 5553504.5000 acc_train: 0.0864 time: 0.0177s\n",
            "Epoch: 0378 loss_train: 5279127.5000 acc_train: 0.0787 time: 0.0177s\n",
            "Epoch: 0379 loss_train: 5046601.0000 acc_train: 0.1560 time: 0.0178s\n",
            "Epoch: 0380 loss_train: 5504953.5000 acc_train: 0.0760 time: 0.0179s\n",
            "Epoch: 0381 loss_train: 4735104.0000 acc_train: 0.0608 time: 0.0180s\n",
            "Epoch: 0382 loss_train: 7095944.5000 acc_train: 0.1105 time: 0.0186s\n",
            "Epoch: 0383 loss_train: 5051089.0000 acc_train: 0.0953 time: 0.0183s\n",
            "Epoch: 0384 loss_train: 5674609.5000 acc_train: 0.1319 time: 0.0180s\n",
            "Epoch: 0385 loss_train: 5383910.5000 acc_train: 0.1532 time: 0.0177s\n",
            "Epoch: 0386 loss_train: 5570010.0000 acc_train: 0.1227 time: 0.0177s\n",
            "Epoch: 0387 loss_train: 5489951.0000 acc_train: 0.1064 time: 0.0178s\n",
            "Epoch: 0388 loss_train: 4004967.2500 acc_train: 0.1554 time: 0.0178s\n",
            "Epoch: 0389 loss_train: 4350801.0000 acc_train: 0.0931 time: 0.0181s\n",
            "Epoch: 0390 loss_train: 4399674.5000 acc_train: 0.0888 time: 0.0186s\n",
            "Epoch: 0391 loss_train: 4250384.5000 acc_train: 0.0751 time: 0.0188s\n",
            "Epoch: 0392 loss_train: 3681907.2500 acc_train: 0.0892 time: 0.0189s\n",
            "Epoch: 0393 loss_train: 4737361.5000 acc_train: 0.1119 time: 0.0184s\n",
            "Epoch: 0394 loss_train: 5149188.0000 acc_train: 0.1750 time: 0.0182s\n",
            "Epoch: 0395 loss_train: 5268984.0000 acc_train: 0.1117 time: 0.0182s\n",
            "Epoch: 0396 loss_train: 4959975.0000 acc_train: 0.0961 time: 0.0184s\n",
            "Epoch: 0397 loss_train: 3181798.0000 acc_train: 0.1465 time: 0.0185s\n",
            "Epoch: 0398 loss_train: 4338217.5000 acc_train: 0.0966 time: 0.0185s\n",
            "Epoch: 0399 loss_train: 2761959.0000 acc_train: 0.1005 time: 0.0184s\n",
            "Epoch: 0400 loss_train: 4636557.0000 acc_train: 0.0972 time: 0.0183s\n",
            "Epoch: 0401 loss_train: 5539946.5000 acc_train: 0.0820 time: 0.0184s\n",
            "Epoch: 0402 loss_train: 5296516.0000 acc_train: 0.1318 time: 0.0185s\n",
            "Epoch: 0403 loss_train: 5785709.0000 acc_train: 0.1822 time: 0.0186s\n",
            "Epoch: 0404 loss_train: 5259948.5000 acc_train: 0.1083 time: 0.0192s\n",
            "Epoch: 0405 loss_train: 5733724.5000 acc_train: 0.0630 time: 0.0189s\n",
            "Epoch: 0406 loss_train: 4347636.5000 acc_train: 0.0804 time: 0.0187s\n",
            "Epoch: 0407 loss_train: 4053771.7500 acc_train: 0.0959 time: 0.0182s\n",
            "Epoch: 0408 loss_train: 3608123.7500 acc_train: 0.0996 time: 0.0179s\n",
            "Epoch: 0409 loss_train: 4584730.5000 acc_train: 0.1094 time: 0.0179s\n",
            "Epoch: 0410 loss_train: 4645798.0000 acc_train: 0.1839 time: 0.0181s\n",
            "Epoch: 0411 loss_train: 4672909.0000 acc_train: 0.1108 time: 0.0181s\n",
            "Epoch: 0412 loss_train: 3191192.0000 acc_train: 0.1102 time: 0.0181s\n",
            "Epoch: 0413 loss_train: 3947259.2500 acc_train: 0.0797 time: 0.0182s\n",
            "Epoch: 0414 loss_train: 5289537.5000 acc_train: 0.0926 time: 0.0185s\n",
            "Epoch: 0415 loss_train: 4577942.5000 acc_train: 0.1083 time: 0.0189s\n",
            "Epoch: 0416 loss_train: 5218584.0000 acc_train: 0.1865 time: 0.0186s\n",
            "Epoch: 0417 loss_train: 4985714.0000 acc_train: 0.1078 time: 0.0183s\n",
            "Epoch: 0418 loss_train: 4145939.2500 acc_train: 0.0997 time: 0.0181s\n",
            "Epoch: 0419 loss_train: 3614777.2500 acc_train: 0.1021 time: 0.0179s\n",
            "Epoch: 0420 loss_train: 3696196.5000 acc_train: 0.1251 time: 0.0181s\n",
            "Epoch: 0421 loss_train: 5578500.5000 acc_train: 0.1115 time: 0.0180s\n",
            "Epoch: 0422 loss_train: 6392493.0000 acc_train: 0.0942 time: 0.0179s\n",
            "Epoch: 0423 loss_train: 5903361.0000 acc_train: 0.1035 time: 0.0177s\n",
            "Epoch: 0424 loss_train: 6133804.5000 acc_train: 0.1792 time: 0.0183s\n",
            "Epoch: 0425 loss_train: 7756769.5000 acc_train: 0.0636 time: 0.0185s\n",
            "Epoch: 0426 loss_train: 7725288.0000 acc_train: 0.0669 time: 0.0182s\n",
            "Epoch: 0427 loss_train: 6148015.0000 acc_train: 0.0967 time: 0.0181s\n",
            "Epoch: 0428 loss_train: 4150355.5000 acc_train: 0.0810 time: 0.0180s\n",
            "Epoch: 0429 loss_train: 4471049.0000 acc_train: 0.1630 time: 0.0181s\n",
            "Epoch: 0430 loss_train: 5862311.5000 acc_train: 0.1076 time: 0.0181s\n",
            "Epoch: 0431 loss_train: 6159646.5000 acc_train: 0.0868 time: 0.0181s\n",
            "Epoch: 0432 loss_train: 6530758.5000 acc_train: 0.0855 time: 0.0180s\n",
            "Epoch: 0433 loss_train: 6430613.0000 acc_train: 0.0945 time: 0.0180s\n",
            "Epoch: 0434 loss_train: 4390539.0000 acc_train: 0.1082 time: 0.0183s\n",
            "Epoch: 0435 loss_train: 5480941.5000 acc_train: 0.1191 time: 0.0181s\n",
            "Epoch: 0436 loss_train: 5414410.5000 acc_train: 0.1755 time: 0.0179s\n",
            "Epoch: 0437 loss_train: 3732024.0000 acc_train: 0.0874 time: 0.0179s\n",
            "Epoch: 0438 loss_train: 5037776.0000 acc_train: 0.0971 time: 0.0178s\n",
            "Epoch: 0439 loss_train: 4554506.5000 acc_train: 0.0856 time: 0.0179s\n",
            "Epoch: 0440 loss_train: 5083868.0000 acc_train: 0.1100 time: 0.0178s\n",
            "Epoch: 0441 loss_train: 5457374.0000 acc_train: 0.1045 time: 0.0179s\n",
            "Epoch: 0442 loss_train: 3640528.0000 acc_train: 0.1210 time: 0.0182s\n",
            "Epoch: 0443 loss_train: 4881167.0000 acc_train: 0.1230 time: 0.0187s\n",
            "Epoch: 0444 loss_train: 6269016.0000 acc_train: 0.1270 time: 0.0184s\n",
            "Epoch: 0445 loss_train: 6285232.5000 acc_train: 0.1860 time: 0.0182s\n",
            "Epoch: 0446 loss_train: 6761021.0000 acc_train: 0.0933 time: 0.0181s\n",
            "Epoch: 0447 loss_train: 6703696.5000 acc_train: 0.0776 time: 0.0181s\n",
            "Epoch: 0448 loss_train: 7241176.0000 acc_train: 0.1034 time: 0.0183s\n",
            "Epoch: 0449 loss_train: 6579503.5000 acc_train: 0.0688 time: 0.0184s\n",
            "Epoch: 0450 loss_train: 5926843.0000 acc_train: 0.0786 time: 0.0184s\n",
            "Epoch: 0451 loss_train: 6159768.0000 acc_train: 0.0762 time: 0.0181s\n",
            "Epoch: 0452 loss_train: 5025703.5000 acc_train: 0.0877 time: 0.0179s\n",
            "Epoch: 0453 loss_train: 5469210.0000 acc_train: 0.1770 time: 0.0179s\n",
            "Epoch: 0454 loss_train: 5579119.0000 acc_train: 0.1097 time: 0.0184s\n",
            "Epoch: 0455 loss_train: 4674945.0000 acc_train: 0.1439 time: 0.0184s\n",
            "Epoch: 0456 loss_train: 4011863.2500 acc_train: 0.1334 time: 0.0181s\n",
            "Epoch: 0457 loss_train: 5048722.5000 acc_train: 0.0988 time: 0.0179s\n",
            "Epoch: 0458 loss_train: 6341443.5000 acc_train: 0.0815 time: 0.0181s\n",
            "Epoch: 0459 loss_train: 5334656.5000 acc_train: 0.0854 time: 0.0181s\n",
            "Epoch: 0460 loss_train: 7728419.5000 acc_train: 0.1108 time: 0.0182s\n",
            "Epoch: 0461 loss_train: 7814623.5000 acc_train: 0.0873 time: 0.0182s\n",
            "Epoch: 0462 loss_train: 6126752.0000 acc_train: 0.1860 time: 0.0183s\n",
            "Epoch: 0463 loss_train: 5178741.5000 acc_train: 0.1568 time: 0.0185s\n",
            "Epoch: 0464 loss_train: 6304055.0000 acc_train: 0.0981 time: 0.0190s\n",
            "Epoch: 0465 loss_train: 5167936.5000 acc_train: 0.1085 time: 0.0184s\n",
            "Epoch: 0466 loss_train: 4760392.5000 acc_train: 0.0799 time: 0.0180s\n",
            "Epoch: 0467 loss_train: 5184324.5000 acc_train: 0.0724 time: 0.0180s\n",
            "Epoch: 0468 loss_train: 3746399.7500 acc_train: 0.0834 time: 0.0178s\n",
            "Epoch: 0469 loss_train: 4369699.5000 acc_train: 0.0956 time: 0.0180s\n",
            "Epoch: 0470 loss_train: 4900798.0000 acc_train: 0.0863 time: 0.0180s\n",
            "Epoch: 0471 loss_train: 4598734.0000 acc_train: 0.0847 time: 0.0179s\n",
            "Epoch: 0472 loss_train: 5027378.5000 acc_train: 0.1763 time: 0.0182s\n",
            "Epoch: 0473 loss_train: 6296410.5000 acc_train: 0.0995 time: 0.0185s\n",
            "Epoch: 0474 loss_train: 5236487.5000 acc_train: 0.1062 time: 0.0187s\n",
            "Epoch: 0475 loss_train: 5603009.5000 acc_train: 0.1844 time: 0.0186s\n",
            "Epoch: 0476 loss_train: 5189771.0000 acc_train: 0.1192 time: 0.0182s\n",
            "Epoch: 0477 loss_train: 4361258.5000 acc_train: 0.0903 time: 0.0180s\n",
            "Epoch: 0478 loss_train: 5791408.0000 acc_train: 0.0956 time: 0.0180s\n",
            "Epoch: 0479 loss_train: 4563578.5000 acc_train: 0.0927 time: 0.0179s\n",
            "Epoch: 0480 loss_train: 3410119.2500 acc_train: 0.0903 time: 0.0178s\n",
            "Epoch: 0481 loss_train: 3679407.0000 acc_train: 0.1705 time: 0.0177s\n",
            "Epoch: 0482 loss_train: 4437187.5000 acc_train: 0.0966 time: 0.0178s\n",
            "Epoch: 0483 loss_train: 3405132.0000 acc_train: 0.1374 time: 0.0178s\n",
            "Epoch: 0484 loss_train: 3611974.0000 acc_train: 0.0766 time: 0.0178s\n",
            "Epoch: 0485 loss_train: 4164580.0000 acc_train: 0.0973 time: 0.0179s\n",
            "Epoch: 0486 loss_train: 4053052.2500 acc_train: 0.0936 time: 0.0178s\n",
            "Epoch: 0487 loss_train: 6071376.5000 acc_train: 0.0835 time: 0.0180s\n",
            "Epoch: 0488 loss_train: 3836267.5000 acc_train: 0.0852 time: 0.0181s\n",
            "Epoch: 0489 loss_train: 4370477.5000 acc_train: 0.0862 time: 0.0180s\n",
            "Epoch: 0490 loss_train: 5316047.0000 acc_train: 0.0886 time: 0.0178s\n",
            "Epoch: 0491 loss_train: 7051169.0000 acc_train: 0.1108 time: 0.0179s\n",
            "Epoch: 0492 loss_train: 7762271.5000 acc_train: 0.1854 time: 0.0181s\n",
            "Epoch: 0493 loss_train: 7061205.5000 acc_train: 0.1252 time: 0.0179s\n",
            "Epoch: 0494 loss_train: 7691426.5000 acc_train: 0.0888 time: 0.0179s\n",
            "Epoch: 0495 loss_train: 7542591.0000 acc_train: 0.0912 time: 0.0179s\n",
            "Epoch: 0496 loss_train: 6353933.5000 acc_train: 0.0746 time: 0.0179s\n",
            "Epoch: 0497 loss_train: 5723599.5000 acc_train: 0.0978 time: 0.0178s\n",
            "Epoch: 0498 loss_train: 7090702.0000 acc_train: 0.1873 time: 0.0178s\n",
            "Epoch: 0499 loss_train: 7167578.0000 acc_train: 0.0964 time: 0.0180s\n",
            "Epoch: 0500 loss_train: 7253443.0000 acc_train: 0.0967 time: 0.0182s\n",
            "Epoch: 0501 loss_train: 7410436.5000 acc_train: 0.0856 time: 0.0185s\n",
            "Epoch: 0502 loss_train: 7864341.5000 acc_train: 0.1098 time: 0.0188s\n",
            "Epoch: 0503 loss_train: 9180630.0000 acc_train: 0.0826 time: 0.0184s\n",
            "Epoch: 0504 loss_train: 8556093.0000 acc_train: 0.1799 time: 0.0182s\n",
            "Epoch: 0505 loss_train: 6938168.5000 acc_train: 0.1528 time: 0.0180s\n",
            "Epoch: 0506 loss_train: 7940669.5000 acc_train: 0.0933 time: 0.0178s\n",
            "Epoch: 0507 loss_train: 6397869.5000 acc_train: 0.0651 time: 0.0178s\n",
            "Epoch: 0508 loss_train: 4460066.0000 acc_train: 0.0704 time: 0.0178s\n",
            "Epoch: 0509 loss_train: 3574897.0000 acc_train: 0.0880 time: 0.0179s\n",
            "Epoch: 0510 loss_train: 3767725.7500 acc_train: 0.0962 time: 0.0180s\n",
            "Epoch: 0511 loss_train: 3206566.5000 acc_train: 0.1841 time: 0.0181s\n",
            "Epoch: 0512 loss_train: 4785152.0000 acc_train: 0.0919 time: 0.0182s\n",
            "Epoch: 0513 loss_train: 5567799.0000 acc_train: 0.1039 time: 0.0179s\n",
            "Epoch: 0514 loss_train: 7600233.5000 acc_train: 0.0865 time: 0.0180s\n",
            "Epoch: 0515 loss_train: 4840881.0000 acc_train: 0.0848 time: 0.0179s\n",
            "Epoch: 0516 loss_train: 4867282.0000 acc_train: 0.0952 time: 0.0179s\n",
            "Epoch: 0517 loss_train: 5745865.0000 acc_train: 0.0834 time: 0.0178s\n",
            "Epoch: 0518 loss_train: 6109091.0000 acc_train: 0.1024 time: 0.0179s\n",
            "Epoch: 0519 loss_train: 6773621.0000 acc_train: 0.1847 time: 0.0182s\n",
            "Epoch: 0520 loss_train: 6197240.0000 acc_train: 0.1601 time: 0.0181s\n",
            "Epoch: 0521 loss_train: 5858241.0000 acc_train: 0.1051 time: 0.0181s\n",
            "Epoch: 0522 loss_train: 5881208.0000 acc_train: 0.1014 time: 0.0179s\n",
            "Epoch: 0523 loss_train: 4835765.0000 acc_train: 0.0960 time: 0.0179s\n",
            "Epoch: 0524 loss_train: 7186851.0000 acc_train: 0.1091 time: 0.0178s\n",
            "Epoch: 0525 loss_train: 5889796.0000 acc_train: 0.0892 time: 0.0178s\n",
            "Epoch: 0526 loss_train: 5483549.0000 acc_train: 0.1568 time: 0.0181s\n",
            "Epoch: 0527 loss_train: 6284588.0000 acc_train: 0.0987 time: 0.0182s\n",
            "Epoch: 0528 loss_train: 4640254.5000 acc_train: 0.1818 time: 0.0182s\n",
            "Epoch: 0529 loss_train: 5277051.0000 acc_train: 0.0811 time: 0.0181s\n",
            "Epoch: 0530 loss_train: 5001386.5000 acc_train: 0.0839 time: 0.0181s\n",
            "Epoch: 0531 loss_train: 4696327.5000 acc_train: 0.0814 time: 0.0179s\n",
            "Epoch: 0532 loss_train: 5137785.0000 acc_train: 0.0941 time: 0.0178s\n",
            "Epoch: 0533 loss_train: 2992578.5000 acc_train: 0.0931 time: 0.0180s\n",
            "Epoch: 0534 loss_train: 2727295.2500 acc_train: 0.1056 time: 0.0178s\n",
            "Epoch: 0535 loss_train: 3658549.7500 acc_train: 0.1795 time: 0.0179s\n",
            "Epoch: 0536 loss_train: 6088186.0000 acc_train: 0.1105 time: 0.0179s\n",
            "Epoch: 0537 loss_train: 3813509.5000 acc_train: 0.1015 time: 0.0179s\n",
            "Epoch: 0538 loss_train: 5564369.0000 acc_train: 0.0633 time: 0.0182s\n",
            "Epoch: 0539 loss_train: 5845175.0000 acc_train: 0.0797 time: 0.0186s\n",
            "Epoch: 0540 loss_train: 7453383.5000 acc_train: 0.0830 time: 0.0189s\n",
            "Epoch: 0541 loss_train: 8810559.0000 acc_train: 0.0815 time: 0.0184s\n",
            "Epoch: 0542 loss_train: 6630754.5000 acc_train: 0.1108 time: 0.0182s\n",
            "Epoch: 0543 loss_train: 6980093.5000 acc_train: 0.1823 time: 0.0179s\n",
            "Epoch: 0544 loss_train: 6306745.0000 acc_train: 0.1187 time: 0.0178s\n",
            "Epoch: 0545 loss_train: 5513629.0000 acc_train: 0.0854 time: 0.0179s\n",
            "Epoch: 0546 loss_train: 6712147.0000 acc_train: 0.0813 time: 0.0179s\n",
            "Epoch: 0547 loss_train: 7328933.5000 acc_train: 0.0982 time: 0.0179s\n",
            "Epoch: 0548 loss_train: 6775399.0000 acc_train: 0.1801 time: 0.0180s\n",
            "Epoch: 0549 loss_train: 6711697.5000 acc_train: 0.1100 time: 0.0181s\n",
            "Epoch: 0550 loss_train: 5060054.0000 acc_train: 0.1429 time: 0.0179s\n",
            "Epoch: 0551 loss_train: 5015384.0000 acc_train: 0.1023 time: 0.0178s\n",
            "Epoch: 0552 loss_train: 2828378.2500 acc_train: 0.0795 time: 0.0179s\n",
            "Epoch: 0553 loss_train: 10840758.0000 acc_train: 0.1011 time: 0.0178s\n",
            "Epoch: 0554 loss_train: 7443633.5000 acc_train: 0.0872 time: 0.0178s\n",
            "Epoch: 0555 loss_train: 9030732.0000 acc_train: 0.1097 time: 0.0179s\n",
            "Epoch: 0556 loss_train: 10261790.0000 acc_train: 0.0839 time: 0.0180s\n",
            "Epoch: 0557 loss_train: 7227526.0000 acc_train: 0.0904 time: 0.0185s\n",
            "Epoch: 0558 loss_train: 6813004.0000 acc_train: 0.1276 time: 0.0189s\n",
            "Epoch: 0559 loss_train: 7947582.0000 acc_train: 0.1637 time: 0.0189s\n",
            "Epoch: 0560 loss_train: 7394420.5000 acc_train: 0.1068 time: 0.0188s\n",
            "Epoch: 0561 loss_train: 5487869.5000 acc_train: 0.1802 time: 0.0185s\n",
            "Epoch: 0562 loss_train: 4605672.5000 acc_train: 0.1086 time: 0.0182s\n",
            "Epoch: 0563 loss_train: 7661476.5000 acc_train: 0.0996 time: 0.0180s\n",
            "Epoch: 0564 loss_train: 7199837.5000 acc_train: 0.0827 time: 0.0180s\n",
            "Epoch: 0565 loss_train: 7116420.0000 acc_train: 0.0677 time: 0.0183s\n",
            "Epoch: 0566 loss_train: 7630246.0000 acc_train: 0.0810 time: 0.0183s\n",
            "Epoch: 0567 loss_train: 5578610.5000 acc_train: 0.0749 time: 0.0183s\n",
            "Epoch: 0568 loss_train: 5387502.5000 acc_train: 0.0873 time: 0.0183s\n",
            "Epoch: 0569 loss_train: 6625738.5000 acc_train: 0.1161 time: 0.0183s\n",
            "Epoch: 0570 loss_train: 6389168.5000 acc_train: 0.1003 time: 0.0184s\n",
            "Epoch: 0571 loss_train: 8284265.5000 acc_train: 0.1878 time: 0.0183s\n",
            "Epoch: 0572 loss_train: 7126154.5000 acc_train: 0.1874 time: 0.0182s\n",
            "Epoch: 0573 loss_train: 5315153.5000 acc_train: 0.0958 time: 0.0181s\n",
            "Epoch: 0574 loss_train: 5368063.0000 acc_train: 0.0975 time: 0.0180s\n",
            "Epoch: 0575 loss_train: 6231264.0000 acc_train: 0.1008 time: 0.0182s\n",
            "Epoch: 0576 loss_train: 5886349.0000 acc_train: 0.0827 time: 0.0185s\n",
            "Epoch: 0577 loss_train: 6456560.0000 acc_train: 0.0825 time: 0.0186s\n",
            "Epoch: 0578 loss_train: 6464720.5000 acc_train: 0.0968 time: 0.0184s\n",
            "Epoch: 0579 loss_train: 4797400.5000 acc_train: 0.0900 time: 0.0186s\n",
            "Epoch: 0580 loss_train: 6108596.0000 acc_train: 0.1864 time: 0.0189s\n",
            "Epoch: 0581 loss_train: 5082360.5000 acc_train: 0.1518 time: 0.0189s\n",
            "Epoch: 0582 loss_train: 5107957.0000 acc_train: 0.0963 time: 0.0190s\n",
            "Epoch: 0583 loss_train: 3999849.5000 acc_train: 0.1066 time: 0.0189s\n",
            "Epoch: 0584 loss_train: 2559089.5000 acc_train: 0.0938 time: 0.0187s\n",
            "Epoch: 0585 loss_train: 3873646.5000 acc_train: 0.0918 time: 0.0182s\n",
            "Epoch: 0586 loss_train: 4419331.5000 acc_train: 0.0839 time: 0.0181s\n",
            "Epoch: 0587 loss_train: 4762646.0000 acc_train: 0.0786 time: 0.0181s\n",
            "Epoch: 0588 loss_train: 5618961.0000 acc_train: 0.0649 time: 0.0182s\n",
            "Epoch: 0589 loss_train: 4544030.5000 acc_train: 0.0647 time: 0.0181s\n",
            "Epoch: 0590 loss_train: 6045441.5000 acc_train: 0.1874 time: 0.0180s\n",
            "Epoch: 0591 loss_train: 5426808.5000 acc_train: 0.1872 time: 0.0181s\n",
            "Epoch: 0592 loss_train: 5143876.5000 acc_train: 0.0961 time: 0.0180s\n",
            "Epoch: 0593 loss_train: 4203083.0000 acc_train: 0.1038 time: 0.0184s\n",
            "Epoch: 0594 loss_train: 4489603.0000 acc_train: 0.0864 time: 0.0182s\n",
            "Epoch: 0595 loss_train: 6262265.5000 acc_train: 0.0861 time: 0.0179s\n",
            "Epoch: 0596 loss_train: 5926880.0000 acc_train: 0.0852 time: 0.0179s\n",
            "Epoch: 0597 loss_train: 7102381.0000 acc_train: 0.0956 time: 0.0181s\n",
            "Epoch: 0598 loss_train: 5548425.5000 acc_train: 0.0946 time: 0.0182s\n",
            "Epoch: 0599 loss_train: 6353413.5000 acc_train: 0.1106 time: 0.0181s\n",
            "Epoch: 0600 loss_train: 4639173.5000 acc_train: 0.1731 time: 0.0180s\n",
            "Epoch: 0601 loss_train: 5503605.0000 acc_train: 0.1739 time: 0.0180s\n",
            "Epoch: 0602 loss_train: 7765797.0000 acc_train: 0.0959 time: 0.0184s\n",
            "Epoch: 0603 loss_train: 8065128.5000 acc_train: 0.0889 time: 0.0181s\n",
            "Epoch: 0604 loss_train: 7220477.0000 acc_train: 0.0977 time: 0.0178s\n",
            "Epoch: 0605 loss_train: 6801394.5000 acc_train: 0.0909 time: 0.0181s\n",
            "Epoch: 0606 loss_train: 5145097.5000 acc_train: 0.0698 time: 0.0179s\n",
            "Epoch: 0607 loss_train: 5304025.5000 acc_train: 0.0866 time: 0.0178s\n",
            "Epoch: 0608 loss_train: 5095555.5000 acc_train: 0.1201 time: 0.0178s\n",
            "Epoch: 0609 loss_train: 6839533.0000 acc_train: 0.1868 time: 0.0178s\n",
            "Epoch: 0610 loss_train: 6065106.0000 acc_train: 0.1573 time: 0.0180s\n",
            "Epoch: 0611 loss_train: 7184877.0000 acc_train: 0.0795 time: 0.0186s\n",
            "Epoch: 0612 loss_train: 6921508.5000 acc_train: 0.0742 time: 0.0190s\n",
            "Epoch: 0613 loss_train: 7087885.5000 acc_train: 0.0834 time: 0.0186s\n",
            "Epoch: 0614 loss_train: 6596467.5000 acc_train: 0.0897 time: 0.0183s\n",
            "Epoch: 0615 loss_train: 6509384.0000 acc_train: 0.0962 time: 0.0182s\n",
            "Epoch: 0616 loss_train: 5284335.0000 acc_train: 0.1091 time: 0.0182s\n",
            "Epoch: 0617 loss_train: 3753446.2500 acc_train: 0.0961 time: 0.0181s\n",
            "Epoch: 0618 loss_train: 5432543.5000 acc_train: 0.0814 time: 0.0183s\n",
            "Epoch: 0619 loss_train: 3083061.0000 acc_train: 0.0834 time: 0.0183s\n",
            "Epoch: 0620 loss_train: 4057467.2500 acc_train: 0.1809 time: 0.0183s\n",
            "Epoch: 0621 loss_train: 5842123.0000 acc_train: 0.0929 time: 0.0184s\n",
            "Epoch: 0622 loss_train: 6676590.5000 acc_train: 0.1005 time: 0.0184s\n",
            "Epoch: 0623 loss_train: 4739700.5000 acc_train: 0.1833 time: 0.0184s\n",
            "Epoch: 0624 loss_train: 3368442.7500 acc_train: 0.1572 time: 0.0189s\n",
            "Epoch: 0625 loss_train: 5061345.5000 acc_train: 0.0919 time: 0.0188s\n",
            "Epoch: 0626 loss_train: 5678186.0000 acc_train: 0.0816 time: 0.0184s\n",
            "Epoch: 0627 loss_train: 6601852.0000 acc_train: 0.0783 time: 0.0183s\n",
            "Epoch: 0628 loss_train: 6792601.0000 acc_train: 0.0836 time: 0.0179s\n",
            "Epoch: 0629 loss_train: 7831848.0000 acc_train: 0.0962 time: 0.0179s\n",
            "Epoch: 0630 loss_train: 5949326.5000 acc_train: 0.0960 time: 0.0180s\n",
            "Epoch: 0631 loss_train: 5799544.5000 acc_train: 0.1102 time: 0.0182s\n",
            "Epoch: 0632 loss_train: 7077695.0000 acc_train: 0.1011 time: 0.0181s\n",
            "Epoch: 0633 loss_train: 5349678.5000 acc_train: 0.1093 time: 0.0181s\n",
            "Epoch: 0634 loss_train: 7713074.0000 acc_train: 0.1869 time: 0.0181s\n",
            "Epoch: 0635 loss_train: 7722833.5000 acc_train: 0.1776 time: 0.0179s\n",
            "Epoch: 0636 loss_train: 9074055.0000 acc_train: 0.0829 time: 0.0178s\n",
            "Epoch: 0637 loss_train: 9458280.0000 acc_train: 0.0867 time: 0.0179s\n",
            "Epoch: 0638 loss_train: 9222970.0000 acc_train: 0.1022 time: 0.0179s\n",
            "Epoch: 0639 loss_train: 8686620.0000 acc_train: 0.0845 time: 0.0180s\n",
            "Epoch: 0640 loss_train: 6967413.5000 acc_train: 0.0758 time: 0.0180s\n",
            "Epoch: 0641 loss_train: 8916681.0000 acc_train: 0.0862 time: 0.0180s\n",
            "Epoch: 0642 loss_train: 7178941.0000 acc_train: 0.0770 time: 0.0180s\n",
            "Epoch: 0643 loss_train: 8648593.0000 acc_train: 0.0985 time: 0.0185s\n",
            "Epoch: 0644 loss_train: 7948816.0000 acc_train: 0.1840 time: 0.0189s\n",
            "Epoch: 0645 loss_train: 8200712.5000 acc_train: 0.1874 time: 0.0186s\n",
            "Epoch: 0646 loss_train: 6888695.0000 acc_train: 0.0694 time: 0.0183s\n",
            "Epoch: 0647 loss_train: 9452186.0000 acc_train: 0.0818 time: 0.0183s\n",
            "Epoch: 0648 loss_train: 8813152.0000 acc_train: 0.0816 time: 0.0181s\n",
            "Epoch: 0649 loss_train: 6197417.5000 acc_train: 0.1099 time: 0.0180s\n",
            "Epoch: 0650 loss_train: 5448056.0000 acc_train: 0.1001 time: 0.0178s\n",
            "Epoch: 0651 loss_train: 2991205.2500 acc_train: 0.1018 time: 0.0178s\n",
            "Epoch: 0652 loss_train: 3818908.2500 acc_train: 0.0990 time: 0.0179s\n",
            "Epoch: 0653 loss_train: 3850295.7500 acc_train: 0.1076 time: 0.0184s\n",
            "Epoch: 0654 loss_train: 5613256.5000 acc_train: 0.1863 time: 0.0186s\n",
            "Epoch: 0655 loss_train: 8377632.0000 acc_train: 0.0855 time: 0.0184s\n",
            "Epoch: 0656 loss_train: 6177417.5000 acc_train: 0.0871 time: 0.0181s\n",
            "Epoch: 0657 loss_train: 6984734.0000 acc_train: 0.1021 time: 0.0180s\n",
            "Epoch: 0658 loss_train: 6768005.5000 acc_train: 0.1106 time: 0.0179s\n",
            "Epoch: 0659 loss_train: 7508888.0000 acc_train: 0.1870 time: 0.0178s\n",
            "Epoch: 0660 loss_train: 7339294.5000 acc_train: 0.1118 time: 0.0178s\n",
            "Epoch: 0661 loss_train: 7456543.0000 acc_train: 0.0913 time: 0.0179s\n",
            "Epoch: 0662 loss_train: 8750592.0000 acc_train: 0.0775 time: 0.0180s\n",
            "Epoch: 0663 loss_train: 8927803.0000 acc_train: 0.0567 time: 0.0183s\n",
            "Epoch: 0664 loss_train: 7495190.0000 acc_train: 0.0716 time: 0.0185s\n",
            "Epoch: 0665 loss_train: 6066894.5000 acc_train: 0.1054 time: 0.0182s\n",
            "Epoch: 0666 loss_train: 7145712.0000 acc_train: 0.1860 time: 0.0181s\n",
            "Epoch: 0667 loss_train: 6186370.5000 acc_train: 0.1437 time: 0.0179s\n",
            "Epoch: 0668 loss_train: 5932779.5000 acc_train: 0.1056 time: 0.0181s\n",
            "Epoch: 0669 loss_train: 5796171.0000 acc_train: 0.0998 time: 0.0182s\n",
            "Epoch: 0670 loss_train: 7548064.0000 acc_train: 0.1106 time: 0.0181s\n",
            "Epoch: 0671 loss_train: 6264927.5000 acc_train: 0.0943 time: 0.0180s\n",
            "Epoch: 0672 loss_train: 7276806.0000 acc_train: 0.0814 time: 0.0180s\n",
            "Epoch: 0673 loss_train: 5219683.5000 acc_train: 0.0887 time: 0.0184s\n",
            "Epoch: 0674 loss_train: 6516962.5000 acc_train: 0.0839 time: 0.0189s\n",
            "Epoch: 0675 loss_train: 7094295.0000 acc_train: 0.1633 time: 0.0187s\n",
            "Epoch: 0676 loss_train: 8697574.0000 acc_train: 0.0991 time: 0.0186s\n",
            "Epoch: 0677 loss_train: 7051320.0000 acc_train: 0.1734 time: 0.0185s\n",
            "Epoch: 0678 loss_train: 5174283.5000 acc_train: 0.1231 time: 0.0181s\n",
            "Epoch: 0679 loss_train: 6016078.5000 acc_train: 0.0839 time: 0.0179s\n",
            "Epoch: 0680 loss_train: 7180328.5000 acc_train: 0.0973 time: 0.0178s\n",
            "Epoch: 0681 loss_train: 8351980.5000 acc_train: 0.0923 time: 0.0178s\n",
            "Epoch: 0682 loss_train: 8983922.0000 acc_train: 0.0971 time: 0.0179s\n",
            "Epoch: 0683 loss_train: 8874346.0000 acc_train: 0.1013 time: 0.0182s\n",
            "Epoch: 0684 loss_train: 5928090.0000 acc_train: 0.1088 time: 0.0187s\n",
            "Epoch: 0685 loss_train: 6929531.5000 acc_train: 0.1875 time: 0.0185s\n",
            "Epoch: 0686 loss_train: 6985595.0000 acc_train: 0.1854 time: 0.0184s\n",
            "Epoch: 0687 loss_train: 7809296.5000 acc_train: 0.0832 time: 0.0183s\n",
            "Epoch: 0688 loss_train: 9737764.0000 acc_train: 0.1057 time: 0.0179s\n",
            "Epoch: 0689 loss_train: 10248657.0000 acc_train: 0.1130 time: 0.0179s\n",
            "Epoch: 0690 loss_train: 9699709.0000 acc_train: 0.0962 time: 0.0178s\n",
            "Epoch: 0691 loss_train: 8350078.0000 acc_train: 0.0882 time: 0.0178s\n",
            "Epoch: 0692 loss_train: 7140200.0000 acc_train: 0.0687 time: 0.0178s\n",
            "Epoch: 0693 loss_train: 6644362.0000 acc_train: 0.0916 time: 0.0182s\n",
            "Epoch: 0694 loss_train: 5348164.5000 acc_train: 0.0604 time: 0.0184s\n",
            "Epoch: 0695 loss_train: 4956197.0000 acc_train: 0.1817 time: 0.0182s\n",
            "Epoch: 0696 loss_train: 5342214.5000 acc_train: 0.0867 time: 0.0184s\n",
            "Epoch: 0697 loss_train: 7179960.5000 acc_train: 0.0821 time: 0.0183s\n",
            "Epoch: 0698 loss_train: 6557774.0000 acc_train: 0.0870 time: 0.0182s\n",
            "Epoch: 0699 loss_train: 6132162.0000 acc_train: 0.1871 time: 0.0182s\n",
            "Epoch: 0700 loss_train: 5767775.5000 acc_train: 0.1028 time: 0.0182s\n",
            "Epoch: 0701 loss_train: 4974768.0000 acc_train: 0.0981 time: 0.0181s\n",
            "Epoch: 0702 loss_train: 4431212.5000 acc_train: 0.1098 time: 0.0181s\n",
            "Epoch: 0703 loss_train: 3930125.7500 acc_train: 0.1820 time: 0.0185s\n",
            "Epoch: 0704 loss_train: 6111023.5000 acc_train: 0.1019 time: 0.0187s\n",
            "Epoch: 0705 loss_train: 7359830.0000 acc_train: 0.1103 time: 0.0187s\n",
            "Epoch: 0706 loss_train: 4886726.5000 acc_train: 0.1102 time: 0.0186s\n",
            "Epoch: 0707 loss_train: 6140346.5000 acc_train: 0.0975 time: 0.0183s\n",
            "Epoch: 0708 loss_train: 4619487.5000 acc_train: 0.0895 time: 0.0184s\n",
            "Epoch: 0709 loss_train: 6259537.5000 acc_train: 0.0933 time: 0.0182s\n",
            "Epoch: 0710 loss_train: 6910815.0000 acc_train: 0.0812 time: 0.0180s\n",
            "Epoch: 0711 loss_train: 5839083.0000 acc_train: 0.0647 time: 0.0180s\n",
            "Epoch: 0712 loss_train: 4838277.5000 acc_train: 0.1030 time: 0.0180s\n",
            "Epoch: 0713 loss_train: 6296140.0000 acc_train: 0.1871 time: 0.0181s\n",
            "Epoch: 0714 loss_train: 5729330.0000 acc_train: 0.1856 time: 0.0182s\n",
            "Epoch: 0715 loss_train: 6358447.5000 acc_train: 0.0944 time: 0.0182s\n",
            "Epoch: 0716 loss_train: 6999975.0000 acc_train: 0.0954 time: 0.0180s\n",
            "Epoch: 0717 loss_train: 7600554.5000 acc_train: 0.0861 time: 0.0179s\n",
            "Epoch: 0718 loss_train: 6002402.5000 acc_train: 0.0913 time: 0.0179s\n",
            "Epoch: 0719 loss_train: 5434079.5000 acc_train: 0.0652 time: 0.0181s\n",
            "Epoch: 0720 loss_train: 5275006.0000 acc_train: 0.0951 time: 0.0191s\n",
            "Epoch: 0721 loss_train: 4471427.5000 acc_train: 0.0835 time: 0.0180s\n",
            "Epoch: 0722 loss_train: 2687569.2500 acc_train: 0.1556 time: 0.0179s\n",
            "Epoch: 0723 loss_train: 3041760.0000 acc_train: 0.1087 time: 0.0179s\n",
            "Epoch: 0724 loss_train: 4514642.0000 acc_train: 0.1044 time: 0.0180s\n",
            "Epoch: 0725 loss_train: 3944558.2500 acc_train: 0.1006 time: 0.0183s\n",
            "Epoch: 0726 loss_train: 4552249.0000 acc_train: 0.1295 time: 0.0184s\n",
            "Epoch: 0727 loss_train: 5398309.5000 acc_train: 0.1869 time: 0.0184s\n",
            "Epoch: 0728 loss_train: 4117861.5000 acc_train: 0.1284 time: 0.0183s\n",
            "Epoch: 0729 loss_train: 3160948.2500 acc_train: 0.1863 time: 0.0183s\n",
            "Epoch: 0730 loss_train: 3024160.7500 acc_train: 0.0953 time: 0.0180s\n",
            "Epoch: 0731 loss_train: 4261483.0000 acc_train: 0.0844 time: 0.0182s\n",
            "Epoch: 0732 loss_train: 3623111.2500 acc_train: 0.0868 time: 0.0179s\n",
            "Epoch: 0733 loss_train: 3971750.0000 acc_train: 0.1077 time: 0.0179s\n",
            "Epoch: 0734 loss_train: 5048184.5000 acc_train: 0.0841 time: 0.0179s\n",
            "Epoch: 0735 loss_train: 4977000.0000 acc_train: 0.0816 time: 0.0178s\n",
            "Epoch: 0736 loss_train: 4116787.5000 acc_train: 0.0719 time: 0.0179s\n",
            "Epoch: 0737 loss_train: 4257593.5000 acc_train: 0.0943 time: 0.0181s\n",
            "Epoch: 0738 loss_train: 4632761.0000 acc_train: 0.0866 time: 0.0182s\n",
            "Epoch: 0739 loss_train: 4090481.0000 acc_train: 0.1092 time: 0.0180s\n",
            "Epoch: 0740 loss_train: 2636501.2500 acc_train: 0.0986 time: 0.0179s\n",
            "Epoch: 0741 loss_train: 3768240.7500 acc_train: 0.1350 time: 0.0179s\n",
            "Epoch: 0742 loss_train: 4892276.5000 acc_train: 0.1783 time: 0.0185s\n",
            "Epoch: 0743 loss_train: 6836757.5000 acc_train: 0.1013 time: 0.0180s\n",
            "Epoch: 0744 loss_train: 5549083.5000 acc_train: 0.0958 time: 0.0179s\n",
            "Epoch: 0745 loss_train: 4072252.0000 acc_train: 0.1769 time: 0.0179s\n",
            "Epoch: 0746 loss_train: 4117621.7500 acc_train: 0.0921 time: 0.0180s\n",
            "Epoch: 0747 loss_train: 3708564.7500 acc_train: 0.0778 time: 0.0185s\n",
            "Epoch: 0748 loss_train: 3071740.0000 acc_train: 0.0690 time: 0.0182s\n",
            "Epoch: 0749 loss_train: 3429842.0000 acc_train: 0.0988 time: 0.0181s\n",
            "Epoch: 0750 loss_train: 4342039.5000 acc_train: 0.1262 time: 0.0179s\n",
            "Epoch: 0751 loss_train: 5347099.0000 acc_train: 0.1541 time: 0.0179s\n",
            "Epoch: 0752 loss_train: 5474091.0000 acc_train: 0.1018 time: 0.0180s\n",
            "Epoch: 0753 loss_train: 4338003.0000 acc_train: 0.0912 time: 0.0181s\n",
            "Epoch: 0754 loss_train: 4206524.0000 acc_train: 0.0947 time: 0.0180s\n",
            "Epoch: 0755 loss_train: 4401299.5000 acc_train: 0.0912 time: 0.0180s\n",
            "Epoch: 0756 loss_train: 4481813.5000 acc_train: 0.1748 time: 0.0185s\n",
            "Epoch: 0757 loss_train: 4896957.0000 acc_train: 0.0777 time: 0.0192s\n",
            "Epoch: 0758 loss_train: 4003207.5000 acc_train: 0.0976 time: 0.0187s\n",
            "Epoch: 0759 loss_train: 3111348.0000 acc_train: 0.0912 time: 0.0184s\n",
            "Epoch: 0760 loss_train: 3342308.0000 acc_train: 0.0696 time: 0.0182s\n",
            "Epoch: 0761 loss_train: 3532582.7500 acc_train: 0.0911 time: 0.0181s\n",
            "Epoch: 0762 loss_train: 3727037.5000 acc_train: 0.1080 time: 0.0177s\n",
            "Epoch: 0763 loss_train: 4497268.0000 acc_train: 0.1852 time: 0.0179s\n",
            "Epoch: 0764 loss_train: 3781157.5000 acc_train: 0.0978 time: 0.0179s\n",
            "Epoch: 0765 loss_train: 3331138.2500 acc_train: 0.0848 time: 0.0180s\n",
            "Epoch: 0766 loss_train: 5017687.0000 acc_train: 0.1018 time: 0.0181s\n",
            "Epoch: 0767 loss_train: 3817218.0000 acc_train: 0.0945 time: 0.0183s\n",
            "Epoch: 0768 loss_train: 3251624.5000 acc_train: 0.1237 time: 0.0184s\n",
            "Epoch: 0769 loss_train: 4400059.0000 acc_train: 0.1835 time: 0.0183s\n",
            "Epoch: 0770 loss_train: 2694848.0000 acc_train: 0.0869 time: 0.0180s\n",
            "Epoch: 0771 loss_train: 2790643.5000 acc_train: 0.0982 time: 0.0180s\n",
            "Epoch: 0772 loss_train: 2035693.6250 acc_train: 0.0850 time: 0.0180s\n",
            "Epoch: 0773 loss_train: 3199652.5000 acc_train: 0.0767 time: 0.0182s\n",
            "Epoch: 0774 loss_train: 4081716.7500 acc_train: 0.0956 time: 0.0181s\n",
            "Epoch: 0775 loss_train: 3862863.0000 acc_train: 0.1822 time: 0.0179s\n",
            "Epoch: 0776 loss_train: 3821305.5000 acc_train: 0.0922 time: 0.0180s\n",
            "Epoch: 0777 loss_train: 5349546.0000 acc_train: 0.0959 time: 0.0183s\n",
            "Epoch: 0778 loss_train: 6255190.0000 acc_train: 0.0994 time: 0.0190s\n",
            "Epoch: 0779 loss_train: 4299427.5000 acc_train: 0.1655 time: 0.0189s\n",
            "Epoch: 0780 loss_train: 5590173.0000 acc_train: 0.1089 time: 0.0185s\n",
            "Epoch: 0781 loss_train: 3887868.7500 acc_train: 0.0916 time: 0.0182s\n",
            "Epoch: 0782 loss_train: 4239673.0000 acc_train: 0.0781 time: 0.0183s\n",
            "Epoch: 0783 loss_train: 3880180.2500 acc_train: 0.0940 time: 0.0181s\n",
            "Epoch: 0784 loss_train: 4794334.5000 acc_train: 0.0867 time: 0.0183s\n",
            "Epoch: 0785 loss_train: 4883671.5000 acc_train: 0.0872 time: 0.0183s\n",
            "Epoch: 0786 loss_train: 5139398.0000 acc_train: 0.1871 time: 0.0189s\n",
            "Epoch: 0787 loss_train: 4017668.7500 acc_train: 0.1486 time: 0.0183s\n",
            "Epoch: 0788 loss_train: 3649696.0000 acc_train: 0.0925 time: 0.0182s\n",
            "Epoch: 0789 loss_train: 5614711.5000 acc_train: 0.0811 time: 0.0185s\n",
            "Epoch: 0790 loss_train: 3760810.5000 acc_train: 0.0971 time: 0.0188s\n",
            "Epoch: 0791 loss_train: 4209307.0000 acc_train: 0.0891 time: 0.0190s\n",
            "Epoch: 0792 loss_train: 3504073.5000 acc_train: 0.0650 time: 0.0184s\n",
            "Epoch: 0793 loss_train: 3726393.5000 acc_train: 0.1249 time: 0.0182s\n",
            "Epoch: 0794 loss_train: 3403037.2500 acc_train: 0.1809 time: 0.0181s\n",
            "Epoch: 0795 loss_train: 4699137.5000 acc_train: 0.0987 time: 0.0179s\n",
            "Epoch: 0796 loss_train: 5660393.5000 acc_train: 0.0844 time: 0.0179s\n",
            "Epoch: 0797 loss_train: 4656216.0000 acc_train: 0.0954 time: 0.0179s\n",
            "Epoch: 0798 loss_train: 3678945.2500 acc_train: 0.0952 time: 0.0180s\n",
            "Epoch: 0799 loss_train: 4930695.0000 acc_train: 0.0846 time: 0.0182s\n",
            "Epoch: 0800 loss_train: 4095805.2500 acc_train: 0.1089 time: 0.0181s\n",
            "Epoch: 0801 loss_train: 4823720.5000 acc_train: 0.1808 time: 0.0184s\n",
            "Epoch: 0802 loss_train: 6207644.5000 acc_train: 0.1041 time: 0.0181s\n",
            "Epoch: 0803 loss_train: 5218860.0000 acc_train: 0.1037 time: 0.0182s\n",
            "Epoch: 0804 loss_train: 5482528.0000 acc_train: 0.1772 time: 0.0182s\n",
            "Epoch: 0805 loss_train: 5536430.0000 acc_train: 0.0902 time: 0.0184s\n",
            "Epoch: 0806 loss_train: 3787938.0000 acc_train: 0.0979 time: 0.0185s\n",
            "Epoch: 0807 loss_train: 5859014.0000 acc_train: 0.1103 time: 0.0185s\n",
            "Epoch: 0808 loss_train: 4332255.5000 acc_train: 0.1076 time: 0.0185s\n",
            "Epoch: 0809 loss_train: 3884641.2500 acc_train: 0.0857 time: 0.0186s\n",
            "Epoch: 0810 loss_train: 4721781.0000 acc_train: 0.1018 time: 0.0188s\n",
            "Epoch: 0811 loss_train: 4102169.0000 acc_train: 0.1015 time: 0.0189s\n",
            "Epoch: 0812 loss_train: 4901035.5000 acc_train: 0.1122 time: 0.0188s\n",
            "Epoch: 0813 loss_train: 6511892.0000 acc_train: 0.0872 time: 0.0188s\n",
            "Epoch: 0814 loss_train: 6423577.5000 acc_train: 0.1875 time: 0.0186s\n",
            "Epoch: 0815 loss_train: 5367717.0000 acc_train: 0.1266 time: 0.0182s\n",
            "Epoch: 0816 loss_train: 4386463.0000 acc_train: 0.0839 time: 0.0180s\n",
            "Epoch: 0817 loss_train: 4689950.0000 acc_train: 0.0694 time: 0.0181s\n",
            "Epoch: 0818 loss_train: 4737139.0000 acc_train: 0.0867 time: 0.0178s\n",
            "Epoch: 0819 loss_train: 4410672.5000 acc_train: 0.0903 time: 0.0178s\n",
            "Epoch: 0820 loss_train: 4749454.0000 acc_train: 0.1874 time: 0.0179s\n",
            "Epoch: 0821 loss_train: 4451501.0000 acc_train: 0.1064 time: 0.0180s\n",
            "Epoch: 0822 loss_train: 4466846.5000 acc_train: 0.1022 time: 0.0180s\n",
            "Epoch: 0823 loss_train: 4747717.5000 acc_train: 0.0919 time: 0.0180s\n",
            "Epoch: 0824 loss_train: 4170869.0000 acc_train: 0.1452 time: 0.0182s\n",
            "Epoch: 0825 loss_train: 3636455.2500 acc_train: 0.1831 time: 0.0181s\n",
            "Epoch: 0826 loss_train: 2660818.5000 acc_train: 0.0712 time: 0.0179s\n",
            "Epoch: 0827 loss_train: 2817070.5000 acc_train: 0.1080 time: 0.0180s\n",
            "Epoch: 0828 loss_train: 2931068.7500 acc_train: 0.0884 time: 0.0181s\n",
            "Epoch: 0829 loss_train: 2577117.2500 acc_train: 0.0941 time: 0.0181s\n",
            "Epoch: 0830 loss_train: 3093930.0000 acc_train: 0.0892 time: 0.0181s\n",
            "Epoch: 0831 loss_train: 3085040.2500 acc_train: 0.1047 time: 0.0180s\n",
            "Epoch: 0832 loss_train: 3117799.0000 acc_train: 0.1000 time: 0.0182s\n",
            "Epoch: 0833 loss_train: 2971815.2500 acc_train: 0.0945 time: 0.0185s\n",
            "Epoch: 0834 loss_train: 1504393.1250 acc_train: 0.1170 time: 0.0182s\n",
            "Epoch: 0835 loss_train: 2373911.5000 acc_train: 0.1436 time: 0.0180s\n",
            "Epoch: 0836 loss_train: 2586950.5000 acc_train: 0.0970 time: 0.0181s\n",
            "Epoch: 0837 loss_train: 2422849.0000 acc_train: 0.1030 time: 0.0180s\n",
            "Epoch: 0838 loss_train: 2097186.2500 acc_train: 0.0976 time: 0.0178s\n",
            "Epoch: 0839 loss_train: 1934699.1250 acc_train: 0.1661 time: 0.0179s\n",
            "Epoch: 0840 loss_train: 3530866.7500 acc_train: 0.0827 time: 0.0178s\n",
            "Epoch: 0841 loss_train: 4378657.0000 acc_train: 0.0941 time: 0.0178s\n",
            "Epoch: 0842 loss_train: 3861862.2500 acc_train: 0.0809 time: 0.0183s\n",
            "Epoch: 0843 loss_train: 3774150.2500 acc_train: 0.0930 time: 0.0187s\n",
            "Epoch: 0844 loss_train: 2937030.5000 acc_train: 0.1074 time: 0.0184s\n",
            "Epoch: 0845 loss_train: 3179962.7500 acc_train: 0.1050 time: 0.0182s\n",
            "Epoch: 0846 loss_train: 3280646.5000 acc_train: 0.1874 time: 0.0180s\n",
            "Epoch: 0847 loss_train: 2888550.7500 acc_train: 0.1866 time: 0.0187s\n",
            "Epoch: 0848 loss_train: 4835352.5000 acc_train: 0.0986 time: 0.0179s\n",
            "Epoch: 0849 loss_train: 4621758.0000 acc_train: 0.0835 time: 0.0179s\n",
            "Epoch: 0850 loss_train: 3716388.7500 acc_train: 0.0835 time: 0.0179s\n",
            "Epoch: 0851 loss_train: 4563236.5000 acc_train: 0.0960 time: 0.0179s\n",
            "Epoch: 0852 loss_train: 3767874.5000 acc_train: 0.0952 time: 0.0179s\n",
            "Epoch: 0853 loss_train: 4330401.5000 acc_train: 0.0867 time: 0.0179s\n",
            "Epoch: 0854 loss_train: 3998508.2500 acc_train: 0.0909 time: 0.0183s\n",
            "Epoch: 0855 loss_train: 2269518.7500 acc_train: 0.0926 time: 0.0183s\n",
            "Epoch: 0856 loss_train: 3634417.2500 acc_train: 0.1534 time: 0.0184s\n",
            "Epoch: 0857 loss_train: 4239358.5000 acc_train: 0.1840 time: 0.0182s\n",
            "Epoch: 0858 loss_train: 3990640.2500 acc_train: 0.0720 time: 0.0182s\n",
            "Epoch: 0859 loss_train: 3347918.2500 acc_train: 0.0745 time: 0.0182s\n",
            "Epoch: 0860 loss_train: 3241075.2500 acc_train: 0.1064 time: 0.0181s\n",
            "Epoch: 0861 loss_train: 3555674.2500 acc_train: 0.0893 time: 0.0181s\n",
            "Epoch: 0862 loss_train: 3854734.7500 acc_train: 0.0881 time: 0.0183s\n",
            "Epoch: 0863 loss_train: 3983146.0000 acc_train: 0.0967 time: 0.0199s\n",
            "Epoch: 0864 loss_train: 2661901.0000 acc_train: 0.0989 time: 0.0191s\n",
            "Epoch: 0865 loss_train: 2902235.2500 acc_train: 0.1108 time: 0.0190s\n",
            "Epoch: 0866 loss_train: 2704826.5000 acc_train: 0.1078 time: 0.0191s\n",
            "Epoch: 0867 loss_train: 4419149.5000 acc_train: 0.1876 time: 0.0187s\n",
            "Epoch: 0868 loss_train: 4016652.2500 acc_train: 0.1833 time: 0.0184s\n",
            "Epoch: 0869 loss_train: 5166736.0000 acc_train: 0.0949 time: 0.0182s\n",
            "Epoch: 0870 loss_train: 5418462.5000 acc_train: 0.0830 time: 0.0179s\n",
            "Epoch: 0871 loss_train: 5559252.0000 acc_train: 0.0835 time: 0.0179s\n",
            "Epoch: 0872 loss_train: 3512477.5000 acc_train: 0.0687 time: 0.0179s\n",
            "Epoch: 0873 loss_train: 3506525.7500 acc_train: 0.0853 time: 0.0179s\n",
            "Epoch: 0874 loss_train: 2928632.2500 acc_train: 0.0764 time: 0.0180s\n",
            "Epoch: 0875 loss_train: 3035062.5000 acc_train: 0.0974 time: 0.0183s\n",
            "Epoch: 0876 loss_train: 2890002.2500 acc_train: 0.1476 time: 0.0186s\n",
            "Epoch: 0877 loss_train: 3691000.2500 acc_train: 0.1843 time: 0.0184s\n",
            "Epoch: 0878 loss_train: 3688198.5000 acc_train: 0.1015 time: 0.0184s\n",
            "Epoch: 0879 loss_train: 2949496.2500 acc_train: 0.0936 time: 0.0184s\n",
            "Epoch: 0880 loss_train: 2760365.5000 acc_train: 0.1077 time: 0.0180s\n",
            "Epoch: 0881 loss_train: 2473140.7500 acc_train: 0.0759 time: 0.0179s\n",
            "Epoch: 0882 loss_train: 1968566.5000 acc_train: 0.0881 time: 0.0180s\n",
            "Epoch: 0883 loss_train: 2476832.5000 acc_train: 0.1843 time: 0.0180s\n",
            "Epoch: 0884 loss_train: 3737081.2500 acc_train: 0.0875 time: 0.0181s\n",
            "Epoch: 0885 loss_train: 3518595.2500 acc_train: 0.0839 time: 0.0183s\n",
            "Epoch: 0886 loss_train: 3682504.7500 acc_train: 0.0931 time: 0.0182s\n",
            "Epoch: 0887 loss_train: 2797787.7500 acc_train: 0.0815 time: 0.0180s\n",
            "Epoch: 0888 loss_train: 3409382.2500 acc_train: 0.1046 time: 0.0179s\n",
            "Epoch: 0889 loss_train: 2537853.0000 acc_train: 0.0674 time: 0.0179s\n",
            "Epoch: 0890 loss_train: 2718047.7500 acc_train: 0.1316 time: 0.0181s\n",
            "Epoch: 0891 loss_train: 3363687.0000 acc_train: 0.1853 time: 0.0182s\n",
            "Epoch: 0892 loss_train: 3515195.7500 acc_train: 0.1049 time: 0.0181s\n",
            "Epoch: 0893 loss_train: 2886942.5000 acc_train: 0.1060 time: 0.0179s\n",
            "Epoch: 0894 loss_train: 2685368.7500 acc_train: 0.1126 time: 0.0180s\n",
            "Epoch: 0895 loss_train: 2923194.2500 acc_train: 0.1225 time: 0.0186s\n",
            "Epoch: 0896 loss_train: 3072266.0000 acc_train: 0.0954 time: 0.0190s\n",
            "Epoch: 0897 loss_train: 2590371.0000 acc_train: 0.0937 time: 0.0192s\n",
            "Epoch: 0898 loss_train: 3565453.2500 acc_train: 0.0901 time: 0.0187s\n",
            "Epoch: 0899 loss_train: 4394695.5000 acc_train: 0.0961 time: 0.0183s\n",
            "Epoch: 0900 loss_train: 4463421.0000 acc_train: 0.0903 time: 0.0182s\n",
            "Epoch: 0901 loss_train: 5488446.5000 acc_train: 0.1800 time: 0.0182s\n",
            "Epoch: 0902 loss_train: 6206495.5000 acc_train: 0.0884 time: 0.0183s\n",
            "Epoch: 0903 loss_train: 3728998.0000 acc_train: 0.1489 time: 0.0183s\n",
            "Epoch: 0904 loss_train: 3344057.2500 acc_train: 0.0844 time: 0.0183s\n",
            "Epoch: 0905 loss_train: 4434787.5000 acc_train: 0.0971 time: 0.0182s\n",
            "Epoch: 0906 loss_train: 2723976.2500 acc_train: 0.1140 time: 0.0180s\n",
            "Epoch: 0907 loss_train: 3782784.0000 acc_train: 0.1022 time: 0.0180s\n",
            "Epoch: 0908 loss_train: 3369488.7500 acc_train: 0.1095 time: 0.0182s\n",
            "Epoch: 0909 loss_train: 3182628.7500 acc_train: 0.1449 time: 0.0181s\n",
            "Epoch: 0910 loss_train: 3481667.7500 acc_train: 0.1630 time: 0.0182s\n",
            "Epoch: 0911 loss_train: 4728153.0000 acc_train: 0.0970 time: 0.0180s\n",
            "Epoch: 0912 loss_train: 3802195.5000 acc_train: 0.0836 time: 0.0183s\n",
            "Epoch: 0913 loss_train: 3296801.0000 acc_train: 0.0723 time: 0.0185s\n",
            "Epoch: 0914 loss_train: 3455270.2500 acc_train: 0.0842 time: 0.0185s\n",
            "Epoch: 0915 loss_train: 3735350.7500 acc_train: 0.1125 time: 0.0184s\n",
            "Epoch: 0916 loss_train: 3647024.2500 acc_train: 0.1857 time: 0.0186s\n",
            "Epoch: 0917 loss_train: 2845075.0000 acc_train: 0.0951 time: 0.0192s\n",
            "Epoch: 0918 loss_train: 2520753.0000 acc_train: 0.0837 time: 0.0191s\n",
            "Epoch: 0919 loss_train: 3225800.5000 acc_train: 0.0888 time: 0.0191s\n",
            "Epoch: 0920 loss_train: 3433012.0000 acc_train: 0.0976 time: 0.0193s\n",
            "Epoch: 0921 loss_train: 2943880.5000 acc_train: 0.1000 time: 0.0191s\n",
            "Epoch: 0922 loss_train: 3389903.7500 acc_train: 0.1078 time: 0.0187s\n",
            "Epoch: 0923 loss_train: 2924013.7500 acc_train: 0.1176 time: 0.0185s\n",
            "Epoch: 0924 loss_train: 4161579.7500 acc_train: 0.1246 time: 0.0180s\n",
            "Epoch: 0925 loss_train: 4544847.5000 acc_train: 0.1829 time: 0.0180s\n",
            "Epoch: 0926 loss_train: 4097474.2500 acc_train: 0.0932 time: 0.0179s\n",
            "Epoch: 0927 loss_train: 4030267.0000 acc_train: 0.0794 time: 0.0179s\n",
            "Epoch: 0928 loss_train: 4182092.0000 acc_train: 0.0652 time: 0.0180s\n",
            "Epoch: 0929 loss_train: 2529605.2500 acc_train: 0.1129 time: 0.0183s\n",
            "Epoch: 0930 loss_train: 2741715.7500 acc_train: 0.1861 time: 0.0187s\n",
            "Epoch: 0931 loss_train: 2858456.7500 acc_train: 0.0892 time: 0.0189s\n",
            "Epoch: 0932 loss_train: 3569931.5000 acc_train: 0.1089 time: 0.0186s\n",
            "Epoch: 0933 loss_train: 3764730.5000 acc_train: 0.0959 time: 0.0183s\n",
            "Epoch: 0934 loss_train: 4669369.5000 acc_train: 0.1011 time: 0.0180s\n",
            "Epoch: 0935 loss_train: 4864984.0000 acc_train: 0.0954 time: 0.0179s\n",
            "Epoch: 0936 loss_train: 2719984.7500 acc_train: 0.0934 time: 0.0182s\n",
            "Epoch: 0937 loss_train: 3975175.5000 acc_train: 0.1073 time: 0.0185s\n",
            "Epoch: 0938 loss_train: 4363347.0000 acc_train: 0.0813 time: 0.0186s\n",
            "Epoch: 0939 loss_train: 5379529.5000 acc_train: 0.1866 time: 0.0184s\n",
            "Epoch: 0940 loss_train: 6371975.0000 acc_train: 0.0859 time: 0.0185s\n",
            "Epoch: 0941 loss_train: 4285708.5000 acc_train: 0.1457 time: 0.0188s\n",
            "Epoch: 0942 loss_train: 3815788.2500 acc_train: 0.0748 time: 0.0188s\n",
            "Epoch: 0943 loss_train: 3397712.0000 acc_train: 0.0858 time: 0.0189s\n",
            "Epoch: 0944 loss_train: 3855121.0000 acc_train: 0.0789 time: 0.0184s\n",
            "Epoch: 0945 loss_train: 4341034.5000 acc_train: 0.0992 time: 0.0183s\n",
            "Epoch: 0946 loss_train: 3511906.7500 acc_train: 0.1870 time: 0.0182s\n",
            "Epoch: 0947 loss_train: 2754824.7500 acc_train: 0.1295 time: 0.0182s\n",
            "Epoch: 0948 loss_train: 3001398.0000 acc_train: 0.1003 time: 0.0182s\n",
            "Epoch: 0949 loss_train: 2875960.5000 acc_train: 0.0828 time: 0.0182s\n",
            "Epoch: 0950 loss_train: 3022224.2500 acc_train: 0.0703 time: 0.0182s\n",
            "Epoch: 0951 loss_train: 2592111.5000 acc_train: 0.0949 time: 0.0183s\n",
            "Epoch: 0952 loss_train: 2459467.7500 acc_train: 0.0955 time: 0.0185s\n",
            "Epoch: 0953 loss_train: 2336363.5000 acc_train: 0.1759 time: 0.0185s\n",
            "Epoch: 0954 loss_train: 3737393.2500 acc_train: 0.0842 time: 0.0188s\n",
            "Epoch: 0955 loss_train: 3040856.0000 acc_train: 0.0826 time: 0.0186s\n",
            "Epoch: 0956 loss_train: 2488980.5000 acc_train: 0.0837 time: 0.0183s\n",
            "Epoch: 0957 loss_train: 2783097.7500 acc_train: 0.1842 time: 0.0180s\n",
            "Epoch: 0958 loss_train: 3298973.7500 acc_train: 0.1016 time: 0.0178s\n",
            "Epoch: 0959 loss_train: 4602839.0000 acc_train: 0.0964 time: 0.0178s\n",
            "Epoch: 0960 loss_train: 3167233.0000 acc_train: 0.0989 time: 0.0179s\n",
            "Epoch: 0961 loss_train: 3153498.5000 acc_train: 0.0973 time: 0.0180s\n",
            "Epoch: 0962 loss_train: 2260059.0000 acc_train: 0.1726 time: 0.0181s\n",
            "Epoch: 0963 loss_train: 1803690.3750 acc_train: 0.0799 time: 0.0185s\n",
            "Epoch: 0964 loss_train: 2672511.2500 acc_train: 0.0814 time: 0.0187s\n",
            "Epoch: 0965 loss_train: 2677306.0000 acc_train: 0.0834 time: 0.0186s\n",
            "Epoch: 0966 loss_train: 2926219.2500 acc_train: 0.0978 time: 0.0183s\n",
            "Epoch: 0967 loss_train: 4457832.0000 acc_train: 0.1092 time: 0.0181s\n",
            "Epoch: 0968 loss_train: 4769890.5000 acc_train: 0.0982 time: 0.0179s\n",
            "Epoch: 0969 loss_train: 3560237.0000 acc_train: 0.1735 time: 0.0178s\n",
            "Epoch: 0970 loss_train: 3709335.0000 acc_train: 0.1193 time: 0.0181s\n",
            "Epoch: 0971 loss_train: 3469859.5000 acc_train: 0.1039 time: 0.0184s\n",
            "Epoch: 0972 loss_train: 3384998.0000 acc_train: 0.0867 time: 0.0183s\n",
            "Epoch: 0973 loss_train: 2939350.5000 acc_train: 0.1538 time: 0.0186s\n",
            "Epoch: 0974 loss_train: 3756275.0000 acc_train: 0.0956 time: 0.0191s\n",
            "Epoch: 0975 loss_train: 4595500.5000 acc_train: 0.0657 time: 0.0191s\n",
            "Epoch: 0976 loss_train: 2689647.7500 acc_train: 0.0863 time: 0.0190s\n",
            "Epoch: 0977 loss_train: 3180963.0000 acc_train: 0.0966 time: 0.0185s\n",
            "Epoch: 0978 loss_train: 2476370.0000 acc_train: 0.0961 time: 0.0183s\n",
            "Epoch: 0979 loss_train: 2747059.2500 acc_train: 0.1857 time: 0.0182s\n",
            "Epoch: 0980 loss_train: 2116226.2500 acc_train: 0.1141 time: 0.0181s\n",
            "Epoch: 0981 loss_train: 2912326.5000 acc_train: 0.0825 time: 0.0181s\n",
            "Epoch: 0982 loss_train: 3486962.0000 acc_train: 0.0960 time: 0.0183s\n",
            "Epoch: 0983 loss_train: 3384612.5000 acc_train: 0.0789 time: 0.0185s\n",
            "Epoch: 0984 loss_train: 3377792.0000 acc_train: 0.1433 time: 0.0184s\n",
            "Epoch: 0985 loss_train: 4656479.5000 acc_train: 0.1012 time: 0.0183s\n",
            "Epoch: 0986 loss_train: 5210305.0000 acc_train: 0.0917 time: 0.0184s\n",
            "Epoch: 0987 loss_train: 4972229.0000 acc_train: 0.1866 time: 0.0189s\n",
            "Epoch: 0988 loss_train: 5779652.5000 acc_train: 0.0963 time: 0.0189s\n",
            "Epoch: 0989 loss_train: 5979351.5000 acc_train: 0.1101 time: 0.0187s\n",
            "Epoch: 0990 loss_train: 5542259.0000 acc_train: 0.0842 time: 0.0183s\n",
            "Epoch: 0991 loss_train: 2545233.2500 acc_train: 0.1278 time: 0.0182s\n",
            "Epoch: 0992 loss_train: 3892911.7500 acc_train: 0.0939 time: 0.0182s\n",
            "Epoch: 0993 loss_train: 4269230.5000 acc_train: 0.0904 time: 0.0184s\n",
            "Epoch: 0994 loss_train: 3555607.7500 acc_train: 0.1037 time: 0.0186s\n",
            "Epoch: 0995 loss_train: 4363884.5000 acc_train: 0.1865 time: 0.0186s\n",
            "Epoch: 0996 loss_train: 3987421.5000 acc_train: 0.1193 time: 0.0184s\n",
            "Epoch: 0997 loss_train: 5290696.5000 acc_train: 0.0982 time: 0.0185s\n",
            "Epoch: 0998 loss_train: 4091850.2500 acc_train: 0.0944 time: 0.0187s\n",
            "Epoch: 0999 loss_train: 4511573.5000 acc_train: 0.1099 time: 0.0188s\n",
            "Epoch: 1000 loss_train: 5016786.5000 acc_train: 0.0925 time: 0.0187s\n",
            "Epoch: 1001 loss_train: 5849348.5000 acc_train: 0.1836 time: 0.0185s\n",
            "Epoch: 1002 loss_train: 6568930.0000 acc_train: 0.0979 time: 0.0184s\n",
            "Epoch: 1003 loss_train: 5029585.0000 acc_train: 0.0886 time: 0.0181s\n",
            "Epoch: 1004 loss_train: 4555150.5000 acc_train: 0.1001 time: 0.0180s\n",
            "Epoch: 1005 loss_train: 4701248.5000 acc_train: 0.0893 time: 0.0181s\n",
            "Epoch: 1006 loss_train: 5162955.5000 acc_train: 0.1537 time: 0.0181s\n",
            "Epoch: 1007 loss_train: 4880700.0000 acc_train: 0.1161 time: 0.0182s\n",
            "Epoch: 1008 loss_train: 5984577.5000 acc_train: 0.0583 time: 0.0184s\n",
            "Epoch: 1009 loss_train: 5084954.5000 acc_train: 0.0834 time: 0.0187s\n",
            "Epoch: 1010 loss_train: 5284949.5000 acc_train: 0.0978 time: 0.0188s\n",
            "Epoch: 1011 loss_train: 5758188.5000 acc_train: 0.1878 time: 0.0189s\n",
            "Epoch: 1012 loss_train: 3740041.7500 acc_train: 0.1866 time: 0.0188s\n",
            "Epoch: 1013 loss_train: 4268877.5000 acc_train: 0.0952 time: 0.0184s\n",
            "Epoch: 1014 loss_train: 5917158.0000 acc_train: 0.1009 time: 0.0182s\n",
            "Epoch: 1015 loss_train: 6434106.0000 acc_train: 0.1084 time: 0.0180s\n",
            "Epoch: 1016 loss_train: 7324090.0000 acc_train: 0.0960 time: 0.0179s\n",
            "Epoch: 1017 loss_train: 6024858.0000 acc_train: 0.0921 time: 0.0179s\n",
            "Epoch: 1018 loss_train: 7579595.0000 acc_train: 0.0817 time: 0.0180s\n",
            "Epoch: 1019 loss_train: 6528867.0000 acc_train: 0.0814 time: 0.0180s\n",
            "Epoch: 1020 loss_train: 5851369.5000 acc_train: 0.0975 time: 0.0184s\n",
            "Epoch: 1021 loss_train: 5410240.5000 acc_train: 0.0844 time: 0.0186s\n",
            "Epoch: 1022 loss_train: 4240281.0000 acc_train: 0.0984 time: 0.0185s\n",
            "Epoch: 1023 loss_train: 3713617.2500 acc_train: 0.1083 time: 0.0183s\n",
            "Epoch: 1024 loss_train: 4420716.0000 acc_train: 0.0869 time: 0.0182s\n",
            "Epoch: 1025 loss_train: 3141927.7500 acc_train: 0.0752 time: 0.0179s\n",
            "Epoch: 1026 loss_train: 4684611.0000 acc_train: 0.1873 time: 0.0179s\n",
            "Epoch: 1027 loss_train: 4729328.0000 acc_train: 0.1863 time: 0.0182s\n",
            "Epoch: 1028 loss_train: 6261159.5000 acc_train: 0.0936 time: 0.0185s\n",
            "Epoch: 1029 loss_train: 5867118.5000 acc_train: 0.0673 time: 0.0185s\n",
            "Epoch: 1030 loss_train: 6461949.5000 acc_train: 0.0732 time: 0.0185s\n",
            "Epoch: 1031 loss_train: 5775261.0000 acc_train: 0.0898 time: 0.0185s\n",
            "Epoch: 1032 loss_train: 4303232.5000 acc_train: 0.0807 time: 0.0191s\n",
            "Epoch: 1033 loss_train: 4816112.0000 acc_train: 0.0923 time: 0.0186s\n",
            "Epoch: 1034 loss_train: 6113233.5000 acc_train: 0.1874 time: 0.0183s\n",
            "Epoch: 1035 loss_train: 5464961.0000 acc_train: 0.1873 time: 0.0182s\n",
            "Epoch: 1036 loss_train: 5215409.5000 acc_train: 0.1000 time: 0.0181s\n",
            "Epoch: 1037 loss_train: 4693579.0000 acc_train: 0.1099 time: 0.0182s\n",
            "Epoch: 1038 loss_train: 2855714.2500 acc_train: 0.0972 time: 0.0183s\n",
            "Epoch: 1039 loss_train: 3043622.0000 acc_train: 0.0774 time: 0.0184s\n",
            "Epoch: 1040 loss_train: 3930152.5000 acc_train: 0.0901 time: 0.0183s\n",
            "Epoch: 1041 loss_train: 3500263.5000 acc_train: 0.0818 time: 0.0182s\n",
            "Epoch: 1042 loss_train: 4848403.5000 acc_train: 0.0810 time: 0.0182s\n",
            "Epoch: 1043 loss_train: 4239416.0000 acc_train: 0.0793 time: 0.0184s\n",
            "Epoch: 1044 loss_train: 2744099.5000 acc_train: 0.0825 time: 0.0186s\n",
            "Epoch: 1045 loss_train: 4005446.0000 acc_train: 0.1867 time: 0.0183s\n",
            "Epoch: 1046 loss_train: 3873904.2500 acc_train: 0.1868 time: 0.0181s\n",
            "Epoch: 1047 loss_train: 3878269.5000 acc_train: 0.0897 time: 0.0179s\n",
            "Epoch: 1048 loss_train: 3746487.0000 acc_train: 0.0846 time: 0.0179s\n",
            "Epoch: 1049 loss_train: 3922258.5000 acc_train: 0.0957 time: 0.0178s\n",
            "Epoch: 1050 loss_train: 3957517.7500 acc_train: 0.0914 time: 0.0179s\n",
            "Epoch: 1051 loss_train: 4633766.5000 acc_train: 0.0786 time: 0.0181s\n",
            "Epoch: 1052 loss_train: 5012602.5000 acc_train: 0.0958 time: 0.0188s\n",
            "Epoch: 1053 loss_train: 3670841.5000 acc_train: 0.0961 time: 0.0190s\n",
            "Epoch: 1054 loss_train: 3310334.0000 acc_train: 0.1097 time: 0.0191s\n",
            "Epoch: 1055 loss_train: 3176169.0000 acc_train: 0.1110 time: 0.0186s\n",
            "Epoch: 1056 loss_train: 3501156.2500 acc_train: 0.1662 time: 0.0184s\n",
            "Epoch: 1057 loss_train: 3765427.2500 acc_train: 0.1871 time: 0.0180s\n",
            "Epoch: 1058 loss_train: 3316867.7500 acc_train: 0.0949 time: 0.0178s\n",
            "Epoch: 1059 loss_train: 3600519.5000 acc_train: 0.0921 time: 0.0178s\n",
            "Epoch: 1060 loss_train: 3253331.0000 acc_train: 0.0919 time: 0.0180s\n",
            "Epoch: 1061 loss_train: 4159221.0000 acc_train: 0.0945 time: 0.0181s\n",
            "Epoch: 1062 loss_train: 3150291.5000 acc_train: 0.0767 time: 0.0181s\n",
            "Epoch: 1063 loss_train: 3654111.7500 acc_train: 0.0787 time: 0.0186s\n",
            "Epoch: 1064 loss_train: 2802431.0000 acc_train: 0.1093 time: 0.0189s\n",
            "Epoch: 1065 loss_train: 4573046.0000 acc_train: 0.1856 time: 0.0191s\n",
            "Epoch: 1066 loss_train: 4030643.5000 acc_train: 0.1812 time: 0.0186s\n",
            "Epoch: 1067 loss_train: 3315514.2500 acc_train: 0.0985 time: 0.0183s\n",
            "Epoch: 1068 loss_train: 4032717.0000 acc_train: 0.0883 time: 0.0181s\n",
            "Epoch: 1069 loss_train: 5110830.5000 acc_train: 0.0808 time: 0.0179s\n",
            "Epoch: 1070 loss_train: 4081893.7500 acc_train: 0.0989 time: 0.0180s\n",
            "Epoch: 1071 loss_train: 3208966.5000 acc_train: 0.0960 time: 0.0180s\n",
            "Epoch: 1072 loss_train: 2502346.2500 acc_train: 0.0837 time: 0.0179s\n",
            "Epoch: 1073 loss_train: 3374432.7500 acc_train: 0.0678 time: 0.0180s\n",
            "Epoch: 1074 loss_train: 2138897.0000 acc_train: 0.0752 time: 0.0184s\n",
            "Epoch: 1075 loss_train: 2940306.7500 acc_train: 0.1020 time: 0.0189s\n",
            "Epoch: 1076 loss_train: 3418168.7500 acc_train: 0.1612 time: 0.0191s\n",
            "Epoch: 1077 loss_train: 4258443.0000 acc_train: 0.1534 time: 0.0189s\n",
            "Epoch: 1078 loss_train: 4702197.0000 acc_train: 0.1021 time: 0.0187s\n",
            "Epoch: 1079 loss_train: 3853935.7500 acc_train: 0.0771 time: 0.0184s\n",
            "Epoch: 1080 loss_train: 3150964.0000 acc_train: 0.1055 time: 0.0185s\n",
            "Epoch: 1081 loss_train: 3932444.2500 acc_train: 0.0814 time: 0.0183s\n",
            "Epoch: 1082 loss_train: 3669709.2500 acc_train: 0.1812 time: 0.0182s\n",
            "Epoch: 1083 loss_train: 3436499.7500 acc_train: 0.0937 time: 0.0181s\n",
            "Epoch: 1084 loss_train: 3712212.5000 acc_train: 0.0852 time: 0.0179s\n",
            "Epoch: 1085 loss_train: 3847640.7500 acc_train: 0.0964 time: 0.0181s\n",
            "Epoch: 1086 loss_train: 4206751.0000 acc_train: 0.1031 time: 0.0185s\n",
            "Epoch: 1087 loss_train: 3791703.2500 acc_train: 0.1206 time: 0.0192s\n",
            "Epoch: 1088 loss_train: 4790970.0000 acc_train: 0.1866 time: 0.0189s\n",
            "Epoch: 1089 loss_train: 4787697.5000 acc_train: 0.1108 time: 0.0184s\n",
            "Epoch: 1090 loss_train: 2918246.0000 acc_train: 0.1191 time: 0.0182s\n",
            "Epoch: 1091 loss_train: 3375257.7500 acc_train: 0.0935 time: 0.0180s\n",
            "Epoch: 1092 loss_train: 4449941.0000 acc_train: 0.1000 time: 0.0181s\n",
            "Epoch: 1093 loss_train: 3481550.0000 acc_train: 0.0850 time: 0.0180s\n",
            "Epoch: 1094 loss_train: 3320528.0000 acc_train: 0.0829 time: 0.0179s\n",
            "Epoch: 1095 loss_train: 3760253.0000 acc_train: 0.1122 time: 0.0181s\n",
            "Epoch: 1096 loss_train: 4333439.5000 acc_train: 0.1455 time: 0.0186s\n",
            "Epoch: 1097 loss_train: 4998984.5000 acc_train: 0.1858 time: 0.0189s\n",
            "Epoch: 1098 loss_train: 4138646.0000 acc_train: 0.0971 time: 0.0193s\n",
            "Epoch: 1099 loss_train: 3842590.0000 acc_train: 0.0816 time: 0.0195s\n",
            "Epoch: 1100 loss_train: 4113600.2500 acc_train: 0.0951 time: 0.0190s\n",
            "Epoch: 1101 loss_train: 3700243.7500 acc_train: 0.0966 time: 0.0186s\n",
            "Epoch: 1102 loss_train: 3842185.2500 acc_train: 0.0837 time: 0.0183s\n",
            "Epoch: 1103 loss_train: 3115777.7500 acc_train: 0.0897 time: 0.0184s\n",
            "Epoch: 1104 loss_train: 3907030.5000 acc_train: 0.1349 time: 0.0183s\n",
            "Epoch: 1105 loss_train: 3827930.7500 acc_train: 0.1695 time: 0.0183s\n",
            "Epoch: 1106 loss_train: 4446481.0000 acc_train: 0.0724 time: 0.0183s\n",
            "Epoch: 1107 loss_train: 4570517.5000 acc_train: 0.0863 time: 0.0183s\n",
            "Epoch: 1108 loss_train: 3672205.7500 acc_train: 0.0853 time: 0.0181s\n",
            "Epoch: 1109 loss_train: 4568152.5000 acc_train: 0.1102 time: 0.0181s\n",
            "Epoch: 1110 loss_train: 3231518.7500 acc_train: 0.1006 time: 0.0181s\n",
            "Epoch: 1111 loss_train: 3304121.2500 acc_train: 0.1024 time: 0.0181s\n",
            "Epoch: 1112 loss_train: 3388420.0000 acc_train: 0.1511 time: 0.0179s\n",
            "Epoch: 1113 loss_train: 3429960.5000 acc_train: 0.1168 time: 0.0179s\n",
            "Epoch: 1114 loss_train: 3247768.5000 acc_train: 0.0917 time: 0.0182s\n",
            "Epoch: 1115 loss_train: 3206275.7500 acc_train: 0.1522 time: 0.0183s\n",
            "Epoch: 1116 loss_train: 2820216.5000 acc_train: 0.1657 time: 0.0187s\n",
            "Epoch: 1117 loss_train: 2839705.7500 acc_train: 0.0825 time: 0.0185s\n",
            "Epoch: 1118 loss_train: 3877826.2500 acc_train: 0.0839 time: 0.0184s\n",
            "Epoch: 1119 loss_train: 4283512.5000 acc_train: 0.0874 time: 0.0187s\n",
            "Epoch: 1120 loss_train: 5388075.0000 acc_train: 0.0844 time: 0.0191s\n",
            "Epoch: 1121 loss_train: 3534499.5000 acc_train: 0.0928 time: 0.0190s\n",
            "Epoch: 1122 loss_train: 3201529.0000 acc_train: 0.0948 time: 0.0188s\n",
            "Epoch: 1123 loss_train: 3447115.0000 acc_train: 0.1835 time: 0.0183s\n",
            "Epoch: 1124 loss_train: 3660711.7500 acc_train: 0.1127 time: 0.0180s\n",
            "Epoch: 1125 loss_train: 2844928.2500 acc_train: 0.1763 time: 0.0178s\n",
            "Epoch: 1126 loss_train: 3426264.7500 acc_train: 0.0975 time: 0.0179s\n",
            "Epoch: 1127 loss_train: 3455290.2500 acc_train: 0.0972 time: 0.0181s\n",
            "Epoch: 1128 loss_train: 3979385.2500 acc_train: 0.1101 time: 0.0182s\n",
            "Epoch: 1129 loss_train: 3520054.5000 acc_train: 0.0843 time: 0.0182s\n",
            "Epoch: 1130 loss_train: 3095964.5000 acc_train: 0.0709 time: 0.0184s\n",
            "Epoch: 1131 loss_train: 1663874.8750 acc_train: 0.0940 time: 0.0186s\n",
            "Epoch: 1132 loss_train: 1556556.2500 acc_train: 0.1000 time: 0.0192s\n",
            "Epoch: 1133 loss_train: 2538911.2500 acc_train: 0.0863 time: 0.0192s\n",
            "Epoch: 1134 loss_train: 2834437.5000 acc_train: 0.1561 time: 0.0189s\n",
            "Epoch: 1135 loss_train: 3735768.2500 acc_train: 0.1056 time: 0.0186s\n",
            "Epoch: 1136 loss_train: 3428765.0000 acc_train: 0.1407 time: 0.0183s\n",
            "Epoch: 1137 loss_train: 2911843.5000 acc_train: 0.1811 time: 0.0182s\n",
            "Epoch: 1138 loss_train: 1700471.5000 acc_train: 0.0951 time: 0.0182s\n",
            "Epoch: 1139 loss_train: 3063800.0000 acc_train: 0.0955 time: 0.0182s\n",
            "Epoch: 1140 loss_train: 2764924.7500 acc_train: 0.0898 time: 0.0183s\n",
            "Epoch: 1141 loss_train: 2652139.0000 acc_train: 0.0921 time: 0.0184s\n",
            "Epoch: 1142 loss_train: 2980813.5000 acc_train: 0.0959 time: 0.0185s\n",
            "Epoch: 1143 loss_train: 2761646.0000 acc_train: 0.1121 time: 0.0186s\n",
            "Epoch: 1144 loss_train: 3268430.2500 acc_train: 0.1716 time: 0.0186s\n",
            "Epoch: 1145 loss_train: 2555121.7500 acc_train: 0.1460 time: 0.0189s\n",
            "Epoch: 1146 loss_train: 2705245.2500 acc_train: 0.0866 time: 0.0186s\n",
            "Epoch: 1147 loss_train: 3066825.5000 acc_train: 0.0983 time: 0.0185s\n",
            "Epoch: 1148 loss_train: 3677774.5000 acc_train: 0.0871 time: 0.0184s\n",
            "Epoch: 1149 loss_train: 4701316.0000 acc_train: 0.0928 time: 0.0180s\n",
            "Epoch: 1150 loss_train: 3816223.5000 acc_train: 0.0698 time: 0.0181s\n",
            "Epoch: 1151 loss_train: 3647537.7500 acc_train: 0.0918 time: 0.0182s\n",
            "Epoch: 1152 loss_train: 4381251.5000 acc_train: 0.1696 time: 0.0183s\n",
            "Epoch: 1153 loss_train: 4248749.0000 acc_train: 0.1168 time: 0.0183s\n",
            "Epoch: 1154 loss_train: 2759001.5000 acc_train: 0.1704 time: 0.0183s\n",
            "Epoch: 1155 loss_train: 3284605.2500 acc_train: 0.0960 time: 0.0185s\n",
            "Epoch: 1156 loss_train: 3764939.5000 acc_train: 0.0954 time: 0.0188s\n",
            "Epoch: 1157 loss_train: 5026484.5000 acc_train: 0.1013 time: 0.0190s\n",
            "Epoch: 1158 loss_train: 4221853.5000 acc_train: 0.0930 time: 0.0186s\n",
            "Epoch: 1159 loss_train: 4227719.0000 acc_train: 0.0980 time: 0.0186s\n",
            "Epoch: 1160 loss_train: 2241304.2500 acc_train: 0.0846 time: 0.0182s\n",
            "Epoch: 1161 loss_train: 3342608.0000 acc_train: 0.1836 time: 0.0181s\n",
            "Epoch: 1162 loss_train: 4444926.5000 acc_train: 0.1064 time: 0.0184s\n",
            "Epoch: 1163 loss_train: 4284474.5000 acc_train: 0.0881 time: 0.0186s\n",
            "Epoch: 1164 loss_train: 4112497.7500 acc_train: 0.0927 time: 0.0184s\n",
            "Epoch: 1165 loss_train: 4703514.0000 acc_train: 0.1181 time: 0.0181s\n",
            "Epoch: 1166 loss_train: 4392523.0000 acc_train: 0.1716 time: 0.0182s\n",
            "Epoch: 1167 loss_train: 4883561.5000 acc_train: 0.0917 time: 0.0185s\n",
            "Epoch: 1168 loss_train: 4275920.0000 acc_train: 0.0923 time: 0.0186s\n",
            "Epoch: 1169 loss_train: 4812512.0000 acc_train: 0.0618 time: 0.0185s\n",
            "Epoch: 1170 loss_train: 4404524.5000 acc_train: 0.0692 time: 0.0185s\n",
            "Epoch: 1171 loss_train: 3083844.0000 acc_train: 0.1531 time: 0.0181s\n",
            "Epoch: 1172 loss_train: 3443645.0000 acc_train: 0.1129 time: 0.0178s\n",
            "Epoch: 1173 loss_train: 3518878.5000 acc_train: 0.0972 time: 0.0180s\n",
            "Epoch: 1174 loss_train: 2785474.5000 acc_train: 0.0950 time: 0.0181s\n",
            "Epoch: 1175 loss_train: 2792724.0000 acc_train: 0.0946 time: 0.0181s\n",
            "Epoch: 1176 loss_train: 3712981.0000 acc_train: 0.1862 time: 0.0182s\n",
            "Epoch: 1177 loss_train: 3983676.7500 acc_train: 0.0835 time: 0.0183s\n",
            "Epoch: 1178 loss_train: 3263270.0000 acc_train: 0.0993 time: 0.0186s\n",
            "Epoch: 1179 loss_train: 2501177.5000 acc_train: 0.0944 time: 0.0183s\n",
            "Epoch: 1180 loss_train: 2248764.5000 acc_train: 0.1413 time: 0.0181s\n",
            "Epoch: 1181 loss_train: 2158758.7500 acc_train: 0.1522 time: 0.0178s\n",
            "Epoch: 1182 loss_train: 2813302.2500 acc_train: 0.0975 time: 0.0178s\n",
            "Epoch: 1183 loss_train: 2612082.0000 acc_train: 0.0961 time: 0.0181s\n",
            "Epoch: 1184 loss_train: 1838492.5000 acc_train: 0.0867 time: 0.0182s\n",
            "Epoch: 1185 loss_train: 2866388.2500 acc_train: 0.0816 time: 0.0183s\n",
            "Epoch: 1186 loss_train: 1581902.3750 acc_train: 0.1569 time: 0.0185s\n",
            "Epoch: 1187 loss_train: 1878268.8750 acc_train: 0.0942 time: 0.0185s\n",
            "Epoch: 1188 loss_train: 1180615.6250 acc_train: 0.1045 time: 0.0191s\n",
            "Epoch: 1189 loss_train: 1797338.7500 acc_train: 0.0988 time: 0.0187s\n",
            "Epoch: 1190 loss_train: 1913531.5000 acc_train: 0.1789 time: 0.0187s\n",
            "Epoch: 1191 loss_train: 2502511.0000 acc_train: 0.1014 time: 0.0184s\n",
            "Epoch: 1192 loss_train: 3630651.0000 acc_train: 0.1105 time: 0.0183s\n",
            "Epoch: 1193 loss_train: 2572056.7500 acc_train: 0.1014 time: 0.0183s\n",
            "Epoch: 1194 loss_train: 3032643.7500 acc_train: 0.0920 time: 0.0182s\n",
            "Epoch: 1195 loss_train: 3436404.2500 acc_train: 0.0736 time: 0.0182s\n",
            "Epoch: 1196 loss_train: 3420566.5000 acc_train: 0.0860 time: 0.0182s\n",
            "Epoch: 1197 loss_train: 2384179.2500 acc_train: 0.0671 time: 0.0182s\n",
            "Epoch: 1198 loss_train: 3091775.5000 acc_train: 0.1159 time: 0.0184s\n",
            "Epoch: 1199 loss_train: 3879551.2500 acc_train: 0.1872 time: 0.0185s\n",
            "Epoch: 1200 loss_train: 2996237.7500 acc_train: 0.1804 time: 0.0190s\n",
            "Epoch: 1201 loss_train: 3666305.2500 acc_train: 0.0970 time: 0.0188s\n",
            "Epoch: 1202 loss_train: 3324504.7500 acc_train: 0.0899 time: 0.0185s\n",
            "Epoch: 1203 loss_train: 4507153.5000 acc_train: 0.0981 time: 0.0184s\n",
            "Epoch: 1204 loss_train: 4818672.0000 acc_train: 0.1070 time: 0.0181s\n",
            "Epoch: 1205 loss_train: 3990202.5000 acc_train: 0.0930 time: 0.0179s\n",
            "Epoch: 1206 loss_train: 4992109.0000 acc_train: 0.0993 time: 0.0179s\n",
            "Epoch: 1207 loss_train: 4587580.5000 acc_train: 0.0976 time: 0.0181s\n",
            "Epoch: 1208 loss_train: 4454328.0000 acc_train: 0.0822 time: 0.0183s\n",
            "Epoch: 1209 loss_train: 3800784.7500 acc_train: 0.0950 time: 0.0186s\n",
            "Epoch: 1210 loss_train: 2992347.2500 acc_train: 0.1229 time: 0.0190s\n",
            "Epoch: 1211 loss_train: 5011592.5000 acc_train: 0.1873 time: 0.0194s\n",
            "Epoch: 1212 loss_train: 5468145.0000 acc_train: 0.1874 time: 0.0188s\n",
            "Epoch: 1213 loss_train: 4305810.5000 acc_train: 0.0852 time: 0.0185s\n",
            "Epoch: 1214 loss_train: 3055229.7500 acc_train: 0.0951 time: 0.0183s\n",
            "Epoch: 1215 loss_train: 3352422.7500 acc_train: 0.0942 time: 0.0182s\n",
            "Epoch: 1216 loss_train: 2865530.0000 acc_train: 0.0944 time: 0.0183s\n",
            "Epoch: 1217 loss_train: 2475093.5000 acc_train: 0.1055 time: 0.0184s\n",
            "Epoch: 1218 loss_train: 3457071.7500 acc_train: 0.1009 time: 0.0184s\n",
            "Epoch: 1219 loss_train: 2571187.2500 acc_train: 0.0846 time: 0.0184s\n",
            "Epoch: 1220 loss_train: 3076312.5000 acc_train: 0.1833 time: 0.0185s\n",
            "Epoch: 1221 loss_train: 3387419.0000 acc_train: 0.0976 time: 0.0187s\n",
            "Epoch: 1222 loss_train: 3106181.0000 acc_train: 0.0971 time: 0.0186s\n",
            "Epoch: 1223 loss_train: 3359036.7500 acc_train: 0.0717 time: 0.0189s\n",
            "Epoch: 1224 loss_train: 2691885.5000 acc_train: 0.1667 time: 0.0191s\n",
            "Epoch: 1225 loss_train: 2658938.7500 acc_train: 0.0934 time: 0.0185s\n",
            "Epoch: 1226 loss_train: 2932445.7500 acc_train: 0.0951 time: 0.0183s\n",
            "Epoch: 1227 loss_train: 3030941.5000 acc_train: 0.0880 time: 0.0182s\n",
            "Epoch: 1228 loss_train: 2464890.0000 acc_train: 0.1573 time: 0.0182s\n",
            "Epoch: 1229 loss_train: 3287009.7500 acc_train: 0.1027 time: 0.0180s\n",
            "Epoch: 1230 loss_train: 2392807.7500 acc_train: 0.1047 time: 0.0179s\n",
            "Epoch: 1231 loss_train: 2507407.7500 acc_train: 0.1432 time: 0.0180s\n",
            "Epoch: 1232 loss_train: 2160098.5000 acc_train: 0.1434 time: 0.0182s\n",
            "Epoch: 1233 loss_train: 2412624.0000 acc_train: 0.0858 time: 0.0184s\n",
            "Epoch: 1234 loss_train: 2235801.2500 acc_train: 0.0628 time: 0.0185s\n",
            "Epoch: 1235 loss_train: 2668799.2500 acc_train: 0.0798 time: 0.0189s\n",
            "Epoch: 1236 loss_train: 1233439.3750 acc_train: 0.1607 time: 0.0187s\n",
            "Epoch: 1237 loss_train: 1445862.1250 acc_train: 0.1019 time: 0.0185s\n",
            "Epoch: 1238 loss_train: 2470488.0000 acc_train: 0.0867 time: 0.0184s\n",
            "Epoch: 1239 loss_train: 2301456.2500 acc_train: 0.0822 time: 0.0183s\n",
            "Epoch: 1240 loss_train: 2454941.2500 acc_train: 0.0967 time: 0.0183s\n",
            "Epoch: 1241 loss_train: 2264689.2500 acc_train: 0.0982 time: 0.0183s\n",
            "Epoch: 1242 loss_train: 2550494.5000 acc_train: 0.1467 time: 0.0183s\n",
            "Epoch: 1243 loss_train: 3471409.2500 acc_train: 0.1871 time: 0.0183s\n",
            "Epoch: 1244 loss_train: 2133178.7500 acc_train: 0.1473 time: 0.0187s\n",
            "Epoch: 1245 loss_train: 2608812.5000 acc_train: 0.1092 time: 0.0189s\n",
            "Epoch: 1246 loss_train: 2649704.0000 acc_train: 0.0939 time: 0.0191s\n",
            "Epoch: 1247 loss_train: 2654141.0000 acc_train: 0.0901 time: 0.0191s\n",
            "Epoch: 1248 loss_train: 3554059.7500 acc_train: 0.0903 time: 0.0186s\n",
            "Epoch: 1249 loss_train: 3208170.7500 acc_train: 0.0821 time: 0.0183s\n",
            "Epoch: 1250 loss_train: 3523711.5000 acc_train: 0.0600 time: 0.0182s\n",
            "Epoch: 1251 loss_train: 1999462.5000 acc_train: 0.0918 time: 0.0180s\n",
            "Epoch: 1252 loss_train: 2599379.0000 acc_train: 0.1107 time: 0.0180s\n",
            "Epoch: 1253 loss_train: 2477361.5000 acc_train: 0.0957 time: 0.0182s\n",
            "Epoch: 1254 loss_train: 3300024.5000 acc_train: 0.1838 time: 0.0186s\n",
            "Epoch: 1255 loss_train: 3840489.5000 acc_train: 0.1033 time: 0.0187s\n",
            "Epoch: 1256 loss_train: 3911158.2500 acc_train: 0.1043 time: 0.0188s\n",
            "Epoch: 1257 loss_train: 3964508.5000 acc_train: 0.1826 time: 0.0187s\n",
            "Epoch: 1258 loss_train: 3542150.2500 acc_train: 0.1108 time: 0.0187s\n",
            "Epoch: 1259 loss_train: 2820649.0000 acc_train: 0.0972 time: 0.0189s\n",
            "Epoch: 1260 loss_train: 3328513.7500 acc_train: 0.0954 time: 0.0187s\n",
            "Epoch: 1261 loss_train: 3889212.2500 acc_train: 0.0822 time: 0.0186s\n",
            "Epoch: 1262 loss_train: 3588051.0000 acc_train: 0.0929 time: 0.0184s\n",
            "Epoch: 1263 loss_train: 2493496.5000 acc_train: 0.1792 time: 0.0182s\n",
            "Epoch: 1264 loss_train: 1842909.0000 acc_train: 0.1494 time: 0.0180s\n",
            "Epoch: 1265 loss_train: 2734291.0000 acc_train: 0.0930 time: 0.0180s\n",
            "Epoch: 1266 loss_train: 2317391.0000 acc_train: 0.0865 time: 0.0181s\n",
            "Epoch: 1267 loss_train: 1841612.3750 acc_train: 0.0876 time: 0.0180s\n",
            "Epoch: 1268 loss_train: 3162845.7500 acc_train: 0.1014 time: 0.0184s\n",
            "Epoch: 1269 loss_train: 2017902.3750 acc_train: 0.0922 time: 0.0188s\n",
            "Epoch: 1270 loss_train: 2837256.5000 acc_train: 0.0918 time: 0.0190s\n",
            "Epoch: 1271 loss_train: 3840050.7500 acc_train: 0.1875 time: 0.0186s\n",
            "Epoch: 1272 loss_train: 2956395.2500 acc_train: 0.1793 time: 0.0183s\n",
            "Epoch: 1273 loss_train: 3366191.0000 acc_train: 0.0871 time: 0.0182s\n",
            "Epoch: 1274 loss_train: 3852004.5000 acc_train: 0.0972 time: 0.0180s\n",
            "Epoch: 1275 loss_train: 3930492.2500 acc_train: 0.0999 time: 0.0179s\n",
            "Epoch: 1276 loss_train: 4787928.0000 acc_train: 0.0972 time: 0.0181s\n",
            "Epoch: 1277 loss_train: 2930635.7500 acc_train: 0.0978 time: 0.0184s\n",
            "Epoch: 1278 loss_train: 3690736.7500 acc_train: 0.0907 time: 0.0187s\n",
            "Epoch: 1279 loss_train: 3787307.7500 acc_train: 0.0706 time: 0.0185s\n",
            "Epoch: 1280 loss_train: 3854121.2500 acc_train: 0.0824 time: 0.0187s\n",
            "Epoch: 1281 loss_train: 2458099.0000 acc_train: 0.0953 time: 0.0189s\n",
            "Epoch: 1282 loss_train: 2732097.7500 acc_train: 0.1157 time: 0.0189s\n",
            "Epoch: 1283 loss_train: 4228129.0000 acc_train: 0.1875 time: 0.0185s\n",
            "Epoch: 1284 loss_train: 3579445.0000 acc_train: 0.1797 time: 0.0184s\n",
            "Epoch: 1285 loss_train: 4893125.0000 acc_train: 0.0857 time: 0.0182s\n",
            "Epoch: 1286 loss_train: 5020144.5000 acc_train: 0.0873 time: 0.0182s\n",
            "Epoch: 1287 loss_train: 6370115.0000 acc_train: 0.1010 time: 0.0182s\n",
            "Epoch: 1288 loss_train: 5211577.5000 acc_train: 0.0966 time: 0.0183s\n",
            "Epoch: 1289 loss_train: 5524369.5000 acc_train: 0.0981 time: 0.0183s\n",
            "Epoch: 1290 loss_train: 3919495.0000 acc_train: 0.0898 time: 0.0183s\n",
            "Epoch: 1291 loss_train: 3290354.7500 acc_train: 0.1007 time: 0.0182s\n",
            "Epoch: 1292 loss_train: 3550567.5000 acc_train: 0.1580 time: 0.0183s\n",
            "Epoch: 1293 loss_train: 3682428.5000 acc_train: 0.1540 time: 0.0186s\n",
            "Epoch: 1294 loss_train: 3772757.7500 acc_train: 0.0961 time: 0.0185s\n",
            "Epoch: 1295 loss_train: 2874358.0000 acc_train: 0.1042 time: 0.0183s\n",
            "Epoch: 1296 loss_train: 4266907.0000 acc_train: 0.0662 time: 0.0183s\n",
            "Epoch: 1297 loss_train: 2973752.5000 acc_train: 0.0761 time: 0.0186s\n",
            "Epoch: 1298 loss_train: 2894302.0000 acc_train: 0.1099 time: 0.0186s\n",
            "Epoch: 1299 loss_train: 3379255.0000 acc_train: 0.1131 time: 0.0188s\n",
            "Epoch: 1300 loss_train: 3505307.2500 acc_train: 0.1837 time: 0.0187s\n",
            "Epoch: 1301 loss_train: 5300522.5000 acc_train: 0.0817 time: 0.0184s\n",
            "Epoch: 1302 loss_train: 4846365.5000 acc_train: 0.0820 time: 0.0184s\n",
            "Epoch: 1303 loss_train: 4297046.0000 acc_train: 0.0977 time: 0.0185s\n",
            "Epoch: 1304 loss_train: 3069970.5000 acc_train: 0.1011 time: 0.0188s\n",
            "Epoch: 1305 loss_train: 3223845.2500 acc_train: 0.1737 time: 0.0191s\n",
            "Epoch: 1306 loss_train: 3451641.7500 acc_train: 0.1089 time: 0.0187s\n",
            "Epoch: 1307 loss_train: 4432089.5000 acc_train: 0.0936 time: 0.0185s\n",
            "Epoch: 1308 loss_train: 4078339.2500 acc_train: 0.1071 time: 0.0184s\n",
            "Epoch: 1309 loss_train: 4198160.5000 acc_train: 0.1784 time: 0.0181s\n",
            "Epoch: 1310 loss_train: 5619241.0000 acc_train: 0.0913 time: 0.0180s\n",
            "Epoch: 1311 loss_train: 4698424.5000 acc_train: 0.1091 time: 0.0182s\n",
            "Epoch: 1312 loss_train: 3475266.7500 acc_train: 0.1020 time: 0.0184s\n",
            "Epoch: 1313 loss_train: 3143204.7500 acc_train: 0.1001 time: 0.0186s\n",
            "Epoch: 1314 loss_train: 3211857.2500 acc_train: 0.1094 time: 0.0187s\n",
            "Epoch: 1315 loss_train: 3235283.5000 acc_train: 0.1534 time: 0.0187s\n",
            "Epoch: 1316 loss_train: 3182824.0000 acc_train: 0.0938 time: 0.0186s\n",
            "Epoch: 1317 loss_train: 3508960.5000 acc_train: 0.1054 time: 0.0188s\n",
            "Epoch: 1318 loss_train: 2510143.7500 acc_train: 0.1311 time: 0.0190s\n",
            "Epoch: 1319 loss_train: 2846928.0000 acc_train: 0.1302 time: 0.0187s\n",
            "Epoch: 1320 loss_train: 2714189.5000 acc_train: 0.1645 time: 0.0187s\n",
            "Epoch: 1321 loss_train: 3740477.5000 acc_train: 0.0972 time: 0.0185s\n",
            "Epoch: 1322 loss_train: 2856657.7500 acc_train: 0.0939 time: 0.0184s\n",
            "Epoch: 1323 loss_train: 3277384.5000 acc_train: 0.0880 time: 0.0181s\n",
            "Epoch: 1324 loss_train: 3031770.7500 acc_train: 0.0966 time: 0.0180s\n",
            "Epoch: 1325 loss_train: 3301824.5000 acc_train: 0.1042 time: 0.0179s\n",
            "Epoch: 1326 loss_train: 3112441.2500 acc_train: 0.0723 time: 0.0181s\n",
            "Epoch: 1327 loss_train: 3770689.7500 acc_train: 0.1689 time: 0.0185s\n",
            "Epoch: 1328 loss_train: 3311196.7500 acc_train: 0.0858 time: 0.0186s\n",
            "Epoch: 1329 loss_train: 2617959.7500 acc_train: 0.1107 time: 0.0189s\n",
            "Epoch: 1330 loss_train: 2531074.7500 acc_train: 0.1055 time: 0.0187s\n",
            "Epoch: 1331 loss_train: 2436007.5000 acc_train: 0.1321 time: 0.0185s\n",
            "Epoch: 1332 loss_train: 3424897.5000 acc_train: 0.0886 time: 0.0183s\n",
            "Epoch: 1333 loss_train: 2876418.0000 acc_train: 0.0924 time: 0.0182s\n",
            "Epoch: 1334 loss_train: 2672812.5000 acc_train: 0.1233 time: 0.0184s\n",
            "Epoch: 1335 loss_train: 2757847.7500 acc_train: 0.1015 time: 0.0185s\n",
            "Epoch: 1336 loss_train: 3029334.5000 acc_train: 0.0828 time: 0.0184s\n",
            "Epoch: 1337 loss_train: 2733977.2500 acc_train: 0.1022 time: 0.0182s\n",
            "Epoch: 1338 loss_train: 3013715.7500 acc_train: 0.1767 time: 0.0183s\n",
            "Epoch: 1339 loss_train: 4040115.0000 acc_train: 0.1026 time: 0.0187s\n",
            "Epoch: 1340 loss_train: 3679704.0000 acc_train: 0.0969 time: 0.0191s\n",
            "Epoch: 1341 loss_train: 3237571.2500 acc_train: 0.1011 time: 0.0191s\n",
            "Epoch: 1342 loss_train: 3567482.7500 acc_train: 0.1032 time: 0.0191s\n",
            "Epoch: 1343 loss_train: 4894118.5000 acc_train: 0.1872 time: 0.0187s\n",
            "Epoch: 1344 loss_train: 4029137.0000 acc_train: 0.1481 time: 0.0184s\n",
            "Epoch: 1345 loss_train: 4026834.0000 acc_train: 0.0950 time: 0.0182s\n",
            "Epoch: 1346 loss_train: 3881304.7500 acc_train: 0.1005 time: 0.0181s\n",
            "Epoch: 1347 loss_train: 3245423.0000 acc_train: 0.0656 time: 0.0183s\n",
            "Epoch: 1348 loss_train: 3485754.0000 acc_train: 0.0813 time: 0.0185s\n",
            "Epoch: 1349 loss_train: 2473239.7500 acc_train: 0.0926 time: 0.0186s\n",
            "Epoch: 1350 loss_train: 2240807.7500 acc_train: 0.1801 time: 0.0184s\n",
            "Epoch: 1351 loss_train: 2659946.0000 acc_train: 0.0895 time: 0.0184s\n",
            "Epoch: 1352 loss_train: 2595972.2500 acc_train: 0.0971 time: 0.0189s\n",
            "Epoch: 1353 loss_train: 2337245.5000 acc_train: 0.1026 time: 0.0190s\n",
            "Epoch: 1354 loss_train: 2801641.2500 acc_train: 0.1354 time: 0.0195s\n",
            "Epoch: 1355 loss_train: 3766509.0000 acc_train: 0.0887 time: 0.0200s\n",
            "Epoch: 1356 loss_train: 3406907.7500 acc_train: 0.1170 time: 0.0201s\n",
            "Epoch: 1357 loss_train: 4100323.0000 acc_train: 0.1014 time: 0.0197s\n",
            "Epoch: 1358 loss_train: 3560798.7500 acc_train: 0.1839 time: 0.0191s\n",
            "Epoch: 1359 loss_train: 2584956.7500 acc_train: 0.1051 time: 0.0190s\n",
            "Epoch: 1360 loss_train: 2355413.0000 acc_train: 0.1023 time: 0.0185s\n",
            "Epoch: 1361 loss_train: 4608413.0000 acc_train: 0.0993 time: 0.0183s\n",
            "Epoch: 1362 loss_train: 3895970.7500 acc_train: 0.0648 time: 0.0182s\n",
            "Epoch: 1363 loss_train: 2671138.2500 acc_train: 0.0782 time: 0.0184s\n",
            "Epoch: 1364 loss_train: 3293754.7500 acc_train: 0.1083 time: 0.0186s\n",
            "Epoch: 1365 loss_train: 2564400.0000 acc_train: 0.1738 time: 0.0184s\n",
            "Epoch: 1366 loss_train: 3400867.0000 acc_train: 0.0889 time: 0.0182s\n",
            "Epoch: 1367 loss_train: 3431897.7500 acc_train: 0.0814 time: 0.0185s\n",
            "Epoch: 1368 loss_train: 2126502.5000 acc_train: 0.0900 time: 0.0190s\n",
            "Epoch: 1369 loss_train: 2450006.5000 acc_train: 0.1793 time: 0.0193s\n",
            "Epoch: 1370 loss_train: 3940294.5000 acc_train: 0.0994 time: 0.0197s\n",
            "Epoch: 1371 loss_train: 2844374.0000 acc_train: 0.0932 time: 0.0194s\n",
            "Epoch: 1372 loss_train: 2431034.7500 acc_train: 0.1113 time: 0.0191s\n",
            "Epoch: 1373 loss_train: 2638072.5000 acc_train: 0.1599 time: 0.0186s\n",
            "Epoch: 1374 loss_train: 2940124.2500 acc_train: 0.1137 time: 0.0183s\n",
            "Epoch: 1375 loss_train: 3032507.5000 acc_train: 0.1861 time: 0.0180s\n",
            "Epoch: 1376 loss_train: 3148546.7500 acc_train: 0.0915 time: 0.0179s\n",
            "Epoch: 1377 loss_train: 4174281.5000 acc_train: 0.0836 time: 0.0179s\n",
            "Epoch: 1378 loss_train: 3007023.7500 acc_train: 0.0874 time: 0.0178s\n",
            "Epoch: 1379 loss_train: 3735058.7500 acc_train: 0.0965 time: 0.0180s\n",
            "Epoch: 1380 loss_train: 3921245.0000 acc_train: 0.1077 time: 0.0186s\n",
            "Epoch: 1381 loss_train: 3803795.0000 acc_train: 0.0813 time: 0.0189s\n",
            "Epoch: 1382 loss_train: 2995608.0000 acc_train: 0.0990 time: 0.0189s\n",
            "Epoch: 1383 loss_train: 3089349.2500 acc_train: 0.0835 time: 0.0193s\n",
            "Epoch: 1384 loss_train: 3142769.0000 acc_train: 0.1233 time: 0.0189s\n",
            "Epoch: 1385 loss_train: 3994591.0000 acc_train: 0.1793 time: 0.0185s\n",
            "Epoch: 1386 loss_train: 4201499.5000 acc_train: 0.0908 time: 0.0183s\n",
            "Epoch: 1387 loss_train: 4393513.0000 acc_train: 0.0564 time: 0.0182s\n",
            "Epoch: 1388 loss_train: 2659334.2500 acc_train: 0.1731 time: 0.0183s\n",
            "Epoch: 1389 loss_train: 3189557.7500 acc_train: 0.0947 time: 0.0185s\n",
            "Epoch: 1390 loss_train: 2477088.2500 acc_train: 0.0887 time: 0.0185s\n",
            "Epoch: 1391 loss_train: 3490991.7500 acc_train: 0.0835 time: 0.0183s\n",
            "Epoch: 1392 loss_train: 3416344.5000 acc_train: 0.1002 time: 0.0185s\n",
            "Epoch: 1393 loss_train: 2952954.2500 acc_train: 0.1025 time: 0.0189s\n",
            "Epoch: 1394 loss_train: 3611158.7500 acc_train: 0.1019 time: 0.0189s\n",
            "Epoch: 1395 loss_train: 3743591.0000 acc_train: 0.1323 time: 0.0193s\n",
            "Epoch: 1396 loss_train: 4570785.0000 acc_train: 0.1875 time: 0.0196s\n",
            "Epoch: 1397 loss_train: 2906404.5000 acc_train: 0.1157 time: 0.0189s\n",
            "Epoch: 1398 loss_train: 3567963.0000 acc_train: 0.0971 time: 0.0187s\n",
            "Epoch: 1399 loss_train: 3458376.0000 acc_train: 0.0883 time: 0.0185s\n",
            "Epoch: 1400 loss_train: 2779836.7500 acc_train: 0.0835 time: 0.0182s\n",
            "Epoch: 1401 loss_train: 3389482.7500 acc_train: 0.0976 time: 0.0180s\n",
            "Epoch: 1402 loss_train: 3783192.2500 acc_train: 0.0919 time: 0.0180s\n",
            "Epoch: 1403 loss_train: 3411090.5000 acc_train: 0.1013 time: 0.0184s\n",
            "Epoch: 1404 loss_train: 3380107.7500 acc_train: 0.1266 time: 0.0187s\n",
            "Epoch: 1405 loss_train: 3567113.2500 acc_train: 0.1872 time: 0.0188s\n",
            "Epoch: 1406 loss_train: 2983504.2500 acc_train: 0.0915 time: 0.0188s\n",
            "Epoch: 1407 loss_train: 4159826.5000 acc_train: 0.0991 time: 0.0189s\n",
            "Epoch: 1408 loss_train: 4107183.5000 acc_train: 0.0924 time: 0.0193s\n",
            "Epoch: 1409 loss_train: 3480940.0000 acc_train: 0.0732 time: 0.0197s\n",
            "Epoch: 1410 loss_train: 3824830.7500 acc_train: 0.1870 time: 0.0197s\n",
            "Epoch: 1411 loss_train: 2519062.0000 acc_train: 0.1811 time: 0.0199s\n",
            "Epoch: 1412 loss_train: 2398769.5000 acc_train: 0.0940 time: 0.0201s\n",
            "Epoch: 1413 loss_train: 4061706.5000 acc_train: 0.0870 time: 0.0198s\n",
            "Epoch: 1414 loss_train: 2734867.2500 acc_train: 0.0888 time: 0.0190s\n",
            "Epoch: 1415 loss_train: 3952290.7500 acc_train: 0.0829 time: 0.0184s\n",
            "Epoch: 1416 loss_train: 4208656.0000 acc_train: 0.0825 time: 0.0179s\n",
            "Epoch: 1417 loss_train: 4859352.0000 acc_train: 0.1095 time: 0.0178s\n",
            "Epoch: 1418 loss_train: 4795632.5000 acc_train: 0.1004 time: 0.0180s\n",
            "Epoch: 1419 loss_train: 4353482.0000 acc_train: 0.1099 time: 0.0182s\n",
            "Epoch: 1420 loss_train: 3492331.5000 acc_train: 0.0797 time: 0.0185s\n",
            "Epoch: 1421 loss_train: 3425311.7500 acc_train: 0.0827 time: 0.0185s\n",
            "Epoch: 1422 loss_train: 4152921.0000 acc_train: 0.1872 time: 0.0190s\n",
            "Epoch: 1423 loss_train: 3782597.2500 acc_train: 0.1639 time: 0.0191s\n",
            "Epoch: 1424 loss_train: 4903754.0000 acc_train: 0.0970 time: 0.0190s\n",
            "Epoch: 1425 loss_train: 3497808.5000 acc_train: 0.1022 time: 0.0190s\n",
            "Epoch: 1426 loss_train: 2001624.0000 acc_train: 0.0940 time: 0.0190s\n",
            "Epoch: 1427 loss_train: 3274191.0000 acc_train: 0.0846 time: 0.0186s\n",
            "Epoch: 1428 loss_train: 2381968.7500 acc_train: 0.1589 time: 0.0185s\n",
            "Epoch: 1429 loss_train: 2891723.0000 acc_train: 0.1045 time: 0.0182s\n",
            "Epoch: 1430 loss_train: 2591399.7500 acc_train: 0.1061 time: 0.0207s\n",
            "Epoch: 1431 loss_train: 2106251.5000 acc_train: 0.1649 time: 0.0181s\n",
            "Epoch: 1432 loss_train: 3695545.0000 acc_train: 0.0819 time: 0.0179s\n",
            "Epoch: 1433 loss_train: 2456759.0000 acc_train: 0.0838 time: 0.0179s\n",
            "Epoch: 1434 loss_train: 2459555.5000 acc_train: 0.0970 time: 0.0178s\n",
            "Epoch: 1435 loss_train: 2823101.7500 acc_train: 0.0870 time: 0.0179s\n",
            "Epoch: 1436 loss_train: 1551519.7500 acc_train: 0.0927 time: 0.0183s\n",
            "Epoch: 1437 loss_train: 2213060.2500 acc_train: 0.1809 time: 0.0190s\n",
            "Epoch: 1438 loss_train: 2346509.7500 acc_train: 0.0780 time: 0.0196s\n",
            "Epoch: 1439 loss_train: 1891943.3750 acc_train: 0.0779 time: 0.0197s\n",
            "Epoch: 1440 loss_train: 1865334.7500 acc_train: 0.1039 time: 0.0192s\n",
            "Epoch: 1441 loss_train: 1836440.3750 acc_train: 0.1097 time: 0.0186s\n",
            "Epoch: 1442 loss_train: 1987174.5000 acc_train: 0.1250 time: 0.0181s\n",
            "Epoch: 1443 loss_train: 2787375.5000 acc_train: 0.0946 time: 0.0179s\n",
            "Epoch: 1444 loss_train: 2571315.2500 acc_train: 0.1753 time: 0.0179s\n",
            "Epoch: 1445 loss_train: 2833912.2500 acc_train: 0.1018 time: 0.0182s\n",
            "Epoch: 1446 loss_train: 2763507.7500 acc_train: 0.0969 time: 0.0183s\n",
            "Epoch: 1447 loss_train: 3497361.2500 acc_train: 0.0895 time: 0.0184s\n",
            "Epoch: 1448 loss_train: 3631519.2500 acc_train: 0.1109 time: 0.0187s\n",
            "Epoch: 1449 loss_train: 2335867.5000 acc_train: 0.1411 time: 0.0189s\n",
            "Epoch: 1450 loss_train: 2548576.0000 acc_train: 0.0817 time: 0.0188s\n",
            "Epoch: 1451 loss_train: 3398169.5000 acc_train: 0.1002 time: 0.0188s\n",
            "Epoch: 1452 loss_train: 2477814.0000 acc_train: 0.1034 time: 0.0224s\n",
            "Epoch: 1453 loss_train: 2684299.0000 acc_train: 0.1042 time: 0.0187s\n",
            "Epoch: 1454 loss_train: 3598392.5000 acc_train: 0.1871 time: 0.0179s\n",
            "Epoch: 1455 loss_train: 2816766.7500 acc_train: 0.1867 time: 0.0179s\n",
            "Epoch: 1456 loss_train: 3227135.2500 acc_train: 0.0993 time: 0.0180s\n",
            "Epoch: 1457 loss_train: 2574809.0000 acc_train: 0.0872 time: 0.0179s\n",
            "Epoch: 1458 loss_train: 3638667.2500 acc_train: 0.0938 time: 0.0179s\n",
            "Epoch: 1459 loss_train: 3652385.0000 acc_train: 0.0907 time: 0.0179s\n",
            "Epoch: 1460 loss_train: 3628268.2500 acc_train: 0.0877 time: 0.0180s\n",
            "Epoch: 1461 loss_train: 3271515.5000 acc_train: 0.0979 time: 0.0181s\n",
            "Epoch: 1462 loss_train: 1918188.1250 acc_train: 0.0883 time: 0.0189s\n",
            "Epoch: 1463 loss_train: 2590001.5000 acc_train: 0.0959 time: 0.0195s\n",
            "Epoch: 1464 loss_train: 3144226.5000 acc_train: 0.1870 time: 0.0194s\n",
            "Epoch: 1465 loss_train: 2994087.0000 acc_train: 0.1717 time: 0.0190s\n",
            "Epoch: 1466 loss_train: 4396826.5000 acc_train: 0.0829 time: 0.0187s\n",
            "Epoch: 1467 loss_train: 3518317.5000 acc_train: 0.0863 time: 0.0184s\n",
            "Epoch: 1468 loss_train: 3794648.2500 acc_train: 0.1057 time: 0.0184s\n",
            "Epoch: 1469 loss_train: 3760454.5000 acc_train: 0.0737 time: 0.0184s\n",
            "Epoch: 1470 loss_train: 4520953.5000 acc_train: 0.1014 time: 0.0183s\n",
            "Epoch: 1471 loss_train: 4791730.0000 acc_train: 0.0967 time: 0.0182s\n",
            "Epoch: 1472 loss_train: 4100001.0000 acc_train: 0.0916 time: 0.0182s\n",
            "Epoch: 1473 loss_train: 3997940.2500 acc_train: 0.1106 time: 0.0180s\n",
            "Epoch: 1474 loss_train: 2889218.2500 acc_train: 0.1216 time: 0.0183s\n",
            "Epoch: 1475 loss_train: 3451690.0000 acc_train: 0.1672 time: 0.0184s\n",
            "Epoch: 1476 loss_train: 3894499.7500 acc_train: 0.0562 time: 0.0184s\n",
            "Epoch: 1477 loss_train: 3315776.0000 acc_train: 0.0803 time: 0.0185s\n",
            "Epoch: 1478 loss_train: 4029518.5000 acc_train: 0.0921 time: 0.0185s\n",
            "Epoch: 1479 loss_train: 3682443.7500 acc_train: 0.0857 time: 0.0185s\n",
            "Epoch: 1480 loss_train: 3521690.5000 acc_train: 0.1079 time: 0.0187s\n",
            "Epoch: 1481 loss_train: 4254100.0000 acc_train: 0.1854 time: 0.0188s\n",
            "Epoch: 1482 loss_train: 3807830.5000 acc_train: 0.1352 time: 0.0188s\n",
            "Epoch: 1483 loss_train: 2769530.7500 acc_train: 0.0872 time: 0.0188s\n",
            "Epoch: 1484 loss_train: 3411293.0000 acc_train: 0.0992 time: 0.0187s\n",
            "Epoch: 1485 loss_train: 3130199.2500 acc_train: 0.1062 time: 0.0187s\n",
            "Epoch: 1486 loss_train: 2913103.7500 acc_train: 0.1801 time: 0.0186s\n",
            "Epoch: 1487 loss_train: 2784391.2500 acc_train: 0.0929 time: 0.0188s\n",
            "Epoch: 1488 loss_train: 2009030.3750 acc_train: 0.0982 time: 0.0182s\n",
            "Epoch: 1489 loss_train: 1585219.3750 acc_train: 0.1088 time: 0.0184s\n",
            "Epoch: 1490 loss_train: 2860589.7500 acc_train: 0.0902 time: 0.0189s\n",
            "Epoch: 1491 loss_train: 3155080.2500 acc_train: 0.1044 time: 0.0189s\n",
            "Epoch: 1492 loss_train: 3631676.2500 acc_train: 0.0824 time: 0.0188s\n",
            "Epoch: 1493 loss_train: 3933756.5000 acc_train: 0.1585 time: 0.0185s\n",
            "Epoch: 1494 loss_train: 4260181.5000 acc_train: 0.1038 time: 0.0185s\n",
            "Epoch: 1495 loss_train: 5340484.5000 acc_train: 0.0977 time: 0.0184s\n",
            "Epoch: 1496 loss_train: 4594861.0000 acc_train: 0.1135 time: 0.0184s\n",
            "Epoch: 1497 loss_train: 5221049.0000 acc_train: 0.1874 time: 0.0184s\n",
            "Epoch: 1498 loss_train: 4000654.7500 acc_train: 0.1780 time: 0.0182s\n",
            "Epoch: 1499 loss_train: 5245334.0000 acc_train: 0.0814 time: 0.0178s\n",
            "Epoch: 1500 loss_train: 5468514.0000 acc_train: 0.1012 time: 0.0173s\n",
            "Epoch: 1501 loss_train: 3941887.7500 acc_train: 0.0944 time: 0.0177s\n",
            "Epoch: 1502 loss_train: 4063185.0000 acc_train: 0.1047 time: 0.0184s\n",
            "Epoch: 1503 loss_train: 4466317.0000 acc_train: 0.0898 time: 0.0182s\n",
            "Epoch: 1504 loss_train: 4499471.5000 acc_train: 0.0983 time: 0.0183s\n",
            "Epoch: 1505 loss_train: 3518392.2500 acc_train: 0.0908 time: 0.0201s\n",
            "Epoch: 1506 loss_train: 4155551.2500 acc_train: 0.0867 time: 0.0184s\n",
            "Epoch: 1507 loss_train: 4117059.0000 acc_train: 0.0867 time: 0.0183s\n",
            "Epoch: 1508 loss_train: 3745414.7500 acc_train: 0.1109 time: 0.0179s\n",
            "Epoch: 1509 loss_train: 3366269.0000 acc_train: 0.1502 time: 0.0179s\n",
            "Epoch: 1510 loss_train: 3967662.0000 acc_train: 0.0999 time: 0.0179s\n",
            "Epoch: 1511 loss_train: 4261097.5000 acc_train: 0.1199 time: 0.0180s\n",
            "Epoch: 1512 loss_train: 3907431.0000 acc_train: 0.1559 time: 0.0184s\n",
            "Epoch: 1513 loss_train: 3295087.0000 acc_train: 0.0793 time: 0.0187s\n",
            "Epoch: 1514 loss_train: 1932265.0000 acc_train: 0.0900 time: 0.0248s\n",
            "Epoch: 1515 loss_train: 2220924.2500 acc_train: 0.0973 time: 0.0184s\n",
            "Epoch: 1516 loss_train: 2758525.7500 acc_train: 0.0943 time: 0.0176s\n",
            "Epoch: 1517 loss_train: 2832089.0000 acc_train: 0.1016 time: 0.0177s\n",
            "Epoch: 1518 loss_train: 2684795.5000 acc_train: 0.1412 time: 0.0180s\n",
            "Epoch: 1519 loss_train: 3358629.7500 acc_train: 0.0847 time: 0.0179s\n",
            "Epoch: 1520 loss_train: 2381510.2500 acc_train: 0.1091 time: 0.0182s\n",
            "Epoch: 1521 loss_train: 1818329.8750 acc_train: 0.1699 time: 0.0185s\n",
            "Epoch: 1522 loss_train: 1862390.2500 acc_train: 0.0915 time: 0.0179s\n",
            "Epoch: 1523 loss_train: 2121371.7500 acc_train: 0.0827 time: 0.0180s\n",
            "Epoch: 1524 loss_train: 2740814.2500 acc_train: 0.0871 time: 0.0181s\n",
            "Epoch: 1525 loss_train: 2408661.5000 acc_train: 0.0997 time: 0.0179s\n",
            "Epoch: 1526 loss_train: 1791115.6250 acc_train: 0.1865 time: 0.0180s\n",
            "Epoch: 1527 loss_train: 1544929.2500 acc_train: 0.1674 time: 0.0182s\n",
            "Epoch: 1528 loss_train: 1973056.0000 acc_train: 0.0782 time: 0.0187s\n",
            "Epoch: 1529 loss_train: 2262777.0000 acc_train: 0.0840 time: 0.0191s\n",
            "Epoch: 1530 loss_train: 2517427.7500 acc_train: 0.0836 time: 0.0203s\n",
            "Epoch: 1531 loss_train: 2484527.0000 acc_train: 0.0952 time: 0.0185s\n",
            "Epoch: 1532 loss_train: 2375994.2500 acc_train: 0.1035 time: 0.0177s\n",
            "Epoch: 1533 loss_train: 1902474.2500 acc_train: 0.0714 time: 0.0177s\n",
            "Epoch: 1534 loss_train: 2662710.2500 acc_train: 0.0844 time: 0.0179s\n",
            "Epoch: 1535 loss_train: 1651060.5000 acc_train: 0.0875 time: 0.0180s\n",
            "Epoch: 1536 loss_train: 2279500.7500 acc_train: 0.1150 time: 0.0182s\n",
            "Epoch: 1537 loss_train: 2444586.7500 acc_train: 0.1019 time: 0.0186s\n",
            "Epoch: 1538 loss_train: 3376096.5000 acc_train: 0.1869 time: 0.0187s\n",
            "Epoch: 1539 loss_train: 2599269.5000 acc_train: 0.1825 time: 0.0186s\n",
            "Epoch: 1540 loss_train: 4049050.5000 acc_train: 0.1012 time: 0.0185s\n",
            "Epoch: 1541 loss_train: 3023206.5000 acc_train: 0.0952 time: 0.0185s\n",
            "Epoch: 1542 loss_train: 3030262.5000 acc_train: 0.0955 time: 0.0186s\n",
            "Epoch: 1543 loss_train: 2372611.7500 acc_train: 0.1013 time: 0.0184s\n",
            "Epoch: 1544 loss_train: 2564432.2500 acc_train: 0.0996 time: 0.0198s\n",
            "Epoch: 1545 loss_train: 2625675.2500 acc_train: 0.0831 time: 0.0192s\n",
            "Epoch: 1546 loss_train: 2300254.2500 acc_train: 0.1049 time: 0.0188s\n",
            "Epoch: 1547 loss_train: 2558753.7500 acc_train: 0.1718 time: 0.0187s\n",
            "Epoch: 1548 loss_train: 2623596.7500 acc_train: 0.0927 time: 0.0186s\n",
            "Epoch: 1549 loss_train: 2018554.2500 acc_train: 0.0924 time: 0.0187s\n",
            "Epoch: 1550 loss_train: 2049676.2500 acc_train: 0.1098 time: 0.0183s\n",
            "Epoch: 1551 loss_train: 2164036.0000 acc_train: 0.0861 time: 0.0184s\n",
            "Epoch: 1552 loss_train: 1983004.0000 acc_train: 0.1415 time: 0.0186s\n",
            "Epoch: 1553 loss_train: 1865953.0000 acc_train: 0.0867 time: 0.0185s\n",
            "Epoch: 1554 loss_train: 2322128.0000 acc_train: 0.0969 time: 0.0185s\n",
            "Epoch: 1555 loss_train: 2740168.7500 acc_train: 0.1033 time: 0.0187s\n",
            "Epoch: 1556 loss_train: 2576963.2500 acc_train: 0.1339 time: 0.0188s\n",
            "Epoch: 1557 loss_train: 2092723.8750 acc_train: 0.1226 time: 0.0190s\n",
            "Epoch: 1558 loss_train: 2057793.2500 acc_train: 0.0975 time: 0.0190s\n",
            "Epoch: 1559 loss_train: 2448458.5000 acc_train: 0.0851 time: 0.0186s\n",
            "Epoch: 1560 loss_train: 2052954.5000 acc_train: 0.1765 time: 0.0182s\n",
            "Epoch: 1561 loss_train: 1914944.5000 acc_train: 0.0817 time: 0.0182s\n",
            "Epoch: 1562 loss_train: 1488364.7500 acc_train: 0.0938 time: 0.0183s\n",
            "Epoch: 1563 loss_train: 1448693.3750 acc_train: 0.0860 time: 0.0183s\n",
            "Epoch: 1564 loss_train: 2501987.0000 acc_train: 0.0905 time: 0.0184s\n",
            "Epoch: 1565 loss_train: 2818632.7500 acc_train: 0.1098 time: 0.0182s\n",
            "Epoch: 1566 loss_train: 1785186.8750 acc_train: 0.1219 time: 0.0183s\n",
            "Epoch: 1567 loss_train: 2370403.0000 acc_train: 0.1026 time: 0.0187s\n",
            "Epoch: 1568 loss_train: 2391136.0000 acc_train: 0.1014 time: 0.0191s\n",
            "Epoch: 1569 loss_train: 2732724.0000 acc_train: 0.1821 time: 0.0190s\n",
            "Epoch: 1570 loss_train: 2457649.2500 acc_train: 0.1013 time: 0.0191s\n",
            "Epoch: 1571 loss_train: 1841115.5000 acc_train: 0.0987 time: 0.0194s\n",
            "Epoch: 1572 loss_train: 1472663.7500 acc_train: 0.0940 time: 0.0197s\n",
            "Epoch: 1573 loss_train: 1957761.0000 acc_train: 0.1685 time: 0.0190s\n",
            "Epoch: 1574 loss_train: 2288913.0000 acc_train: 0.0995 time: 0.0187s\n",
            "Epoch: 1575 loss_train: 2451305.0000 acc_train: 0.1041 time: 0.0184s\n",
            "Epoch: 1576 loss_train: 2746602.5000 acc_train: 0.0948 time: 0.0182s\n",
            "Epoch: 1577 loss_train: 2884710.2500 acc_train: 0.0962 time: 0.0180s\n",
            "Epoch: 1578 loss_train: 2809572.5000 acc_train: 0.0800 time: 0.0184s\n",
            "Epoch: 1579 loss_train: 2929570.5000 acc_train: 0.0825 time: 0.0187s\n",
            "Epoch: 1580 loss_train: 3356080.0000 acc_train: 0.1788 time: 0.0186s\n",
            "Epoch: 1581 loss_train: 3114188.5000 acc_train: 0.1455 time: 0.0183s\n",
            "Epoch: 1582 loss_train: 2803661.2500 acc_train: 0.0789 time: 0.0181s\n",
            "Epoch: 1583 loss_train: 3449248.0000 acc_train: 0.0647 time: 0.0184s\n",
            "Epoch: 1584 loss_train: 2726061.7500 acc_train: 0.0834 time: 0.0187s\n",
            "Epoch: 1585 loss_train: 1884539.7500 acc_train: 0.0927 time: 0.0186s\n",
            "Epoch: 1586 loss_train: 1612968.1250 acc_train: 0.1183 time: 0.0183s\n",
            "Epoch: 1587 loss_train: 1985938.3750 acc_train: 0.1478 time: 0.0182s\n",
            "Epoch: 1588 loss_train: 3160422.7500 acc_train: 0.0984 time: 0.0182s\n",
            "Epoch: 1589 loss_train: 3371665.0000 acc_train: 0.1003 time: 0.0183s\n",
            "Epoch: 1590 loss_train: 3385477.2500 acc_train: 0.1103 time: 0.0184s\n",
            "Epoch: 1591 loss_train: 2865158.7500 acc_train: 0.0959 time: 0.0187s\n",
            "Epoch: 1592 loss_train: 3881988.0000 acc_train: 0.1287 time: 0.0185s\n",
            "Epoch: 1593 loss_train: 4014398.0000 acc_train: 0.1695 time: 0.0186s\n",
            "Epoch: 1594 loss_train: 3399794.0000 acc_train: 0.1180 time: 0.0190s\n",
            "Epoch: 1595 loss_train: 3052978.2500 acc_train: 0.0962 time: 0.0190s\n",
            "Epoch: 1596 loss_train: 2943026.0000 acc_train: 0.0822 time: 0.0192s\n",
            "Epoch: 1597 loss_train: 3376286.2500 acc_train: 0.0991 time: 0.0192s\n",
            "Epoch: 1598 loss_train: 3079730.0000 acc_train: 0.1161 time: 0.0195s\n",
            "Epoch: 1599 loss_train: 3769430.7500 acc_train: 0.1871 time: 0.0191s\n",
            "Epoch: 1600 loss_train: 2674292.5000 acc_train: 0.1837 time: 0.0187s\n",
            "Epoch: 1601 loss_train: 2651828.5000 acc_train: 0.0931 time: 0.0185s\n",
            "Epoch: 1602 loss_train: 2405359.7500 acc_train: 0.0751 time: 0.0184s\n",
            "Epoch: 1603 loss_train: 2850037.7500 acc_train: 0.0938 time: 0.0182s\n",
            "Epoch: 1604 loss_train: 3401209.0000 acc_train: 0.1009 time: 0.0182s\n",
            "Epoch: 1605 loss_train: 4138043.0000 acc_train: 0.0821 time: 0.0185s\n",
            "Epoch: 1606 loss_train: 2951876.2500 acc_train: 0.0984 time: 0.0187s\n",
            "Epoch: 1607 loss_train: 3483472.2500 acc_train: 0.0840 time: 0.0187s\n",
            "Epoch: 1608 loss_train: 3263370.2500 acc_train: 0.0944 time: 0.0185s\n",
            "Epoch: 1609 loss_train: 3440537.5000 acc_train: 0.1063 time: 0.0184s\n",
            "Epoch: 1610 loss_train: 3479664.5000 acc_train: 0.0849 time: 0.0191s\n",
            "Epoch: 1611 loss_train: 3980362.0000 acc_train: 0.0535 time: 0.0193s\n",
            "Epoch: 1612 loss_train: 2072386.7500 acc_train: 0.1654 time: 0.0196s\n",
            "Epoch: 1613 loss_train: 2037156.8750 acc_train: 0.1488 time: 0.0193s\n",
            "Epoch: 1614 loss_train: 1773881.0000 acc_train: 0.0860 time: 0.0188s\n",
            "Epoch: 1615 loss_train: 1794436.3750 acc_train: 0.0782 time: 0.0187s\n",
            "Epoch: 1616 loss_train: 1935395.5000 acc_train: 0.0986 time: 0.0184s\n",
            "Epoch: 1617 loss_train: 2738005.0000 acc_train: 0.1099 time: 0.0180s\n",
            "Epoch: 1618 loss_train: 2750914.0000 acc_train: 0.1045 time: 0.0180s\n",
            "Epoch: 1619 loss_train: 3470829.0000 acc_train: 0.1877 time: 0.0181s\n",
            "Epoch: 1620 loss_train: 2289826.5000 acc_train: 0.1365 time: 0.0183s\n",
            "Epoch: 1621 loss_train: 2317547.0000 acc_train: 0.0907 time: 0.0185s\n",
            "Epoch: 1622 loss_train: 2428973.5000 acc_train: 0.0940 time: 0.0189s\n",
            "Epoch: 1623 loss_train: 2714027.2500 acc_train: 0.0946 time: 0.0191s\n",
            "Epoch: 1624 loss_train: 1507318.2500 acc_train: 0.0896 time: 0.0193s\n",
            "Epoch: 1625 loss_train: 2627744.7500 acc_train: 0.1856 time: 0.0195s\n",
            "Epoch: 1626 loss_train: 1755407.5000 acc_train: 0.1121 time: 0.0193s\n",
            "Epoch: 1627 loss_train: 2901890.0000 acc_train: 0.0803 time: 0.0197s\n",
            "Epoch: 1628 loss_train: 2929622.0000 acc_train: 0.0958 time: 0.0193s\n",
            "Epoch: 1629 loss_train: 3219757.0000 acc_train: 0.1083 time: 0.0188s\n",
            "Epoch: 1630 loss_train: 3558870.7500 acc_train: 0.0848 time: 0.0184s\n",
            "Epoch: 1631 loss_train: 3376103.7500 acc_train: 0.0986 time: 0.0182s\n",
            "Epoch: 1632 loss_train: 3200852.0000 acc_train: 0.1706 time: 0.0185s\n",
            "Epoch: 1633 loss_train: 3918965.5000 acc_train: 0.0976 time: 0.0185s\n",
            "Epoch: 1634 loss_train: 4151944.5000 acc_train: 0.0814 time: 0.0186s\n",
            "Epoch: 1635 loss_train: 3119152.5000 acc_train: 0.0900 time: 0.0186s\n",
            "Epoch: 1636 loss_train: 3474157.5000 acc_train: 0.1733 time: 0.0187s\n",
            "Epoch: 1637 loss_train: 4568916.5000 acc_train: 0.0541 time: 0.0185s\n",
            "Epoch: 1638 loss_train: 3008981.7500 acc_train: 0.0790 time: 0.0185s\n",
            "Epoch: 1639 loss_train: 2382107.7500 acc_train: 0.1068 time: 0.0190s\n",
            "Epoch: 1640 loss_train: 2308167.7500 acc_train: 0.1633 time: 0.0190s\n",
            "Epoch: 1641 loss_train: 3095064.7500 acc_train: 0.0991 time: 0.0190s\n",
            "Epoch: 1642 loss_train: 3499980.5000 acc_train: 0.1099 time: 0.0189s\n",
            "Epoch: 1643 loss_train: 3677086.7500 acc_train: 0.0998 time: 0.0185s\n",
            "Epoch: 1644 loss_train: 4306638.0000 acc_train: 0.0870 time: 0.0184s\n",
            "Epoch: 1645 loss_train: 3767098.5000 acc_train: 0.0865 time: 0.0184s\n",
            "Epoch: 1646 loss_train: 4562630.0000 acc_train: 0.0892 time: 0.0183s\n",
            "Epoch: 1647 loss_train: 3113718.2500 acc_train: 0.0971 time: 0.0183s\n",
            "Epoch: 1648 loss_train: 4387022.0000 acc_train: 0.1873 time: 0.0185s\n",
            "Epoch: 1649 loss_train: 3881808.5000 acc_train: 0.1843 time: 0.0187s\n",
            "Epoch: 1650 loss_train: 4041780.2500 acc_train: 0.1009 time: 0.0187s\n",
            "Epoch: 1651 loss_train: 3755385.0000 acc_train: 0.0972 time: 0.0188s\n",
            "Epoch: 1652 loss_train: 4101356.2500 acc_train: 0.1077 time: 0.0188s\n",
            "Epoch: 1653 loss_train: 4059401.5000 acc_train: 0.0841 time: 0.0190s\n",
            "Epoch: 1654 loss_train: 3793907.2500 acc_train: 0.0923 time: 0.0192s\n",
            "Epoch: 1655 loss_train: 3101567.7500 acc_train: 0.0986 time: 0.0193s\n",
            "Epoch: 1656 loss_train: 2835044.5000 acc_train: 0.1098 time: 0.0197s\n",
            "Epoch: 1657 loss_train: 2449078.2500 acc_train: 0.1785 time: 0.0189s\n",
            "Epoch: 1658 loss_train: 2667199.0000 acc_train: 0.0965 time: 0.0188s\n",
            "Epoch: 1659 loss_train: 2742242.0000 acc_train: 0.0883 time: 0.0186s\n",
            "Epoch: 1660 loss_train: 2650084.2500 acc_train: 0.0826 time: 0.0182s\n",
            "Epoch: 1661 loss_train: 2276416.0000 acc_train: 0.1276 time: 0.0181s\n",
            "Epoch: 1662 loss_train: 2662895.7500 acc_train: 0.1002 time: 0.0180s\n",
            "Epoch: 1663 loss_train: 2599615.0000 acc_train: 0.1255 time: 0.0180s\n",
            "Epoch: 1664 loss_train: 2275951.0000 acc_train: 0.1758 time: 0.0183s\n",
            "Epoch: 1665 loss_train: 2404183.2500 acc_train: 0.0957 time: 0.0189s\n",
            "Epoch: 1666 loss_train: 2205153.5000 acc_train: 0.0921 time: 0.0194s\n",
            "Epoch: 1667 loss_train: 1259165.2500 acc_train: 0.0901 time: 0.0195s\n",
            "Epoch: 1668 loss_train: 1877006.3750 acc_train: 0.0958 time: 0.0194s\n",
            "Epoch: 1669 loss_train: 2484083.7500 acc_train: 0.0808 time: 0.0195s\n",
            "Epoch: 1670 loss_train: 2170606.2500 acc_train: 0.0892 time: 0.0195s\n",
            "Epoch: 1671 loss_train: 2594439.0000 acc_train: 0.1413 time: 0.0197s\n",
            "Epoch: 1672 loss_train: 2545569.2500 acc_train: 0.1779 time: 0.0192s\n",
            "Epoch: 1673 loss_train: 2056528.6250 acc_train: 0.0987 time: 0.0187s\n",
            "Epoch: 1674 loss_train: 2789313.5000 acc_train: 0.0891 time: 0.0184s\n",
            "Epoch: 1675 loss_train: 3321762.5000 acc_train: 0.1007 time: 0.0184s\n",
            "Epoch: 1676 loss_train: 3154315.7500 acc_train: 0.1096 time: 0.0184s\n",
            "Epoch: 1677 loss_train: 2300219.7500 acc_train: 0.0940 time: 0.0185s\n",
            "Epoch: 1678 loss_train: 2325626.5000 acc_train: 0.0960 time: 0.0186s\n",
            "Epoch: 1679 loss_train: 2215201.0000 acc_train: 0.1017 time: 0.0186s\n",
            "Epoch: 1680 loss_train: 2718751.0000 acc_train: 0.1861 time: 0.0184s\n",
            "Epoch: 1681 loss_train: 2169627.0000 acc_train: 0.0837 time: 0.0185s\n",
            "Epoch: 1682 loss_train: 2403689.2500 acc_train: 0.0857 time: 0.0189s\n",
            "Epoch: 1683 loss_train: 1953634.7500 acc_train: 0.1340 time: 0.0191s\n",
            "Epoch: 1684 loss_train: 1831696.5000 acc_train: 0.1255 time: 0.0195s\n",
            "Epoch: 1685 loss_train: 1975322.0000 acc_train: 0.0989 time: 0.0197s\n",
            "Epoch: 1686 loss_train: 1861780.1250 acc_train: 0.0946 time: 0.0200s\n",
            "Epoch: 1687 loss_train: 2038381.2500 acc_train: 0.0941 time: 0.0193s\n",
            "Epoch: 1688 loss_train: 1883271.2500 acc_train: 0.1071 time: 0.0190s\n",
            "Epoch: 1689 loss_train: 2679702.2500 acc_train: 0.0854 time: 0.0188s\n",
            "Epoch: 1690 loss_train: 2840537.0000 acc_train: 0.0984 time: 0.0186s\n",
            "Epoch: 1691 loss_train: 1642810.1250 acc_train: 0.1709 time: 0.0182s\n",
            "Epoch: 1692 loss_train: 2630567.7500 acc_train: 0.0831 time: 0.0183s\n",
            "Epoch: 1693 loss_train: 2827210.0000 acc_train: 0.0804 time: 0.0185s\n",
            "Epoch: 1694 loss_train: 2641689.2500 acc_train: 0.0824 time: 0.0185s\n",
            "Epoch: 1695 loss_train: 2014139.0000 acc_train: 0.1722 time: 0.0183s\n",
            "Epoch: 1696 loss_train: 1853041.5000 acc_train: 0.1011 time: 0.0182s\n",
            "Epoch: 1697 loss_train: 1594779.7500 acc_train: 0.1114 time: 0.0184s\n",
            "Epoch: 1698 loss_train: 1771845.6250 acc_train: 0.1069 time: 0.0189s\n",
            "Epoch: 1699 loss_train: 1967568.5000 acc_train: 0.1109 time: 0.0193s\n",
            "Epoch: 1700 loss_train: 2443510.5000 acc_train: 0.1135 time: 0.0195s\n",
            "Epoch: 1701 loss_train: 2889074.2500 acc_train: 0.1080 time: 0.0189s\n",
            "Epoch: 1702 loss_train: 2345048.0000 acc_train: 0.1042 time: 0.0187s\n",
            "Epoch: 1703 loss_train: 1698398.7500 acc_train: 0.0930 time: 0.0183s\n",
            "Epoch: 1704 loss_train: 2471227.5000 acc_train: 0.0993 time: 0.0181s\n",
            "Epoch: 1705 loss_train: 2293483.2500 acc_train: 0.1838 time: 0.0182s\n",
            "Epoch: 1706 loss_train: 2189395.0000 acc_train: 0.0880 time: 0.0183s\n",
            "Epoch: 1707 loss_train: 3878095.2500 acc_train: 0.1014 time: 0.0182s\n",
            "Epoch: 1708 loss_train: 3106196.0000 acc_train: 0.1021 time: 0.0181s\n",
            "Epoch: 1709 loss_train: 2873122.5000 acc_train: 0.1833 time: 0.0184s\n",
            "Epoch: 1710 loss_train: 2396469.7500 acc_train: 0.1760 time: 0.0187s\n",
            "Epoch: 1711 loss_train: 2677463.5000 acc_train: 0.0968 time: 0.0191s\n",
            "Epoch: 1712 loss_train: 3105988.5000 acc_train: 0.0790 time: 0.0193s\n",
            "Epoch: 1713 loss_train: 4548663.5000 acc_train: 0.0855 time: 0.0187s\n",
            "Epoch: 1714 loss_train: 4650906.5000 acc_train: 0.1108 time: 0.0184s\n",
            "Epoch: 1715 loss_train: 5004094.0000 acc_train: 0.0608 time: 0.0183s\n",
            "Epoch: 1716 loss_train: 5324817.0000 acc_train: 0.0952 time: 0.0186s\n",
            "Epoch: 1717 loss_train: 5461038.5000 acc_train: 0.0899 time: 0.0183s\n",
            "Epoch: 1718 loss_train: 4209188.5000 acc_train: 0.0966 time: 0.0184s\n",
            "Epoch: 1719 loss_train: 4011399.2500 acc_train: 0.1108 time: 0.0183s\n",
            "Epoch: 1720 loss_train: 3487134.7500 acc_train: 0.0998 time: 0.0185s\n",
            "Epoch: 1721 loss_train: 2611011.2500 acc_train: 0.0812 time: 0.0188s\n",
            "Epoch: 1722 loss_train: 3449535.5000 acc_train: 0.1016 time: 0.0190s\n",
            "Epoch: 1723 loss_train: 4686058.5000 acc_train: 0.1868 time: 0.0194s\n",
            "Epoch: 1724 loss_train: 4073372.2500 acc_train: 0.1855 time: 0.0197s\n",
            "Epoch: 1725 loss_train: 3674490.7500 acc_train: 0.0851 time: 0.0195s\n",
            "Epoch: 1726 loss_train: 3493861.7500 acc_train: 0.0956 time: 0.0193s\n",
            "Epoch: 1727 loss_train: 2891545.0000 acc_train: 0.0869 time: 0.0198s\n",
            "Epoch: 1728 loss_train: 2355620.2500 acc_train: 0.0976 time: 0.0193s\n",
            "Epoch: 1729 loss_train: 2381938.5000 acc_train: 0.1002 time: 0.0188s\n",
            "Epoch: 1730 loss_train: 3233295.2500 acc_train: 0.1101 time: 0.0184s\n",
            "Epoch: 1731 loss_train: 3070541.2500 acc_train: 0.1796 time: 0.0181s\n",
            "Epoch: 1732 loss_train: 3060038.7500 acc_train: 0.0876 time: 0.0180s\n",
            "Epoch: 1733 loss_train: 3481313.2500 acc_train: 0.0972 time: 0.0179s\n",
            "Epoch: 1734 loss_train: 3185139.7500 acc_train: 0.0950 time: 0.0180s\n",
            "Epoch: 1735 loss_train: 1995141.3750 acc_train: 0.1105 time: 0.0181s\n",
            "Epoch: 1736 loss_train: 2118846.2500 acc_train: 0.1073 time: 0.0187s\n",
            "Epoch: 1737 loss_train: 2136632.7500 acc_train: 0.1843 time: 0.0191s\n",
            "Epoch: 1738 loss_train: 3769865.0000 acc_train: 0.0985 time: 0.0193s\n",
            "Epoch: 1739 loss_train: 3301648.7500 acc_train: 0.0738 time: 0.0193s\n",
            "Epoch: 1740 loss_train: 2409569.5000 acc_train: 0.0688 time: 0.0195s\n",
            "Epoch: 1741 loss_train: 2722035.2500 acc_train: 0.1112 time: 0.0193s\n",
            "Epoch: 1742 loss_train: 2303636.2500 acc_train: 0.1501 time: 0.0190s\n",
            "Epoch: 1743 loss_train: 2931590.2500 acc_train: 0.0977 time: 0.0188s\n",
            "Epoch: 1744 loss_train: 2665481.7500 acc_train: 0.1021 time: 0.0186s\n",
            "Epoch: 1745 loss_train: 2287914.7500 acc_train: 0.0887 time: 0.0183s\n",
            "Epoch: 1746 loss_train: 2474248.0000 acc_train: 0.0852 time: 0.0180s\n",
            "Epoch: 1747 loss_train: 2978344.5000 acc_train: 0.1866 time: 0.0179s\n",
            "Epoch: 1748 loss_train: 2251978.2500 acc_train: 0.1759 time: 0.0179s\n",
            "Epoch: 1749 loss_train: 2521400.2500 acc_train: 0.0850 time: 0.0181s\n",
            "Epoch: 1750 loss_train: 2599625.7500 acc_train: 0.0861 time: 0.0185s\n",
            "Epoch: 1751 loss_train: 2158520.7500 acc_train: 0.0890 time: 0.0186s\n",
            "Epoch: 1752 loss_train: 2590263.0000 acc_train: 0.0854 time: 0.0193s\n",
            "Epoch: 1753 loss_train: 2799600.0000 acc_train: 0.1071 time: 0.0189s\n",
            "Epoch: 1754 loss_train: 2840524.5000 acc_train: 0.0962 time: 0.0187s\n",
            "Epoch: 1755 loss_train: 3994904.5000 acc_train: 0.0965 time: 0.0185s\n",
            "Epoch: 1756 loss_train: 2709652.0000 acc_train: 0.0994 time: 0.0183s\n",
            "Epoch: 1757 loss_train: 2585187.0000 acc_train: 0.0812 time: 0.0184s\n",
            "Epoch: 1758 loss_train: 2419477.0000 acc_train: 0.1046 time: 0.0183s\n",
            "Epoch: 1759 loss_train: 2865108.0000 acc_train: 0.1116 time: 0.0184s\n",
            "Epoch: 1760 loss_train: 3197541.7500 acc_train: 0.1812 time: 0.0182s\n",
            "Epoch: 1761 loss_train: 2461385.0000 acc_train: 0.0735 time: 0.0180s\n",
            "Epoch: 1762 loss_train: 1796119.2500 acc_train: 0.0813 time: 0.0181s\n",
            "Epoch: 1763 loss_train: 2420814.2500 acc_train: 0.0902 time: 0.0187s\n",
            "Epoch: 1764 loss_train: 2392907.2500 acc_train: 0.0870 time: 0.0192s\n",
            "Epoch: 1765 loss_train: 2284343.2500 acc_train: 0.1710 time: 0.0187s\n",
            "Epoch: 1766 loss_train: 3483426.5000 acc_train: 0.1022 time: 0.0186s\n",
            "Epoch: 1767 loss_train: 3466404.5000 acc_train: 0.0961 time: 0.0185s\n",
            "Epoch: 1768 loss_train: 3120943.5000 acc_train: 0.0983 time: 0.0182s\n",
            "Epoch: 1769 loss_train: 3159861.2500 acc_train: 0.1774 time: 0.0181s\n",
            "Epoch: 1770 loss_train: 4028987.7500 acc_train: 0.1010 time: 0.0180s\n",
            "Epoch: 1771 loss_train: 3348737.0000 acc_train: 0.1137 time: 0.0180s\n",
            "Epoch: 1772 loss_train: 3551116.0000 acc_train: 0.1819 time: 0.0181s\n",
            "Epoch: 1773 loss_train: 4070499.0000 acc_train: 0.1048 time: 0.0184s\n",
            "Epoch: 1774 loss_train: 3589862.5000 acc_train: 0.1091 time: 0.0192s\n",
            "Epoch: 1775 loss_train: 2393607.7500 acc_train: 0.1087 time: 0.0193s\n",
            "Epoch: 1776 loss_train: 2355619.5000 acc_train: 0.0821 time: 0.0194s\n",
            "Epoch: 1777 loss_train: 4004092.5000 acc_train: 0.0887 time: 0.0201s\n",
            "Epoch: 1778 loss_train: 3853779.7500 acc_train: 0.0917 time: 0.0201s\n",
            "Epoch: 1779 loss_train: 2439699.0000 acc_train: 0.0993 time: 0.0202s\n",
            "Epoch: 1780 loss_train: 3546009.5000 acc_train: 0.0884 time: 0.0201s\n",
            "Epoch: 1781 loss_train: 4485608.5000 acc_train: 0.1863 time: 0.0201s\n",
            "Epoch: 1782 loss_train: 4581004.0000 acc_train: 0.1308 time: 0.0199s\n",
            "Epoch: 1783 loss_train: 4845131.0000 acc_train: 0.0549 time: 0.0197s\n",
            "Epoch: 1784 loss_train: 3111800.7500 acc_train: 0.1462 time: 0.0189s\n",
            "Epoch: 1785 loss_train: 3122491.5000 acc_train: 0.0977 time: 0.0187s\n",
            "Epoch: 1786 loss_train: 3586433.2500 acc_train: 0.1045 time: 0.0185s\n",
            "Epoch: 1787 loss_train: 3238941.2500 acc_train: 0.0982 time: 0.0183s\n",
            "Epoch: 1788 loss_train: 2659163.0000 acc_train: 0.1071 time: 0.0182s\n",
            "Epoch: 1789 loss_train: 2900374.0000 acc_train: 0.0825 time: 0.0183s\n",
            "Epoch: 1790 loss_train: 3412890.2500 acc_train: 0.0940 time: 0.0181s\n",
            "Epoch: 1791 loss_train: 2951693.7500 acc_train: 0.0884 time: 0.0180s\n",
            "Epoch: 1792 loss_train: 3649128.2500 acc_train: 0.0974 time: 0.0182s\n",
            "Epoch: 1793 loss_train: 3752841.0000 acc_train: 0.1828 time: 0.0191s\n",
            "Epoch: 1794 loss_train: 3448838.2500 acc_train: 0.1814 time: 0.0195s\n",
            "Epoch: 1795 loss_train: 3481790.7500 acc_train: 0.0825 time: 0.0199s\n",
            "Epoch: 1796 loss_train: 4547719.0000 acc_train: 0.0986 time: 0.0197s\n",
            "Epoch: 1797 loss_train: 4288829.0000 acc_train: 0.0985 time: 0.0197s\n",
            "Epoch: 1798 loss_train: 3852276.7500 acc_train: 0.0957 time: 0.0195s\n",
            "Epoch: 1799 loss_train: 2968095.0000 acc_train: 0.0967 time: 0.0193s\n",
            "Epoch: 1800 loss_train: 2163216.0000 acc_train: 0.0933 time: 0.0191s\n",
            "Epoch: 1801 loss_train: 3121948.7500 acc_train: 0.1834 time: 0.0189s\n",
            "Epoch: 1802 loss_train: 2982149.7500 acc_train: 0.1260 time: 0.0188s\n",
            "Epoch: 1803 loss_train: 3144900.0000 acc_train: 0.0897 time: 0.0186s\n",
            "Epoch: 1804 loss_train: 2272488.7500 acc_train: 0.1579 time: 0.0184s\n",
            "Epoch: 1805 loss_train: 2261601.5000 acc_train: 0.0940 time: 0.0184s\n",
            "Epoch: 1806 loss_train: 2573808.0000 acc_train: 0.1084 time: 0.0185s\n",
            "Epoch: 1807 loss_train: 3248113.7500 acc_train: 0.0646 time: 0.0185s\n",
            "Epoch: 1808 loss_train: 3966627.7500 acc_train: 0.0971 time: 0.0186s\n",
            "Epoch: 1809 loss_train: 2488554.0000 acc_train: 0.0910 time: 0.0185s\n",
            "Epoch: 1810 loss_train: 3447428.7500 acc_train: 0.0840 time: 0.0186s\n",
            "Epoch: 1811 loss_train: 2794052.7500 acc_train: 0.0811 time: 0.0188s\n",
            "Epoch: 1812 loss_train: 1685844.1250 acc_train: 0.1038 time: 0.0190s\n",
            "Epoch: 1813 loss_train: 1931573.2500 acc_train: 0.1865 time: 0.0200s\n",
            "Epoch: 1814 loss_train: 1798626.8750 acc_train: 0.0856 time: 0.0196s\n",
            "Epoch: 1815 loss_train: 2742946.2500 acc_train: 0.0930 time: 0.0191s\n",
            "Epoch: 1816 loss_train: 2877889.0000 acc_train: 0.0985 time: 0.0189s\n",
            "Epoch: 1817 loss_train: 2231891.2500 acc_train: 0.0933 time: 0.0188s\n",
            "Epoch: 1818 loss_train: 2941478.2500 acc_train: 0.1883 time: 0.0185s\n",
            "Epoch: 1819 loss_train: 3603528.5000 acc_train: 0.1007 time: 0.0183s\n",
            "Epoch: 1820 loss_train: 3762353.0000 acc_train: 0.1119 time: 0.0182s\n",
            "Epoch: 1821 loss_train: 2793597.2500 acc_train: 0.1543 time: 0.0181s\n",
            "Epoch: 1822 loss_train: 3309274.5000 acc_train: 0.0955 time: 0.0181s\n",
            "Epoch: 1823 loss_train: 2300190.7500 acc_train: 0.0814 time: 0.0182s\n",
            "Epoch: 1824 loss_train: 1751537.6250 acc_train: 0.0961 time: 0.0186s\n",
            "Epoch: 1825 loss_train: 1477047.7500 acc_train: 0.1272 time: 0.0188s\n",
            "Epoch: 1826 loss_train: 1359680.3750 acc_train: 0.1290 time: 0.0193s\n",
            "Epoch: 1827 loss_train: 2872476.2500 acc_train: 0.0838 time: 0.0189s\n",
            "Epoch: 1828 loss_train: 2112893.7500 acc_train: 0.0855 time: 0.0186s\n",
            "Epoch: 1829 loss_train: 2116648.7500 acc_train: 0.1627 time: 0.0186s\n",
            "Epoch: 1830 loss_train: 2574564.5000 acc_train: 0.0866 time: 0.0186s\n",
            "Epoch: 1831 loss_train: 2957987.0000 acc_train: 0.0948 time: 0.0186s\n",
            "Epoch: 1832 loss_train: 3185462.0000 acc_train: 0.0972 time: 0.0187s\n",
            "Epoch: 1833 loss_train: 2497394.5000 acc_train: 0.1098 time: 0.0189s\n",
            "Epoch: 1834 loss_train: 3030007.5000 acc_train: 0.1017 time: 0.0188s\n",
            "Epoch: 1835 loss_train: 2302212.7500 acc_train: 0.0972 time: 0.0188s\n",
            "Epoch: 1836 loss_train: 3416445.5000 acc_train: 0.1859 time: 0.0187s\n",
            "Epoch: 1837 loss_train: 3382401.0000 acc_train: 0.1034 time: 0.0187s\n",
            "Epoch: 1838 loss_train: 3813392.0000 acc_train: 0.0621 time: 0.0190s\n",
            "Epoch: 1839 loss_train: 3658130.0000 acc_train: 0.0926 time: 0.0189s\n",
            "Epoch: 1840 loss_train: 3822264.7500 acc_train: 0.1810 time: 0.0189s\n",
            "Epoch: 1841 loss_train: 2898597.0000 acc_train: 0.0997 time: 0.0191s\n",
            "Epoch: 1842 loss_train: 2803846.0000 acc_train: 0.0876 time: 0.0186s\n",
            "Epoch: 1843 loss_train: 2883033.0000 acc_train: 0.0969 time: 0.0184s\n",
            "Epoch: 1844 loss_train: 2931674.0000 acc_train: 0.1066 time: 0.0184s\n",
            "Epoch: 1845 loss_train: 2919710.2500 acc_train: 0.0937 time: 0.0183s\n",
            "Epoch: 1846 loss_train: 2425527.7500 acc_train: 0.0959 time: 0.0186s\n",
            "Epoch: 1847 loss_train: 1421365.2500 acc_train: 0.1054 time: 0.0186s\n",
            "Epoch: 1848 loss_train: 1925848.5000 acc_train: 0.1354 time: 0.0186s\n",
            "Epoch: 1849 loss_train: 2589707.5000 acc_train: 0.1864 time: 0.0185s\n",
            "Epoch: 1850 loss_train: 2626740.0000 acc_train: 0.0875 time: 0.0186s\n",
            "Epoch: 1851 loss_train: 3080701.7500 acc_train: 0.1023 time: 0.0190s\n",
            "Epoch: 1852 loss_train: 2001382.2500 acc_train: 0.1130 time: 0.0192s\n",
            "Epoch: 1853 loss_train: 1944617.7500 acc_train: 0.1781 time: 0.0193s\n",
            "Epoch: 1854 loss_train: 1967385.3750 acc_train: 0.0872 time: 0.0192s\n",
            "Epoch: 1855 loss_train: 2257941.0000 acc_train: 0.0788 time: 0.0193s\n",
            "Epoch: 1856 loss_train: 2117860.2500 acc_train: 0.0557 time: 0.0197s\n",
            "Epoch: 1857 loss_train: 1947548.0000 acc_train: 0.0940 time: 0.0191s\n",
            "Epoch: 1858 loss_train: 2225563.7500 acc_train: 0.0969 time: 0.0189s\n",
            "Epoch: 1859 loss_train: 2320932.7500 acc_train: 0.1082 time: 0.0187s\n",
            "Epoch: 1860 loss_train: 1814370.0000 acc_train: 0.0926 time: 0.0186s\n",
            "Epoch: 1861 loss_train: 1487350.0000 acc_train: 0.1822 time: 0.0182s\n",
            "Epoch: 1862 loss_train: 2100729.0000 acc_train: 0.0903 time: 0.0182s\n",
            "Epoch: 1863 loss_train: 2829664.0000 acc_train: 0.0834 time: 0.0182s\n",
            "Epoch: 1864 loss_train: 1934453.6250 acc_train: 0.0867 time: 0.0182s\n",
            "Epoch: 1865 loss_train: 1758784.3750 acc_train: 0.0943 time: 0.0182s\n",
            "Epoch: 1866 loss_train: 2012621.1250 acc_train: 0.1865 time: 0.0184s\n",
            "Epoch: 1867 loss_train: 1783277.2500 acc_train: 0.1625 time: 0.0186s\n",
            "Epoch: 1868 loss_train: 2379537.5000 acc_train: 0.0969 time: 0.0189s\n",
            "Epoch: 1869 loss_train: 2899036.2500 acc_train: 0.0958 time: 0.0189s\n",
            "Epoch: 1870 loss_train: 2503527.2500 acc_train: 0.0970 time: 0.0188s\n",
            "Epoch: 1871 loss_train: 2029255.3750 acc_train: 0.0954 time: 0.0185s\n",
            "Epoch: 1872 loss_train: 2390757.5000 acc_train: 0.0907 time: 0.0185s\n",
            "Epoch: 1873 loss_train: 2827031.5000 acc_train: 0.1093 time: 0.0182s\n",
            "Epoch: 1874 loss_train: 2319434.2500 acc_train: 0.1329 time: 0.0182s\n",
            "Epoch: 1875 loss_train: 2570564.2500 acc_train: 0.1851 time: 0.0181s\n",
            "Epoch: 1876 loss_train: 2119700.5000 acc_train: 0.0909 time: 0.0181s\n",
            "Epoch: 1877 loss_train: 2076712.0000 acc_train: 0.0713 time: 0.0184s\n",
            "Epoch: 1878 loss_train: 2539507.7500 acc_train: 0.0741 time: 0.0189s\n",
            "Epoch: 1879 loss_train: 1523805.7500 acc_train: 0.0711 time: 0.0191s\n",
            "Epoch: 1880 loss_train: 1549872.0000 acc_train: 0.1252 time: 0.0195s\n",
            "Epoch: 1881 loss_train: 2143021.2500 acc_train: 0.1782 time: 0.0195s\n",
            "Epoch: 1882 loss_train: 2995606.2500 acc_train: 0.0859 time: 0.0202s\n",
            "Epoch: 1883 loss_train: 2728824.5000 acc_train: 0.1100 time: 0.0201s\n",
            "Epoch: 1884 loss_train: 2125951.2500 acc_train: 0.0953 time: 0.0201s\n",
            "Epoch: 1885 loss_train: 2423868.0000 acc_train: 0.0993 time: 0.0199s\n",
            "Epoch: 1886 loss_train: 2095468.2500 acc_train: 0.0936 time: 0.0199s\n",
            "Epoch: 1887 loss_train: 1993605.7500 acc_train: 0.0961 time: 0.0193s\n",
            "Epoch: 1888 loss_train: 1530422.8750 acc_train: 0.1536 time: 0.0191s\n",
            "Epoch: 1889 loss_train: 2094666.6250 acc_train: 0.0771 time: 0.0192s\n",
            "Epoch: 1890 loss_train: 1873463.1250 acc_train: 0.1562 time: 0.0187s\n",
            "Epoch: 1891 loss_train: 2269168.2500 acc_train: 0.0974 time: 0.0186s\n",
            "Epoch: 1892 loss_train: 1780919.8750 acc_train: 0.1051 time: 0.0184s\n",
            "Epoch: 1893 loss_train: 1651862.8750 acc_train: 0.1204 time: 0.0187s\n",
            "Epoch: 1894 loss_train: 1537448.2500 acc_train: 0.1024 time: 0.0189s\n",
            "Epoch: 1895 loss_train: 1357313.6250 acc_train: 0.1333 time: 0.0188s\n",
            "Epoch: 1896 loss_train: 1593657.6250 acc_train: 0.1015 time: 0.0187s\n",
            "Epoch: 1897 loss_train: 1293253.2500 acc_train: 0.1724 time: 0.0187s\n",
            "Epoch: 1898 loss_train: 1656942.5000 acc_train: 0.0842 time: 0.0186s\n",
            "Epoch: 1899 loss_train: 1797374.0000 acc_train: 0.0952 time: 0.0187s\n",
            "Epoch: 1900 loss_train: 1642945.5000 acc_train: 0.0952 time: 0.0191s\n",
            "Epoch: 1901 loss_train: 1236130.8750 acc_train: 0.0996 time: 0.0191s\n",
            "Epoch: 1902 loss_train: 2086314.7500 acc_train: 0.1104 time: 0.0191s\n",
            "Epoch: 1903 loss_train: 2046162.5000 acc_train: 0.1707 time: 0.0187s\n",
            "Epoch: 1904 loss_train: 2573014.7500 acc_train: 0.0545 time: 0.0186s\n",
            "Epoch: 1905 loss_train: 2470149.5000 acc_train: 0.0800 time: 0.0186s\n",
            "Epoch: 1906 loss_train: 2779187.5000 acc_train: 0.0974 time: 0.0183s\n",
            "Epoch: 1907 loss_train: 1847958.5000 acc_train: 0.1247 time: 0.0184s\n",
            "Epoch: 1908 loss_train: 2480125.0000 acc_train: 0.0874 time: 0.0188s\n",
            "Epoch: 1909 loss_train: 2094709.0000 acc_train: 0.1717 time: 0.0189s\n",
            "Epoch: 1910 loss_train: 2272486.5000 acc_train: 0.0998 time: 0.0191s\n",
            "Epoch: 1911 loss_train: 1472857.0000 acc_train: 0.1849 time: 0.0189s\n",
            "Epoch: 1912 loss_train: 2134786.7500 acc_train: 0.0951 time: 0.0186s\n",
            "Epoch: 1913 loss_train: 2952233.2500 acc_train: 0.0961 time: 0.0186s\n",
            "Epoch: 1914 loss_train: 2310431.2500 acc_train: 0.0993 time: 0.0189s\n",
            "Epoch: 1915 loss_train: 2509466.7500 acc_train: 0.1102 time: 0.0189s\n",
            "Epoch: 1916 loss_train: 1997379.3750 acc_train: 0.0993 time: 0.0191s\n",
            "Epoch: 1917 loss_train: 2811530.2500 acc_train: 0.0878 time: 0.0194s\n",
            "Epoch: 1918 loss_train: 1966212.0000 acc_train: 0.0846 time: 0.0189s\n",
            "Epoch: 1919 loss_train: 3120934.5000 acc_train: 0.0542 time: 0.0187s\n",
            "Epoch: 1920 loss_train: 3045878.7500 acc_train: 0.1864 time: 0.0186s\n",
            "Epoch: 1921 loss_train: 2613872.7500 acc_train: 0.1801 time: 0.0186s\n",
            "Epoch: 1922 loss_train: 2950372.2500 acc_train: 0.0945 time: 0.0183s\n",
            "Epoch: 1923 loss_train: 3492312.0000 acc_train: 0.0991 time: 0.0183s\n",
            "Epoch: 1924 loss_train: 4732859.0000 acc_train: 0.0840 time: 0.0184s\n",
            "Epoch: 1925 loss_train: 2795810.5000 acc_train: 0.0947 time: 0.0194s\n",
            "Epoch: 1926 loss_train: 2859101.0000 acc_train: 0.1004 time: 0.0185s\n",
            "Epoch: 1927 loss_train: 2078930.1250 acc_train: 0.0989 time: 0.0187s\n",
            "Epoch: 1928 loss_train: 1061719.7500 acc_train: 0.0847 time: 0.0179s\n",
            "Epoch: 1929 loss_train: 1649818.6250 acc_train: 0.1520 time: 0.0181s\n",
            "Epoch: 1930 loss_train: 1978121.7500 acc_train: 0.1422 time: 0.0187s\n",
            "Epoch: 1931 loss_train: 1290543.6250 acc_train: 0.1122 time: 0.0187s\n",
            "Epoch: 1932 loss_train: 1508873.1250 acc_train: 0.0946 time: 0.0186s\n",
            "Epoch: 1933 loss_train: 1433222.7500 acc_train: 0.0856 time: 0.0186s\n",
            "Epoch: 1934 loss_train: 1977428.1250 acc_train: 0.0976 time: 0.0186s\n",
            "Epoch: 1935 loss_train: 1918433.3750 acc_train: 0.1451 time: 0.0187s\n",
            "Epoch: 1936 loss_train: 2139814.0000 acc_train: 0.1140 time: 0.0190s\n",
            "Epoch: 1937 loss_train: 2034901.8750 acc_train: 0.1860 time: 0.0192s\n",
            "Epoch: 1938 loss_train: 1778722.7500 acc_train: 0.1038 time: 0.0192s\n",
            "Epoch: 1939 loss_train: 1239652.0000 acc_train: 0.0961 time: 0.0191s\n",
            "Epoch: 1940 loss_train: 1715908.5000 acc_train: 0.0946 time: 0.0190s\n",
            "Epoch: 1941 loss_train: 2330609.2500 acc_train: 0.0818 time: 0.0191s\n",
            "Epoch: 1942 loss_train: 1177526.2500 acc_train: 0.0929 time: 0.0191s\n",
            "Epoch: 1943 loss_train: 1137774.3750 acc_train: 0.1053 time: 0.0189s\n",
            "Epoch: 1944 loss_train: 1328399.2500 acc_train: 0.1192 time: 0.0189s\n",
            "Epoch: 1945 loss_train: 1620119.1250 acc_train: 0.0904 time: 0.0192s\n",
            "Epoch: 1946 loss_train: 1846823.2500 acc_train: 0.0922 time: 0.0197s\n",
            "Epoch: 1947 loss_train: 2553070.7500 acc_train: 0.1035 time: 0.0195s\n",
            "Epoch: 1948 loss_train: 2863013.0000 acc_train: 0.1164 time: 0.0191s\n",
            "Epoch: 1949 loss_train: 3271999.0000 acc_train: 0.1869 time: 0.0187s\n",
            "Epoch: 1950 loss_train: 2388582.5000 acc_train: 0.1864 time: 0.0186s\n",
            "Epoch: 1951 loss_train: 1817194.0000 acc_train: 0.0865 time: 0.0184s\n",
            "Epoch: 1952 loss_train: 2113705.5000 acc_train: 0.0974 time: 0.0183s\n",
            "Epoch: 1953 loss_train: 3168109.7500 acc_train: 0.0937 time: 0.0183s\n",
            "Epoch: 1954 loss_train: 3114179.0000 acc_train: 0.0925 time: 0.0185s\n",
            "Epoch: 1955 loss_train: 3118916.2500 acc_train: 0.1042 time: 0.0188s\n",
            "Epoch: 1956 loss_train: 3215398.2500 acc_train: 0.1115 time: 0.0187s\n",
            "Epoch: 1957 loss_train: 2949554.5000 acc_train: 0.0731 time: 0.0188s\n",
            "Epoch: 1958 loss_train: 2682877.0000 acc_train: 0.0884 time: 0.0189s\n",
            "Epoch: 1959 loss_train: 1962355.7500 acc_train: 0.0886 time: 0.0193s\n",
            "Epoch: 1960 loss_train: 2371017.2500 acc_train: 0.0977 time: 0.0194s\n",
            "Epoch: 1961 loss_train: 1874906.6250 acc_train: 0.0898 time: 0.0193s\n",
            "Epoch: 1962 loss_train: 3517145.0000 acc_train: 0.1876 time: 0.0195s\n",
            "Epoch: 1963 loss_train: 3476824.0000 acc_train: 0.1874 time: 0.0197s\n",
            "Epoch: 1964 loss_train: 2129469.2500 acc_train: 0.1764 time: 0.0201s\n",
            "Epoch: 1965 loss_train: 2382112.2500 acc_train: 0.0944 time: 0.0195s\n",
            "Epoch: 1966 loss_train: 2396732.7500 acc_train: 0.0588 time: 0.0191s\n",
            "Epoch: 1967 loss_train: 2747656.5000 acc_train: 0.0775 time: 0.0187s\n",
            "Epoch: 1968 loss_train: 3182010.7500 acc_train: 0.0915 time: 0.0186s\n",
            "Epoch: 1969 loss_train: 3268687.7500 acc_train: 0.0953 time: 0.0186s\n",
            "Epoch: 1970 loss_train: 3397842.5000 acc_train: 0.1097 time: 0.0185s\n",
            "Epoch: 1971 loss_train: 3400882.0000 acc_train: 0.0933 time: 0.0185s\n",
            "Epoch: 1972 loss_train: 2836506.0000 acc_train: 0.0873 time: 0.0186s\n",
            "Epoch: 1973 loss_train: 2911274.7500 acc_train: 0.0937 time: 0.0185s\n",
            "Epoch: 1974 loss_train: 2614780.7500 acc_train: 0.0938 time: 0.0184s\n",
            "Epoch: 1975 loss_train: 2486792.5000 acc_train: 0.0841 time: 0.0183s\n",
            "Epoch: 1976 loss_train: 2046678.2500 acc_train: 0.0940 time: 0.0183s\n",
            "Epoch: 1977 loss_train: 1745868.6250 acc_train: 0.0771 time: 0.0186s\n",
            "Epoch: 1978 loss_train: 1959416.3750 acc_train: 0.1563 time: 0.0193s\n",
            "Epoch: 1979 loss_train: 2692093.2500 acc_train: 0.1878 time: 0.0190s\n",
            "Epoch: 1980 loss_train: 1618903.6250 acc_train: 0.1942 time: 0.0186s\n",
            "Epoch: 1981 loss_train: 2032909.5000 acc_train: 0.0933 time: 0.0185s\n",
            "Epoch: 1982 loss_train: 3011161.2500 acc_train: 0.0964 time: 0.0185s\n",
            "Epoch: 1983 loss_train: 3219017.2500 acc_train: 0.0931 time: 0.0183s\n",
            "Epoch: 1984 loss_train: 2866759.5000 acc_train: 0.0993 time: 0.0184s\n",
            "Epoch: 1985 loss_train: 2862205.0000 acc_train: 0.0962 time: 0.0184s\n",
            "Epoch: 1986 loss_train: 2724296.7500 acc_train: 0.0813 time: 0.0185s\n",
            "Epoch: 1987 loss_train: 3102559.2500 acc_train: 0.0841 time: 0.0185s\n",
            "Epoch: 1988 loss_train: 2218245.7500 acc_train: 0.1101 time: 0.0187s\n",
            "Epoch: 1989 loss_train: 1125265.8750 acc_train: 0.0778 time: 0.0190s\n",
            "Epoch: 1990 loss_train: 2098126.7500 acc_train: 0.1182 time: 0.0194s\n",
            "Epoch: 1991 loss_train: 2687901.5000 acc_train: 0.1856 time: 0.0195s\n",
            "Epoch: 1992 loss_train: 2554574.0000 acc_train: 0.0973 time: 0.0197s\n",
            "Epoch: 1993 loss_train: 2723704.0000 acc_train: 0.0961 time: 0.0199s\n",
            "Epoch: 1994 loss_train: 2731285.2500 acc_train: 0.1852 time: 0.0195s\n",
            "Epoch: 1995 loss_train: 1753648.2500 acc_train: 0.1426 time: 0.0192s\n",
            "Epoch: 1996 loss_train: 2067783.3750 acc_train: 0.0825 time: 0.0190s\n",
            "Epoch: 1997 loss_train: 1592153.0000 acc_train: 0.0553 time: 0.0190s\n",
            "Epoch: 1998 loss_train: 1595331.0000 acc_train: 0.1072 time: 0.0191s\n",
            "Epoch: 1999 loss_train: 2232345.7500 acc_train: 0.0936 time: 0.0190s\n",
            "Epoch: 2000 loss_train: 2108996.5000 acc_train: 0.0923 time: 0.0189s\n",
            "Optimization Finished!\n",
            "Total time elapsed: 38.0995s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "otpt = pd.read_csv(\"output.csv\").drop(columns = [\"Unnamed: 0\"])"
      ],
      "metadata": {
        "id": "eZHzHeSgnZXZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.exp(otpt).sum(axis = 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xfCYbZ7swTnv",
        "outputId": "1fd22bd4-6f7c-4a01-9ad4-8e0e1d9d46cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        1.0\n",
              "1        1.0\n",
              "2        1.0\n",
              "3        1.0\n",
              "4        1.0\n",
              "        ... \n",
              "11947    1.0\n",
              "11948    1.0\n",
              "11949    1.0\n",
              "11950    1.0\n",
              "11951    1.0\n",
              "Length: 11952, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame(otpt.apply(lambda row: row.idxmax(), axis=1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "gbHHWgxmnnrV",
        "outputId": "74af3a91-8785-48a5-f068-2c687d4ac472"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       0\n",
              "0      5\n",
              "1      9\n",
              "2      4\n",
              "3      7\n",
              "4      5\n",
              "...   ..\n",
              "11947  0\n",
              "11948  4\n",
              "11949  4\n",
              "11950  5\n",
              "11951  4\n",
              "\n",
              "[11952 rows x 1 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2e62ff01-529f-4c15-ba23-6bf081c401a3\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11947</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11948</th>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11949</th>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11950</th>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11951</th>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>11952 rows  1 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2e62ff01-529f-4c15-ba23-6bf081c401a3')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-2e62ff01-529f-4c15-ba23-6bf081c401a3 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-2e62ff01-529f-4c15-ba23-6bf081c401a3');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-74a63cf3-1a8e-47aa-b3cb-cb4637994ffc\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-74a63cf3-1a8e-47aa-b3cb-cb4637994ffc')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-74a63cf3-1a8e-47aa-b3cb-cb4637994ffc button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"pd\",\n  \"rows\": 11952,\n  \"fields\": [\n    {\n      \"column\": 0,\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"1\",\n          \"9\",\n          \"8\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import scipy.sparse as sp\n",
        "import torch\n",
        "\n",
        "\n",
        "def encode_onehot(labels):\n",
        "    classes = set(labels)\n",
        "    classes_dict = {c: np.identity(len(classes))[i, :] for i, c in\n",
        "                    enumerate(classes)}\n",
        "    labels_onehot = np.array(list(map(classes_dict.get, labels)),\n",
        "                             dtype=np.int32)\n",
        "    return labels_onehot\n",
        "\n",
        "def df_to_sparse_matrix(df):\n",
        "  \"\"\"\n",
        "  Converts a pandas dataframe to a sparse matrix in sp.coo_ format.\n",
        "\n",
        "  Args:\n",
        "      df: A pandas dataframe.\n",
        "\n",
        "  Returns:\n",
        "      A sparse matrix in sp.coo_ format.\n",
        "  \"\"\"\n",
        "  # Get the number of rows and columns\n",
        "  num_rows = df.shape[0]\n",
        "  num_cols = df.shape[1]\n",
        "\n",
        "  # Create a list of tuples for the sparse matrix\n",
        "  data = []\n",
        "  for i in range(num_rows):\n",
        "    for j in range(num_cols):\n",
        "      if df.iloc[i, j] != 0:\n",
        "        data.append((i, j, df.iloc[i, j]))\n",
        "\n",
        "  # Create the sparse matrix\n",
        "  sparse_matrix = sp.coo_matrix((data, (num_rows, num_cols)))\n",
        "\n",
        "  return sparse_matrix\n",
        "\n",
        "\n",
        "def load_data(path=\"../data/cora/\", dataset=\"cora\"):\n",
        "    \"\"\"Load citation network dataset (cora only for now)\"\"\"\n",
        "\n",
        "    features = pd.read_excel(\"attributes.xlsx\")\n",
        "    labels = encode_onehot(pd.read_csv(\"submission.csv\")['LABEL'])\n",
        "    adj = df_to_sparse_matrix(pd.read_csv(\"adjacency.csv\"))\n",
        "\n",
        "    # build symmetric adjacency matrix\n",
        "    adj = adj + adj.T.multiply(adj.T > adj) - adj.multiply(adj.T > adj)\n",
        "\n",
        "    features = normalize(features)\n",
        "    adj = normalize(adj + sp.eye(adj.shape[0]))\n",
        "\n",
        "    idx_train = range(10952)\n",
        "    idx_test = range(10952, 11953)\n",
        "\n",
        "    features = torch.FloatTensor(np.array(features))\n",
        "    labels = torch.LongTensor(np.where(labels)[1])\n",
        "    adj = sparse_mx_to_torch_sparse_tensor(adj)\n",
        "\n",
        "    idx_train = torch.LongTensor(idx_train)\n",
        "    idx_test = torch.LongTensor(idx_test)\n",
        "\n",
        "    return adj, features, labels, idx_train, idx_test\n",
        "\n",
        "\n",
        "def normalize(mx):\n",
        "    \"\"\"Row-normalize sparse matrix\"\"\"\n",
        "    rowsum = np.array(mx.sum(1))\n",
        "    r_inv = np.power(rowsum, -1).flatten()\n",
        "    r_inv[np.isinf(r_inv)] = 0.\n",
        "    r_mat_inv = sp.diags(r_inv)\n",
        "    mx = r_mat_inv.dot(mx)\n",
        "    return mx\n",
        "\n",
        "\n",
        "def accuracy(output, labels):\n",
        "    preds = output.max(1)[1].type_as(labels)\n",
        "    correct = preds.eq(labels).double()\n",
        "    correct = correct.sum()\n",
        "    return correct / len(labels)\n",
        "\n",
        "\n",
        "def sparse_mx_to_torch_sparse_tensor(sparse_mx):\n",
        "    \"\"\"Convert a scipy sparse matrix to a torch sparse tensor.\"\"\"\n",
        "    sparse_mx = sparse_mx.tocoo().astype(np.float32)\n",
        "    indices = torch.from_numpy(\n",
        "        np.vstack((sparse_mx.row, sparse_mx.col)).astype(np.int64))\n",
        "    values = torch.from_numpy(sparse_mx.data)\n",
        "    shape = torch.Size(sparse_mx.shape)\n",
        "    return torch.sparse.FloatTensor(indices, values, shape)\n"
      ],
      "metadata": {
        "id": "ZiY2C5eBVLgA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import time\n",
        "import argparse\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "from utils import load_data, accuracy\n",
        "from models import GCN\n",
        "import pandas as pd\n",
        "\n",
        "# Training settings\n",
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument('--no-cuda', action='store_true', default=False,\n",
        "                    help='Disables CUDA training.')\n",
        "parser.add_argument('--fastmode', action='store_true', default=False,\n",
        "                    help='Validate during training pass.')\n",
        "parser.add_argument('--seed', type=int, default=42, help='Random seed.')\n",
        "parser.add_argument('--epochs', type=int, default=200,\n",
        "                    help='Number of epochs to train.')\n",
        "parser.add_argument('--lr', type=float, default=0.01,\n",
        "                    help='Initial learning rate.')\n",
        "parser.add_argument('--weight_decay', type=float, default=5e-4,\n",
        "                    help='Weight decay (L2 loss on parameters).')\n",
        "parser.add_argument('--hidden', type=int, default=16,\n",
        "                    help='Number of hidden units.')\n",
        "parser.add_argument('--dropout', type=float, default=0.5,\n",
        "                    help='Dropout rate (1 - keep probability).')\n",
        "\n",
        "args = parser.parse_args()\n",
        "args.cuda = not args.no_cuda and torch.cuda.is_available()\n",
        "\n",
        "np.random.seed(args.seed)\n",
        "torch.manual_seed(args.seed)\n",
        "if args.cuda:\n",
        "    torch.cuda.manual_seed(args.seed)\n",
        "\n",
        "# Load data\n",
        "adj, features, labels, idx_train, idx_test = load_data()\n",
        "\n",
        "# Model and optimizer\n",
        "model = GCN(nfeat=features.shape[1],\n",
        "            nhid=args.hidden,\n",
        "            nclass=labels.max().item() + 1,\n",
        "            dropout=args.dropout)\n",
        "optimizer = optim.Adam(model.parameters(),\n",
        "                       lr=args.lr, weight_decay=args.weight_decay)\n",
        "\n",
        "if args.cuda:\n",
        "    model.cuda()\n",
        "    features = features.cuda()\n",
        "    adj = adj.cuda()\n",
        "    labels = labels.cuda()\n",
        "    idx_train = idx_train.cuda()\n",
        "    idx_test = idx_test.cuda()\n",
        "\n",
        "\n",
        "def train(epoch):\n",
        "    t = time.time()\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    output = model(features, adj)\n",
        "    loss_train = F.nll_loss(output[idx_train], labels[idx_train])\n",
        "    acc_train = accuracy(output[idx_train], labels[idx_train])\n",
        "    loss_train.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if not args.fastmode:\n",
        "        # Evaluate validation set performance separately,\n",
        "        # deactivates dropout during validation run.\n",
        "        model.eval()\n",
        "        output = model(features, adj)\n",
        "\n",
        "    print('Epoch: {:04d}'.format(epoch+1),\n",
        "          'loss_train: {:.4f}'.format(loss_train.item()),\n",
        "          'acc_train: {:.4f}'.format(acc_train.item()),\n",
        "          'time: {:.4f}s'.format(time.time() - t))\n",
        "\n",
        "\n",
        "def test():\n",
        "    model.eval()\n",
        "    output = model(features, adj)\n",
        "    pd.DataFrame(output).to_csv('output.csv')\n",
        "\n",
        "\n",
        "# Train model\n",
        "t_total = time.time()\n",
        "for epoch in range(args.epochs):\n",
        "    train(epoch)\n",
        "print(\"Optimization Finished!\")\n",
        "print(\"Total time elapsed: {:.4f}s\".format(time.time() - t_total))\n",
        "\n",
        "# Testing\n",
        "test()\n"
      ],
      "metadata": {
        "id": "mOx-SxMqfKE7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}